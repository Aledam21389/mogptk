{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following example runs over a dataset of aerobic actions recorded from subjects \"using the Inertial Measurement Unit (IMU) on an Apple iPhone 4 smartphone. The IMU includes a 3D accelerometer, gyroscope, and magnetometer*. Each sample was taken at 60Hz, and manually trimmed to 500 samples (8.33s) to eliminate starting and stopping movements. iPhone is always clipped to the belt on the right hand side.\"\n",
    "\n",
    "Each file contains 500 rows, each row with the following information:\n",
    "Acc_x,Acc_y,Acc_z,Gyr_x,Gyr_y,Gyr_z,Mag_x,Mag_y,Mag_z\n",
    "\n",
    "Each sensor has 3 channels.\n",
    "\n",
    "You may find the dataset and revelant information about the publication 'Corey McCall, Kishore Reddy and Mubarak Shah, Macro-Class Selection for Hierarchical K-NN Classification of Inertial Sensor Data, Second International Conference on Pervasive and Embedded Computing and Communication Systems, PECCS 2012, February 24-26, 2012, Rome, Italy.' at: http://crcv.ucf.edu/data/UCF-iPhone.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from os import listdir\n",
    "import time\n",
    "from model import mosm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions transform the dataset info into a more readily usable format, for multi-output regression. Note that the original files only contain the y-axis information, in increasing time order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since the class of the activity is encoded in the filename we use this information to create numerical labels.\n",
    "def conversion(label):\n",
    "    if(label == 'bike'):\n",
    "        return 0\n",
    "    elif(label == 'climbing'):\n",
    "        return 1\n",
    "    elif(label == 'descending'):\n",
    "        return 2\n",
    "    elif(label == 'gymbike'):\n",
    "        return 3\n",
    "    elif(label == 'jumping'):\n",
    "        return 4\n",
    "    elif(label == 'running'):\n",
    "        return 5\n",
    "    elif(label == 'standing'):\n",
    "        return 6\n",
    "    elif(label == 'treadmill'):\n",
    "        return 7\n",
    "    elif(label == 'walking'):\n",
    "        return 8\n",
    "    \n",
    "#For each one of the folders we get all the filenames within them.\n",
    "def get_file_names(path):\n",
    "    folder = path + 'S0%d'\n",
    "    filenames = []\n",
    "    for x in range(1,10):\n",
    "        current_folder = folder % x\n",
    "        onlyfiles = [current_folder + \"/\" + f for f in listdir(current_folder)]\n",
    "        filenames.append(sorted(onlyfiles))\n",
    "    return filenames\n",
    "\n",
    "#Given the full_path (where the dataset resides in memory) we get all the filenames of all the dataset folders\n",
    "#and generate (Y,label) lists.\n",
    "def make_dataset(full_path):\n",
    "    full_file_names = get_file_names(full_path)\n",
    "    Y = []\n",
    "    label_names = []\n",
    "    label_numbers = []\n",
    "    for folder_number in range(9):\n",
    "        for filename in range(len(full_file_names[folder_number])):\n",
    "            path = full_file_names[folder_number][filename]\n",
    "            sample_data = np.genfromtxt(path, delimiter=',')\n",
    "            Y.append(sample_data)\n",
    "            label = path.split('/')\n",
    "            label = label[len(label)-1].split('.')[0]\n",
    "            label = label[0:len(label)-1]\n",
    "            label_names.append(label)\n",
    "            label_numbers.append(conversion(label))\n",
    "\n",
    "    return Y, label_numbers, label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can access the y-axis information for each channel we have to create an x-axis counterpart to feed the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_path = './data/HAR/Smartphone_Dataset/'\n",
    "measurements, label_number, label_names = make_dataset(full_path)\n",
    "\n",
    "#Since we're fitting curves, instead of performing a classification, we won't be using\n",
    "#the class labels. We have to fabricate an X component to our y (the measurements).\n",
    "#The measurements correspond to 9 channels (3 per sensor: accel, gyro, magnetometer) at\n",
    "#a rate of 60hz. There's 500 measurements per channel, so the total time spanned is approx\n",
    "#8.33s\n",
    "X_list_bike = []\n",
    "y_list_bike = []\n",
    "X_list_climb = []\n",
    "y_list_climb = []\n",
    "#Note that measurements is a list containing all y-values for all channels for all experiments. So, by \n",
    "#accessing measurements[0] we are acquiring all the y-values for all 9 channels of experiment 0 which\n",
    "#happens to be a bicycle ride.\n",
    "measurements_for_one_bicycle_ride = measurements[0] #Remember that measurements is a list containing \n",
    "#Experiment 5 is an instance of climbing.\n",
    "measurements_for_one_instance_of_climbing = measurements[5]\n",
    "\n",
    "#The following loop allows us to pick any number of channels, without modifying channel order.\n",
    "number_of_channels = 9\n",
    "for index in range(number_of_channels):\n",
    "    X_list_bike.append(np.array([x/60 for x in range(500)]))\n",
    "    X_list_climb.append(np.array([x/60 for x in range(500)]))\n",
    "    #We also remove the mean from the y-values to better approximate a mean=0 GP.\n",
    "    y_list_bike.append(measurements_for_one_bicycle_ride[:,index]-measurements_for_one_bicycle_ride[:,index].mean())\n",
    "    y_list_climb.append(measurements_for_one_instance_of_climbing[:,index]-measurements_for_one_instance_of_climbing[:,index].mean())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "TFGPU",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
