<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>mogptk.errors API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mogptk.errors</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd          # TODO: remove dependency on sklearn?
from sklearn import metrics  # TODO: remove dependency on sklearn?

def mean_absolute_percentage_error(y_true, y_pred):
    idx = np.nonzero(y_true)
    y_true = y_true[idx]
    y_pred = y_pred[idx]
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# TODO: use relative error per channel
def errors(*models, **kwargs):
    &#34;&#34;&#34;
    Return error metrics for given models.

    errors will returns error measures (MAE, MSE, MAPE) for the model by comparing the deleted observations from the predicted means.
    The predicted values are interpolated linearly to match the X position of the delete dobservations.
    However if a latent function is defined in the data this will be used as the true values, which gets rid of the imposed Gaussian error on the observations.

    Args:
        model_list: Iterable with mogptk models to evaluate.
    
    Returns:
        errors (dic): Dictionary with lists of ndarrays containing different error metrics per model, per channel.

        The dictionary has three keys, &#39;model&#39; which contains model name; &#39;MAE&#39; contains mean absolute error; &#39;MSE&#39; mean squared error; &#39;MAPE&#39; mean absolute percentage error.
        


    &#34;&#34;&#34;
    all_obs = False
    if &#34;all_obs&#34; in kwargs:
        all_obs = kwargs[&#34;all_obs&#34;]
    output = False
    if &#34;print&#34; in kwargs:
        output = kwargs[&#34;print&#34;]

    errors = []
    for model in models:
        if model.get_input_dims() != 1:
            raise Exception(&#34;cannot (yet) estimate errors when using multi input dimensions&#34;)

        Y_true = np.empty(0)
        Y_pred = np.empty(0)
        for channel in model.data:
            if len(channel.X_pred) == 0:
                continue

            if all_obs:
                x, y_true = channel.get_data()
            else:
                x, y_true = channel.get_test_data()

            if len(x) &gt; 0:
                if channel.F != None:
                    y_true = channel.F(x) # use exact latent function to remove imposed Gaussian error on data points

                y_pred = np.interp(x, channel.X_pred.reshape(-1), channel.Y_mu_pred) # TODO: multi input dims

                Y_true = np.append(Y_true, y_true)
                Y_pred = np.append(Y_pred, y_pred)
            
        errors.append({
            &#34;model&#34;: model.name,
            &#34;MAE&#34;: metrics.mean_absolute_error(Y_true, Y_pred),
            &#34;MSE&#34;: metrics.mean_squared_error(Y_true, Y_pred),
            &#34;MAPE&#34;: mean_absolute_percentage_error(Y_true, Y_pred),
        })

    if output:
        df = pd.DataFrame(errors)
        df.set_index(&#39;model&#39;, inplace=True)
        display(df)
    else:
        return errors


def test_errors(*models, x_test, y_test, raw_errors=False):
    &#34;&#34;&#34;
    Return test errors given a model and test set.

    The function assumes all models have been trained and all models
    share equal number of inputs and outputs (channels).

    Args:
        models (mogptk.model): Trained model to evaluate, can be more than one

        x_test (list): List of numpy arrays with the inputs of the test set.
            Length is the output dimension.

        y_test (list): List of numpy array with the true ouputs of test set.
            Length is the output dimension.

        raw_errors (bool): If true returns for each model a list is returned
            with the errors of each channel (y_true - y_pred).
            If false returns for each model a list of 4 arrays with the
            mean absolute error (MAE), range-normalized mean absolute error (nMAE),
            root mean squared error (RMSE) and range-normalized root mean 
            squared error (nRMSE) for each channel.

    Returns:
        List with length equal to the number of models, each element
        contains a list of length of the output dim and each
        element is an array with the errors.

    Example:
        Given model1, model2, x_test, y_test of correct format.

        &gt;&gt;&gt; errors = mogptk.test_errors(model1, model2, x_test, y_test)
        &gt;&gt;&gt; errors[i][j]
        numpy array with errors from model &#39;i&#39; at channel &#39;j&#39;
    &#34;&#34;&#34;

    error_per_model = []

    for model in models:

        n_channels = model.dataset.get_output_dims()

        if n_channels==1:
            if not isinstance(y_test, list):
                y_test = [y_test]

        error_per_channel = []

        # print([a.std() for a in y_test])

        # predict with model
        y_pred, _, _ = model.predict(x_test)

        for i in range(n_channels):
            errors = y_test[i] - y_pred[i]
            # if only error values
            if raw_errors:
                error_per_channel.append(errors)

            # composite errors
            else:
                y_range = y_test[i].max() - y_test[i].min()

                mae = np.abs(errors).mean()
                nmae = mae / y_range
                rmse = np.sqrt((errors**2).mean())
                nrmse = rmse / y_range
                
                error_per_channel.append(np.array([mae, nmae, rmse, nrmse]))

        error_per_model.append(error_per_channel)

    return error_per_model</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mogptk.errors.errors"><code class="name flex">
<span>def <span class="ident">errors</span></span>(<span>*models, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Return error metrics for given models.</p>
<p>errors will returns error measures (MAE, MSE, MAPE) for the model by comparing the deleted observations from the predicted means.
The predicted values are interpolated linearly to match the X position of the delete dobservations.
However if a latent function is defined in the data this will be used as the true values, which gets rid of the imposed Gaussian error on the observations.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_list</code></strong></dt>
<dd>Iterable with mogptk models to evaluate.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="mogptk.errors.errors" href="#mogptk.errors.errors"><code>errors()</code></a></strong> :&ensp;<code>dic</code></dt>
<dd>Dictionary with lists of ndarrays containing different error metrics per model, per channel.</dd>
</dl>
<p>The dictionary has three keys, 'model' which contains model name; 'MAE' contains mean absolute error; 'MSE' mean squared error; 'MAPE' mean absolute percentage error.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def errors(*models, **kwargs):
    &#34;&#34;&#34;
    Return error metrics for given models.

    errors will returns error measures (MAE, MSE, MAPE) for the model by comparing the deleted observations from the predicted means.
    The predicted values are interpolated linearly to match the X position of the delete dobservations.
    However if a latent function is defined in the data this will be used as the true values, which gets rid of the imposed Gaussian error on the observations.

    Args:
        model_list: Iterable with mogptk models to evaluate.
    
    Returns:
        errors (dic): Dictionary with lists of ndarrays containing different error metrics per model, per channel.

        The dictionary has three keys, &#39;model&#39; which contains model name; &#39;MAE&#39; contains mean absolute error; &#39;MSE&#39; mean squared error; &#39;MAPE&#39; mean absolute percentage error.
        


    &#34;&#34;&#34;
    all_obs = False
    if &#34;all_obs&#34; in kwargs:
        all_obs = kwargs[&#34;all_obs&#34;]
    output = False
    if &#34;print&#34; in kwargs:
        output = kwargs[&#34;print&#34;]

    errors = []
    for model in models:
        if model.get_input_dims() != 1:
            raise Exception(&#34;cannot (yet) estimate errors when using multi input dimensions&#34;)

        Y_true = np.empty(0)
        Y_pred = np.empty(0)
        for channel in model.data:
            if len(channel.X_pred) == 0:
                continue

            if all_obs:
                x, y_true = channel.get_data()
            else:
                x, y_true = channel.get_test_data()

            if len(x) &gt; 0:
                if channel.F != None:
                    y_true = channel.F(x) # use exact latent function to remove imposed Gaussian error on data points

                y_pred = np.interp(x, channel.X_pred.reshape(-1), channel.Y_mu_pred) # TODO: multi input dims

                Y_true = np.append(Y_true, y_true)
                Y_pred = np.append(Y_pred, y_pred)
            
        errors.append({
            &#34;model&#34;: model.name,
            &#34;MAE&#34;: metrics.mean_absolute_error(Y_true, Y_pred),
            &#34;MSE&#34;: metrics.mean_squared_error(Y_true, Y_pred),
            &#34;MAPE&#34;: mean_absolute_percentage_error(Y_true, Y_pred),
        })

    if output:
        df = pd.DataFrame(errors)
        df.set_index(&#39;model&#39;, inplace=True)
        display(df)
    else:
        return errors</code></pre>
</details>
</dd>
<dt id="mogptk.errors.mean_absolute_percentage_error"><code class="name flex">
<span>def <span class="ident">mean_absolute_percentage_error</span></span>(<span>y_true, y_pred)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean_absolute_percentage_error(y_true, y_pred):
    idx = np.nonzero(y_true)
    y_true = y_true[idx]
    y_pred = y_pred[idx]
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100</code></pre>
</details>
</dd>
<dt id="mogptk.errors.test_errors"><code class="name flex">
<span>def <span class="ident">test_errors</span></span>(<span>*models, x_test, y_test, raw_errors=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Return test errors given a model and test set.</p>
<p>The function assumes all models have been trained and all models
share equal number of inputs and outputs (channels).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>models</code></strong> :&ensp;<a title="mogptk.model" href="model.html"><code>mogptk.model</code></a></dt>
<dd>Trained model to evaluate, can be more than one</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>list</code></dt>
<dd>List of numpy arrays with the inputs of the test set.
Length is the output dimension.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>list</code></dt>
<dd>List of numpy array with the true ouputs of test set.
Length is the output dimension.</dd>
<dt><strong><code>raw_errors</code></strong> :&ensp;<code>bool</code></dt>
<dd>If true returns for each model a list is returned
with the errors of each channel (y_true - y_pred).
If false returns for each model a list of 4 arrays with the
mean absolute error (MAE), range-normalized mean absolute error (nMAE),
root mean squared error (RMSE) and range-normalized root mean
squared error (nRMSE) for each channel.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List</code> <code>with</code> <code>length</code> <code>equal</code> <code>to</code> <code>the</code> <code>number</code> of <code>models</code>, <code>each</code> <code>element</code></dt>
<dd>&nbsp;</dd>
<dt><code>contains</code> <code>a</code> <code>list</code> of <code>length</code> of <code>the</code> <code>output</code> <code>dim</code> <code>and</code> <code>each</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>element is an array with the errors.</p>
<h2 id="example">Example</h2>
<p>Given model1, model2, x_test, y_test of correct format.</p>
<pre><code>&gt;&gt;&gt; errors = mogptk.test_errors(model1, model2, x_test, y_test)
&gt;&gt;&gt; errors[i][j]
numpy array with errors from model 'i' at channel 'j'
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_errors(*models, x_test, y_test, raw_errors=False):
    &#34;&#34;&#34;
    Return test errors given a model and test set.

    The function assumes all models have been trained and all models
    share equal number of inputs and outputs (channels).

    Args:
        models (mogptk.model): Trained model to evaluate, can be more than one

        x_test (list): List of numpy arrays with the inputs of the test set.
            Length is the output dimension.

        y_test (list): List of numpy array with the true ouputs of test set.
            Length is the output dimension.

        raw_errors (bool): If true returns for each model a list is returned
            with the errors of each channel (y_true - y_pred).
            If false returns for each model a list of 4 arrays with the
            mean absolute error (MAE), range-normalized mean absolute error (nMAE),
            root mean squared error (RMSE) and range-normalized root mean 
            squared error (nRMSE) for each channel.

    Returns:
        List with length equal to the number of models, each element
        contains a list of length of the output dim and each
        element is an array with the errors.

    Example:
        Given model1, model2, x_test, y_test of correct format.

        &gt;&gt;&gt; errors = mogptk.test_errors(model1, model2, x_test, y_test)
        &gt;&gt;&gt; errors[i][j]
        numpy array with errors from model &#39;i&#39; at channel &#39;j&#39;
    &#34;&#34;&#34;

    error_per_model = []

    for model in models:

        n_channels = model.dataset.get_output_dims()

        if n_channels==1:
            if not isinstance(y_test, list):
                y_test = [y_test]

        error_per_channel = []

        # print([a.std() for a in y_test])

        # predict with model
        y_pred, _, _ = model.predict(x_test)

        for i in range(n_channels):
            errors = y_test[i] - y_pred[i]
            # if only error values
            if raw_errors:
                error_per_channel.append(errors)

            # composite errors
            else:
                y_range = y_test[i].max() - y_test[i].min()

                mae = np.abs(errors).mean()
                nmae = mae / y_range
                rmse = np.sqrt((errors**2).mean())
                nrmse = rmse / y_range
                
                error_per_channel.append(np.array([mae, nmae, rmse, nrmse]))

        error_per_model.append(error_per_channel)

    return error_per_model</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mogptk" href="index.html">mogptk</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mogptk.errors.errors" href="#mogptk.errors.errors">errors</a></code></li>
<li><code><a title="mogptk.errors.mean_absolute_percentage_error" href="#mogptk.errors.mean_absolute_percentage_error">mean_absolute_percentage_error</a></code></li>
<li><code><a title="mogptk.errors.test_errors" href="#mogptk.errors.test_errors">test_errors</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>