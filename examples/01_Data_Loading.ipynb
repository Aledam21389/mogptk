{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-Data Loading\n",
    "\n",
    "_[Estimated execution time: 1 min]_\n",
    "\n",
    "This tutorial will show different ways of loading data sets and how we can process different data types such as date and time.\n",
    "\n",
    "In MOGPTK there are two data structures that are important, the `Data` and `DataSet` classes. The `Data` class is the basic component that holds all data and related information for a single channel. For example, it contains the `X` and `Y` coordinates of our input data, which coordinates are for training and testing, the name of the channel, the labels for the X and Y axes, the latent function of our data (if they exist), data from predictions, data transformations (see [02-Data Preparation](https://github.com/GAMES-UChile/mogptk/blob/master/examples/02_Data_Preparation.ipynb)), and data formatters (discussed in this tutorial).\n",
    "\n",
    "The `DataSet` class is essentially an array of `Data` instances and thus represents a complete data set with multiple output channels. The separate `Data` instances can be obtained by indexing (e.g. `dataset[0]` returns the first data channel) and `DataSet` contains convenient functions over all channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.799871Z",
     "start_time": "2020-11-17T11:08:04.038295Z"
    }
   },
   "outputs": [],
   "source": [
    "import mogptk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from CSV file\n",
    "Loading CSV files can be done through the [`mogptk.LoadCSV`](https://games-uchile.github.io/mogptk/dataset.html#mogptk.dataset.LoadCSV) function. We will use the airline passenger data set as an example and we'll inspect how the first lines of this file look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.809324Z",
     "start_time": "2020-11-17T11:08:05.802690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000000000000000e+00 1.120000000000000000e+02\n",
      "1.000000000000000000e+00 1.180000000000000000e+02\n",
      "2.000000000000000000e+00 1.320000000000000000e+02\n",
      "3.000000000000000000e+00 1.290000000000000000e+02\n",
      "4.000000000000000000e+00 1.210000000000000000e+02\n"
     ]
    }
   ],
   "source": [
    "with open('data/Airline_passenger.csv') as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that there are no column names in the first row, nor are columns separated by commas which usually is the case with CSV (comma-separated values) files. Our function is able to load this CSV file, but we have to explicitly pass `sep=' '` to tell that columns are separated by spaces. We also pass the `names=['time','passengers]` to set the column names explicitly as they cannot be extracted from the data. Note that `LoadCSV` is a wrapper around [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html), so you can pass the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.850829Z",
     "start_time": "2020-11-17T11:08:05.812493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      time  passengers\n",
       "0      0.0       112.0\n",
       "1      1.0       118.0\n",
       "2      2.0       132.0\n",
       "3      3.0       129.0\n",
       "4      4.0       121.0\n",
       "..     ...         ...\n",
       "139  139.0       606.0\n",
       "140  140.0       508.0\n",
       "141  141.0       461.0\n",
       "142  142.0       390.0\n",
       "143  143.0       432.0\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mogptk.LoadCSV('data/Airline_passenger.csv',\n",
    "               names=['time','passengers'],\n",
    "               sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from DataFrame\n",
    "A more flexible way to load data is through pandas data frames directly because they provide functionality for loading CSV, Excel, JSON, SQL, and more data files. Furthermore, dataframes allow to filter and clean the data before handing them over to MOGPTK. We will be using the [`mogptk.LoadDataFrame`](https://games-uchile.github.io/mogptk/dataset.html#mogptk.dataset.LoadDataFrame) to load the airline passenger data. First we load our data into a DataFrame using the `read_table` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.877853Z",
     "start_time": "2020-11-17T11:08:05.853988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139.0</td>\n",
       "      <td>606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140.0</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141.0</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142.0</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143.0</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  passengers\n",
       "0      0.0       112.0\n",
       "1      1.0       118.0\n",
       "2      2.0       132.0\n",
       "3      3.0       129.0\n",
       "4      4.0       121.0\n",
       "..     ...         ...\n",
       "139  139.0       606.0\n",
       "140  140.0       508.0\n",
       "141  141.0       461.0\n",
       "142  142.0       390.0\n",
       "143  143.0       432.0\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data/Airline_passenger.csv',\n",
    "                   names=['time','passengers'],\n",
    "                   sep=' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the DataFrame we can load this into a `DataSet` as follows. This function will by default load the first column as the `X` axis and the second column as the `Y` axis. Using the `dtypes` of the data frame for each column, it will automatically load convert `datetime` fields to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.906898Z",
     "start_time": "2020-11-17T11:08:05.880850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      time  passengers\n",
       "0      0.0       112.0\n",
       "1      1.0       118.0\n",
       "2      2.0       132.0\n",
       "3      3.0       129.0\n",
       "4      4.0       121.0\n",
       "..     ...         ...\n",
       "139  139.0       606.0\n",
       "140  140.0       508.0\n",
       "141  141.0       461.0\n",
       "142  142.0       390.0\n",
       "143  143.0       432.0\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mogptk.LoadDataFrame(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns and loading datetime values\n",
    "Here we will use the air quality data set which includes column names as well as date and time values. First we inspect the first five lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.917708Z",
     "start_time": "2020-11-17T11:08:05.910158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date;Time;CO(GT);PT08.S1(CO);NMHC(GT);C6H6(GT);PT08.S2(NMHC);NOx(GT);PT08.S3(NOx);NO2(GT);PT08.S4(NO2);PT08.S5(O3);T;RH;AH;;\n",
      "10/03/2004;18.00.00;2.6;1360;150;11.9;1046;166;1056;113;1692;1268;13.6;48.9;0.7578;;\n",
      "10/03/2004;19.00.00;2;1292;112;9.4;955;103;1174;92;1559;972;13.3;47.7;0.7255;;\n",
      "10/03/2004;20.00.00;2.2;1402;88;9.0;939;131;1140;114;1555;1074;11.9;54.0;0.7502;;\n",
      "10/03/2004;21.00.00;2.2;1376;80;9.2;948;172;1092;122;1584;1203;11.0;60.0;0.7867;;\n"
     ]
    }
   ],
   "source": [
    "with open('data/AirQualityUCI.csv') as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that that the separator between the columns is a semicolon `;`, so this will be our separator for `pandas.read_table`. There is no need to set the `names` parameter since all the column names are given in the first row of the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.953181Z",
     "start_time": "2020-11-17T11:08:05.920748Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('data/AirQualityUCI.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading will automatically try and parse the `Date` column to see if it can be parsed as a datetime type. However we can also explicitly set the DataFrame column's dtype to `datetime64`. The toolkit will automatically recognize this and convert the date time values to numbers which is needed for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:05.976565Z",
     "start_time": "2020-11-17T11:08:05.957834Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H.%M.%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the data frame and set our input dimension to the `Date` column, and our output dimensions to the `CO(GT)` and `PT08.S1(CO)` columns. That means, we will have two channels `CO(GT)` and `PT08.S1(CO)` that share the same `X` coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.039792Z",
     "start_time": "2020-11-17T11:08:05.980365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date  CO(GT)\n",
       "0     2004-10-03     2.6\n",
       "1     2004-10-03     2.0\n",
       "2     2004-10-03     2.2\n",
       "3     2004-10-03     2.2\n",
       "4     2004-10-03     1.6\n",
       "...          ...     ...\n",
       "9352  2005-04-04     3.1\n",
       "9353  2005-04-04     2.4\n",
       "9354  2005-04-04     2.4\n",
       "9355  2005-04-04     2.1\n",
       "9356  2005-04-04     2.2\n",
       "\n",
       "[9357 rows x 2 columns]\n",
       "            Date  PT08.S1(CO)\n",
       "0     2004-10-03       1360.0\n",
       "1     2004-10-03       1292.0\n",
       "2     2004-10-03       1402.0\n",
       "3     2004-10-03       1376.0\n",
       "4     2004-10-03       1272.0\n",
       "...          ...          ...\n",
       "9352  2005-04-04       1314.0\n",
       "9353  2005-04-04       1163.0\n",
       "9354  2005-04-04       1142.0\n",
       "9355  2005-04-04       1003.0\n",
       "9356  2005-04-04       1071.0\n",
       "\n",
       "[9357 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mogptk.LoadDataFrame(df, x_col='Date', y_col=['CO(GT)', 'PT08.S1(CO)'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSets\n",
    "We can expand data sets by appending another `DataSet` or `Data` instance, which will be added to the list of channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.113480Z",
     "start_time": "2020-11-17T11:08:06.044982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date  CO(GT)\n",
       "0     2004-10-03     2.6\n",
       "1     2004-10-03     2.0\n",
       "2     2004-10-03     2.2\n",
       "3     2004-10-03     2.2\n",
       "4     2004-10-03     1.6\n",
       "...          ...     ...\n",
       "9352  2005-04-04     3.1\n",
       "9353  2005-04-04     2.4\n",
       "9354  2005-04-04     2.4\n",
       "9355  2005-04-04     2.1\n",
       "9356  2005-04-04     2.2\n",
       "\n",
       "[9357 rows x 2 columns]\n",
       "            Date  PT08.S1(CO)\n",
       "0     2004-10-03       1360.0\n",
       "1     2004-10-03       1292.0\n",
       "2     2004-10-03       1402.0\n",
       "3     2004-10-03       1376.0\n",
       "4     2004-10-03       1272.0\n",
       "...          ...          ...\n",
       "9352  2005-04-04       1314.0\n",
       "9353  2005-04-04       1163.0\n",
       "9354  2005-04-04       1142.0\n",
       "9355  2005-04-04       1003.0\n",
       "9356  2005-04-04       1071.0\n",
       "\n",
       "[9357 rows x 2 columns]\n",
       "           Date                Time  NMHC(GT)\n",
       "0    2004-10-03 1900-01-01 18:00:00     150.0\n",
       "1    2004-10-03 1900-01-01 19:00:00     112.0\n",
       "2    2004-10-03 1900-01-01 20:00:00      88.0\n",
       "3    2004-10-03 1900-01-01 21:00:00      80.0\n",
       "4    2004-10-03 1900-01-01 22:00:00      51.0\n",
       "...         ...                 ...       ...\n",
       "9352 2005-04-04 1900-01-01 10:00:00    -200.0\n",
       "9353 2005-04-04 1900-01-01 11:00:00    -200.0\n",
       "9354 2005-04-04 1900-01-01 12:00:00    -200.0\n",
       "9355 2005-04-04 1900-01-01 13:00:00    -200.0\n",
       "9356 2005-04-04 1900-01-01 14:00:00    -200.0\n",
       "\n",
       "[9357 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.append(mogptk.LoadDataFrame(df, x_col=['Date', 'Time'], y_col='NMHC(GT)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.121920Z",
     "start_time": "2020-11-17T11:08:06.116869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many channels do we have?\n",
    "data.get_output_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.131335Z",
     "start_time": "2020-11-17T11:08:06.124839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And how many input dimensions do each of these channels have?\n",
    "data.get_input_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.142343Z",
     "start_time": "2020-11-17T11:08:06.135913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the channel's names?\n",
    "data.get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve a single channel as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.167388Z",
     "start_time": "2020-11-17T11:08:06.145054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date  CO(GT)\n",
       "0     2004-10-03     2.6\n",
       "1     2004-10-03     2.0\n",
       "2     2004-10-03     2.2\n",
       "3     2004-10-03     2.2\n",
       "4     2004-10-03     1.6\n",
       "...          ...     ...\n",
       "9352  2005-04-04     3.1\n",
       "9353  2005-04-04     2.4\n",
       "9354  2005-04-04     2.4\n",
       "9355  2005-04-04     2.1\n",
       "9356  2005-04-04     2.2\n",
       "\n",
       "[9357 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.190971Z",
     "start_time": "2020-11-17T11:08:06.171175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date  CO(GT)\n",
       "0     2004-10-03     2.6\n",
       "1     2004-10-03     2.0\n",
       "2     2004-10-03     2.2\n",
       "3     2004-10-03     2.2\n",
       "4     2004-10-03     1.6\n",
       "...          ...     ...\n",
       "9352  2005-04-04     3.1\n",
       "9353  2005-04-04     2.4\n",
       "9354  2005-04-04     2.4\n",
       "9355  2005-04-04     2.1\n",
       "9356  2005-04-04     2.2\n",
       "\n",
       "[9357 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CO(GT)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `get_train_data()` we get the `X` and `Y` training data. `get_data()` returns all data, and `get_test_data()` returns the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.205486Z",
     "start_time": "2020-11-17T11:08:06.193893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([['2004-10-03'],\n",
       "         ['2004-10-03'],\n",
       "         ['2004-10-03'],\n",
       "         ...,\n",
       "         ['2005-04-04'],\n",
       "         ['2005-04-04'],\n",
       "         ['2005-04-04']], dtype='datetime64[D]'), array([['2004-10-03'],\n",
       "         ['2004-10-03'],\n",
       "         ['2004-10-03'],\n",
       "         ...,\n",
       "         ['2005-04-04'],\n",
       "         ['2005-04-04'],\n",
       "         ['2005-04-04']], dtype='datetime64[D]'), array([['2004-10-03T00', '1900-01-01T18'],\n",
       "         ['2004-10-03T00', '1900-01-01T19'],\n",
       "         ['2004-10-03T00', '1900-01-01T20'],\n",
       "         ...,\n",
       "         ['2005-04-04T00', '1900-01-01T12'],\n",
       "         ['2005-04-04T00', '1900-01-01T13'],\n",
       "         ['2005-04-04T00', '1900-01-01T14']], dtype='datetime64[h]')],\n",
       " [array([2.6, 2. , 2.2, ..., 2.4, 2.1, 2.2]),\n",
       "  array([1360., 1292., 1402., ..., 1142., 1003., 1071.]),\n",
       "  array([ 150.,  112.,   88., ..., -200., -200., -200.])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what data is used for training, we have to pass `transformed=True`. This returns the transformed data containing only numbers and with transformations applied to improve training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:08:06.219600Z",
     "start_time": "2020-11-17T11:08:06.208012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[390.55793991],\n",
       "         [390.55793991],\n",
       "         [390.55793991],\n",
       "         ...,\n",
       "         [652.36051502],\n",
       "         [652.36051502],\n",
       "         [652.36051502]]), array([[390.55793991],\n",
       "         [390.55793991],\n",
       "         [390.55793991],\n",
       "         ...,\n",
       "         [652.36051502],\n",
       "         [652.36051502],\n",
       "         [652.36051502]]), array([[390.55793991, 782.60869565],\n",
       "         [390.55793991, 826.08695652],\n",
       "         [390.55793991, 869.56521739],\n",
       "         ...,\n",
       "         [652.36051502, 521.73913043],\n",
       "         [652.36051502, 565.2173913 ],\n",
       "         [652.36051502, 608.69565217]])],\n",
       " [array([2.6, 2. , 2.2, ..., 2.4, 2.1, 2.2]),\n",
       "  array([1360., 1292., 1402., ..., 1142., 1003., 1071.]),\n",
       "  array([ 150.,  112.,   88., ..., -200., -200., -200.])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_train_data(transformed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
