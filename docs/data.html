<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.3" />
<title>mogptk.data API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mogptk.data</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>Source code</summary>
<pre><code class="python">import csv
import copy
import inspect
import dill
import numpy as np
from mogptk.bnse import *
from scipy import signal
import dateutil, datetime
import matplotlib
import matplotlib.pyplot as plt
import re
import pandas as pd
from sklearn.linear_model import Ridge
    
duration_regex = re.compile(
    r&#39;^((?P&lt;years&gt;[\.\d]+?)y)?&#39;
    r&#39;((?P&lt;months&gt;[\.\d]+?)M)?&#39;
    r&#39;((?P&lt;weeks&gt;[\.\d]+?)w)?&#39;
    r&#39;((?P&lt;days&gt;[\.\d]+?)d)?&#39;
    r&#39;((?P&lt;hours&gt;[\.\d]+?)h)?&#39;
    r&#39;((?P&lt;minutes&gt;[\.\d]+?)m)?&#39;
    r&#39;((?P&lt;seconds&gt;[\.\d]+?)s)?$&#39;)


def _detransform(transformations, x, y):
    &#34;&#34;&#34;
    Apply inverse transformations to a set of values.

    Used to apply inverse tranformations of a channel stored
    in a Data class to a set.

    Args:
        transformations(list): List of transformations(objects) in order of aplication.
        x(ndarray): Array of n_points x n_dim of inputs.
        y(ndarray): Array of n_points outputs.
    &#34;&#34;&#34;
    if len(transformations) &gt; 0:
        for t in transformations[::-1]:
            y = t._backward(x, y)
    return y

def _parse_duration_to_sec(s):
    x = duration_regex.match(s)
    if x == None:
        raise ValueError(&#39;duration string must be of the form 2h45m, allowed characters: (y)ear, (M)onth, (w)eek, (d)ay, (h)our, (m)inute, (s)econd&#39;)

    sec = 0
    matches = x.groups()[1::2]
    if matches[0]:
        sec += float(matches[0])*356.2425*24*3600
    if matches[1]:
        sec += float(matches[1])*30.4369*24*3600
    if matches[2]:
        sec += float(matches[2])*7*24*3600
    if matches[3]:
        sec += float(matches[3])*24*3600
    if matches[4]:
        sec += float(matches[4])*3600
    if matches[5]:
        sec += float(matches[5])*60
    if matches[6]:
        sec += float(matches[6])
    return sec

class FormatNumber:
    &#34;&#34;&#34;
    FormatNumber is the default formatter and takes regular floating point values as input.
    &#34;&#34;&#34;
    def _format(val):
        return val

    def _parse(val, loc=None):
        try:
            return float(val)
        except ValueError:
            if loc == None:
                raise ValueError(&#34;could not convert input to number&#34;)
            else:
                raise ValueError(&#34;could not convert input to number at %s&#34; % (loc))

    def _parse_duration(val, loc=None):
        return FormatNumber._parse(val, loc)

    def _scale(maxfreq=None):
        return 1, None

class FormatDate:
    &#34;&#34;&#34;
    FormatDate is a formatter that takes date values as input, such as &#39;2019-03-01&#39;, and stores values internally as days since 1970-01-01.
    &#34;&#34;&#34;
    def _format(val):
        return datetime.datetime.utcfromtimestamp(val*3600*24).strftime(&#39;%Y-%m-%d&#39;)

    def _parse(val, loc=None):
        try:
            return (dateutil.parser.parse(val) - datetime.datetime(1970,1,1)).total_seconds()/3600/24
        except ValueError:
            if loc == None:
                raise ValueError(&#34;could not convert input to date&#34;)
            else:
                raise ValueError(&#34;could not convert input to date at %s&#34; % (loc))

    def _parse_duration(val):
        if isinstance(val, int):
            return val
        if isinstance(val, str):
            return _parse_duration_to_sec(val)/24/3600
        raise ValueError(&#34;could not convert input to duration&#34;)

    def _scale(maxfreq=None):
        if maxfreq == &#39;year&#39;:
            return 356.2425, &#39;year&#39;
        if maxfreq == &#39;month&#39;:
            return 30.4369, &#39;month&#39;
        if maxfreq == None or maxfreq == &#39;day&#39;:
            return 1, &#39;day&#39;
        if maxfreq == &#39;hour&#39;:
            return 1/24, &#39;hour&#39;
        if maxfreq == &#39;minute&#39;:
            return 1/24/60, &#39;minute&#39;
        if maxfreq == &#39;second&#39;:
            return 1/24/3600, &#39;second&#39;

class FormatDateTime:
    &#34;&#34;&#34;
    FormatDateTime is a formatter that takes date and time values as input, such as &#39;2019-03-01 12:30&#39;, and stores values internally as seconds since 1970-01-01.
    &#34;&#34;&#34;
    def _format(val):
        return datetime.datetime.utcfromtimestamp(val).strftime(&#39;%Y-%m-%d %H:%M&#39;)

    def _parse(val, loc=None):
        try:
            return (dateutil.parser.parse(val) - datetime.datetime(1970,1,1)).total_seconds()
        except ValueError:
            if loc == None:
                raise ValueError(&#34;could not convert input to datetime&#34;)
            else:
                raise ValueError(&#34;could not convert input to datetime at %s&#34; % (loc))

    def _parse_duration(val):
        if isinstance(val, int):
            return val
        if isinstance(val, str):
            return _parse_duration_to_sec(val)
        raise ValueError(&#34;could not convert input to duration&#34;)

    def _scale(maxfreq=None):
        if maxfreq == &#39;year&#39;:
            return 3600*24*356.2425, &#39;year&#39;
        if maxfreq == &#39;month&#39;:
            return 3600*24*30.4369, &#39;month&#39;
        if maxfreq == &#39;day&#39;:
            return 3600*24, &#39;day&#39;
        if maxfreq == &#39;hour&#39;:
            return 3600, &#39;hour&#39;
        if maxfreq == &#39;minute&#39;:
            return 60, &#39;minute&#39;
        if maxfreq == None or maxfreq == &#39;second&#39;:
            return 1, &#39;second&#39;

class TransformDetrend:
    &#34;&#34;&#34;
    TransformDetrend is a transformer that detrends the data.

    TODO : add regression or other order polinomial.
    &#34;&#34;&#34;
    def __init__(self, data):
        if data.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        self.coef = np.polyfit(data.X[:,0], data.Y, 2)
        # reg = Ridge(alpha=0.1, fit_intercept=True)
        # reg.fit(data.X, data.Y)
        # self.trend = reg

    def _forward(self, x, y):
        return y - np.polyval(self.coef, x[:, 0])
        # return y - self.trend.predict(x)
    
    def _backward(self, x, y):
        return y + np.polyval(self.coef, x[:, 0])
        # return y + self.trend.predict(x)

class TransformNormalize:
    &#34;&#34;&#34;
    TransformNormalize is a transformer that normalizes the data, so that all Y data is between 0 and 1.
    &#34;&#34;&#34;
    def __init__(self, data):
        self.ymin = np.amin([self.ymin, np.amin(self.Y)])
        self.ymax = np.amax([self.ymax, np.amax(self.Y)])

    def _forward(self, x, y):
        return (y-self.ymin)/(self.ymax-self.ymin)
    
    def _backward(self, x, y):
        return y*(self.ymax-self.ymin)+self.ymin

class TransformLog:
    &#34;&#34;&#34;
    TransformLog is a transformer that takes the log of the data. Make sure there is no negative data.
    &#34;&#34;&#34;
    def _forward(x, y):
        return np.log(y)
    
    def _backward(x, y):
        return np.exp(y)

def LoadFunction(f, start, end, n, var=0.0, name=None, random=False):
    &#34;&#34;&#34;
    LoadFunction loads a dataset from a given function y = f(x) + N(0,var). It will pick n data points between start and end for x, for which f is being evaluated. By default the n points are spread equally over the interval, with random=True they will be picked randomly.

    The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.

    Args:
        f (function): Function taking x with shape (n,input_dims) and returning shape (n) as y.
        n (int): Number of data points to pick between start and end.
        start (float,list): Define start of interval.
        end (float,list): Define end of interval.
        var (float,optional): Variance added to the output.
        name (str,optional): Name of dataset.
        random (boolean): Select points randomly between start and end (defaults to False).

    Returns:
        Data: The dataset.

    Examples:
        &gt;&gt;&gt; LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &lt;mogptk.data.Data at ...&gt;
    &#34;&#34;&#34;
    # TODO: make work for multiple input dimensions, take n as a list

    start = _normalize_input_dims(start, None)
    input_dims = len(start)
    if input_dims != 1:
        raise ValueError(&#34;can only load function with one dimensional input data&#34;)
    
    end = _normalize_input_dims(end, input_dims)
    _check_function(f, input_dims)

    x = np.empty((n, input_dims))
    for i in range(input_dims):
        if start[i] &gt;= end[i]:
            if input_dims == 1:
                raise ValueError(&#34;start must be lower than end&#34;)
            else:
                raise ValueError(&#34;start must be lower than end for input dimension %d&#34; % (i))

        if random:
            x[:,i] = np.random.uniform(start[i], end[i], n)
        else:
            x[:,i] = np.linspace(start[i], end[i], n)

    y = f(x)
    if y.ndim == 2 and y.shape[1] == 1:
        y = y[:,0]
    y += np.random.normal(0.0, var, n)

    data = Data(x, y, name=name)
    data.set_function(f)
    return data

def LoadCSV(filename, x_cols, y_col, name=None, format={}, filter=None, **kwargs):
    &#34;&#34;&#34;
    LoadCSV loads a dataset from a given CSV file. It loads in x_cols as the names of the input dimension columns, and y_col the name of the output column. Setting a formatter for a column will enable parsing for example date fields such as &#39;2019-03-01&#39;. A filter can be set to filter out data from the CSV, such as ensuring that another column has a certain value.

    Args:
        filename (str): CSV filename.
        x_cols (str, list): Name or names of X column(s) in CSV.
        y_col (str): Name of Y column in CSV.
        name (str,optional): Name of dataset.
        format (dict,optional): Dictionary with x_cols values as keys containing FormatNumber (default), FormatDate, FormetDateTime, ...
        filter (function,optional): Function that takes row as argument, and returns True to keep the record.
        **kwargs: Additional keyword arguments for csv.DictReader.

    Returns:
        Data: The dataset.

    Examples:
        &gt;&gt;&gt; LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, name=&#39;Gold&#39;, format={&#39;Date&#39;: FormatDate}, filter=lambda row: row[&#39;Region&#39;] == &#39;Europe&#39;)
        &lt;mogptk.data.Data at ...&gt;

        &gt;&gt;&gt; LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, delimiter=&#39; &#39;, quotechar=&#39;|&#39;)
        &lt;mogptk.data.Data at ...&gt;
    &#34;&#34;&#34;

    input_dims = 1
    if isinstance(x_cols, list) and all(isinstance(item, str) for item in x_cols):
        input_dims = len(x_cols)
    elif isinstance(x_cols, str):
        x_cols = [x_cols]
    else:
        raise ValueError(&#34;x_cols must be string or list of strings&#34;)
    if not isinstance(y_col, str):
        raise ValueError(&#34;y_col must be string&#34;)

    with open(filename, mode=&#39;r&#39;) as csv_file:
        rows = list(csv.DictReader(csv_file, **kwargs))

        def _to_number(val, row, col):
            try:
                if col in format:
                    return format[col]._parse(val, loc=&#34;row %d column %s&#34; % (row+1, col)), True
                else:
                    return FormatNumber._parse(val, loc=&#34;row %d column %s&#34; % (row+1, col)), True
            except:
                return np.nan, False
        
        X = np.empty((len(rows), input_dims))
        Y = np.empty((len(rows)))
        remove = []
        for j, row in enumerate(rows):
            if filter != None and not filter(row):
                remove.append(j)
                continue

            for i, x_col in enumerate(x_cols):
                X[j,i], ok = _to_number(row[x_col], j+1, x_col)
                if not ok:
                    remove.append(j)

            Y[j], ok = _to_number(row[y_col], j+1, y_col)
            if not ok:
                remove.append(j)

        X = np.delete(X, remove, 0)
        Y = np.delete(Y, remove, 0)

        fmts = []
        for x_col in x_cols:
            if x_col in format:
                fmts.append(format[x_col])
            else:
                fmts.append(FormatNumber)

        data = Data(X, Y, name=name, format=fmts)
        data.set_labels(x_col, y_col)
        return data

class Data:
    def __init__(self, X, Y, name=&#39;&#39;, format=None):
        &#34;&#34;&#34;
        Data class holds all the observations, latent functions and prediction data.

        This class takes the data raw, but you can load data also conveniently using
        LoadFunction, LoadCSV, LoadDataFrame, etc. This class allows to modify the data before being passed into the model.
        Examples are transforming data, such as detrending or taking the log, removing data range to simulate sensor failure,
        and aggregating data for given spans on X, such as aggregating daily data into
        weekly data. Additionally, we also use this class to set the range we want to predict.

        Args:
            X (list,ndarray): Independent variable data of shape (n) or (n,input_dims).
            Y (list,ndarray): Dependent variable data of shape (n).
            name (str,optional): Name of dataset.
            format (list,optional): List of formatters (such as FormatNumber (default), FormatDate,
                FormetDateTime, ...) for each input dimension.

        Examples:
            &gt;&gt;&gt; Data([0, 1, 2, 3], [4, 3, 5, 6])
            &lt;mogptk.data.Data at ...&gt;
        &#34;&#34;&#34;

        if isinstance(X, list):
            X = np.array(X)
        if isinstance(Y, list):
            Y = np.array(Y)
        if not isinstance(X, np.ndarray) or not isinstance(Y, np.ndarray):
            raise ValueError(&#34;X and Y must be lists or numpy arrays&#34;)

        if X.ndim == 1:
            X = X.reshape(-1, 1)
        if X.ndim != 2:
            raise ValueError(&#34;X must be either a one or two dimensional array of data&#34;)
        if Y.ndim != 1:
            raise ValueError(&#34;Y must be a one dimensional array of data&#34;)
        if X.shape[0] != Y.shape[0]:
            raise ValueError(&#34;X and Y must be of the same length&#34;)
        
        n = X.shape[0]
        input_dims = X.shape[1]

        if format == None:
            format = [FormatNumber] * input_dims
        if not isinstance(format, list):
            format = [format]
        if len(format) != input_dims:
            raise ValueError(&#34;format must be defined for all input dimensions&#34;)

        # sort on X for single input dimensions
        if input_dims == 1:
            ind = np.argsort(X, axis=0)
            X = np.take_along_axis(X, ind, axis=0)
            Y = np.take_along_axis(Y, ind[:,0], axis=0)
        
        self.name = name
        self.X = X # shape (n, input_dims)
        self.Y = Y # shape (n)
        self.mask = np.array([True] * n)
        self.F = None
        self.X_pred = np.array([])
        self.Y_mu_pred = np.array([])
        self.Y_var_pred = np.array([])

        self.input_label = [&#39;&#39;] * input_dims
        self.output_label = &#39;&#39;
        self.formatters = format
        self.transformations = []

    def __str__(self):
        return &#34;x=%s\ny=%s&#34; % (self.X.tolist(), self.Y.tolist())

    def _encode(self):
        return str(dill.dumps(self))

    def _decode(d):
        return dill.loads(eval(d))

    def set_name(self, name):
        &#34;&#34;&#34;
        Set name for dataset.

        Args:
            name (str): Name of dataset.
        &#34;&#34;&#34;
        self.name = name

    def set_labels(self, input, output):
        &#34;&#34;&#34;
        Set axes labels for plots.

        Args:
            input (list,str): Independent variable name for each input dimension.
            output (str): Dependent variable name for output dimension.

        Examples:
            &gt;&gt;&gt; data.set_labels([&#39;X&#39;, &#39;Y&#39;], &#39;Cd&#39;)
        &#34;&#34;&#34;
        if isinstance(input, str):
            input = [input]
        elif not isinstance(input, list) or not all(isinstance(item, str) for item in input):
            raise ValueError(&#34;input labels must be list of strings&#34;)
        if not isinstance(output, str):
            raise ValueError(&#34;output label must be string&#34;)
        if len(input) != self.get_input_dims():
            raise ValueError(&#34;input labels must have the same input dimensions as the data&#34;)

        self.input_label = input
        self.output_label = output

    def set_function(self, f):
        &#34;&#34;&#34;
        Set a (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.
    
        The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.

        Args:
            f (function): Function taking x with shape (n,input_dims) and returning shape (n) as y.

        Examples:
            &gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
        &#34;&#34;&#34;
        _check_function(f, self.get_input_dims())
        self.F = f

    def copy(self):
        &#34;&#34;&#34;
        Make a deep copy of the dataset.

        Returns:
            Data: Data.
        &#34;&#34;&#34;
        return copy.deepcopy(self)

    def transform(self, transformer):
        &#34;&#34;&#34;
        Transform the data by using one of the provided transformers, such as TransformDetrend, TransformNormalize, TransformLog, ...

        Args:
            transformer (obj): Transformer object with _forward(x, y) and _backward(x, y) methods.

        Examples:
            &gt;&gt;&gt; import mogptk
            &gt;&gt;&gt; from mogptk import TransformDetrend
            &gt;&gt;&gt; data = mogptk.Data(x, y)
            &gt;&gt;&gt; data.transform(TransformDetrend)
        &#34;&#34;&#34;
        t = transformer
        if &#39;__init__&#39; in vars(transformer):
            t = transformer(self)

        self.Y = t._forward(self.X, self.Y)
        if self.F != None:
            f = self.F
            self.F = lambda x: t._forward(x, f(x))
        self.transformations.append(t)
    
    def filter(self, start, end):
        &#34;&#34;&#34;
        Filter the data range to be between start and end. Start and end can be strings if a proper formatter is set for the independent variable.

        Args:
            start (float,str): Start of interval.
            end (float,str): End of interval.

        Examples:
            &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.filter(3, 8)
        
            &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
            &gt;&gt;&gt; data.filter(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise ValueError(&#34;can only filter on one dimensional input data&#34;)
        
        cstart = self.formatters[0]._parse(start)
        cend = self.formatters[0]._parse(end)
        ind = (self.X[:,0] &gt;= cstart) &amp; (self.X[:,0] &lt; cend)

        self.X = np.expand_dims(self.X[ind,0], 1)
        self.Y = self.Y[ind]
        self.mask = self.mask[ind]

    def aggregate(self, duration, f=np.mean):
        &#34;&#34;&#34;
        Aggregate the data by duration and apply a function to obtain a reduced dataset.

        For example, group daily data by week and take the mean.
        The duration can be set as a number which defined the intervals on the X axis,
        or by a string written in the duration format with:
        y=year, M=month, w=week, d=day, h=hour, m=minute, and s=second.
        For example, 3w1d means three weeks and one day, ie. 22 days, or 6M to mean six months.
        If using a number, be aware that when using FormatDate your X data is denoted per day,
        while with FormatDateTime it is per second.

        Args:
            duration (float,str): Duration along the X axis or as a string in the duration format.
            f (function,optional): Function to use to reduce data, by default uses np.mean.

        Examples:
            &gt;&gt;&gt; data.aggregate(5)

            &gt;&gt;&gt; data.aggregate(&#39;2w&#39;, f=np.sum)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise ValueError(&#34;can only aggregate on one dimensional input data&#34;)
        
        start = self.X[0,0]
        end = self.X[-1,0]
        step = self.formatters[0]._parse_duration(duration)

        X = np.arange(start+step/2, end+step/2, step)
        Y = np.empty((len(X)))
        for i in range(len(X)):
            ind = (self.X[:,0] &gt;= X[i]-step/2) &amp; (self.X[:,0] &lt; X[i]+step/2)
            Y[i] = f(self.Y[ind])

        self.X = np.expand_dims(X, 1)
        self.Y = Y
        self.mask = np.array([True] * len(self.X))

    ################################################################

    def has_removed_obs(self):
        &#34;&#34;&#34;
        Returns True if observations have been removed using the remove_* methods.
        &#34;&#34;&#34;
        return False in self.mask

    def get_input_dims(self):
        &#34;&#34;&#34;
        Returns the number of input dimensions.

        Returns:
            int: Input dimensions.
        &#34;&#34;&#34;
        return self.X.shape[1]

    def get_obs(self):
        &#34;&#34;&#34;
        Returns the observations.

        Returns:
            ndarray: X data of shape (n,input_dims).
            ndarray: Y data of shape (n).
        &#34;&#34;&#34;
        return self.X[self.mask,:], self.Y[self.mask]
    
    def get_all_obs(self):
        &#34;&#34;&#34;
        Returns all observations (including removed observations).

        Returns:
            ndarray: X data of shape (n,input_dims).
            ndarray: Y data of shape (n).
        &#34;&#34;&#34;
        return self.X, self.Y

    def get_del_obs(self):
        &#34;&#34;&#34;
        Returns the removed observations.

        Returns:
            ndarray: X data of shape (n,input_dims).
            ndarray: Y data of shape (n).
        &#34;&#34;&#34;
        return self.X[~self.mask,:], self.Y[~self.mask]

    ################################################################
    
    def remove_randomly(self, n=None, pct=None):
        &#34;&#34;&#34;
        Removes observations randomly on the whole range. Either &#39;n&#39; observations are removed, or a percentage of the observations.

        Args:
            n (int,optional): Number of observations to remove randomly.
            pct (float[0,1],optional): Percentage of observations to remove randomly.

        Examples:
            &gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

            &gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
        &#34;&#34;&#34;
        if n == None:
            if pct == None:
                n = 0
            else:
                n = int(pct * self.X.shape[0])

        idx = np.random.choice(self.X.shape[0], n, replace=False)
        self.mask[idx] = False
    
    def remove_range(self, start=None, end=None):
        &#34;&#34;&#34;
        Removes observations in the interval [start,end]. Start and end can be strings if a proper formatter is set for the independent variable.
        
        Args:
            start (float,str,optional): Start of interval. Defaults to first value in observations.
            end (float,str,optional): End of interval. Defaults to last value in observations.

        Examples:
            &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.remove_range(3, 8)
        
            &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
            &gt;&gt;&gt; data.remove_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        if start == None:
            start = np.min(self.X[:,0])
        else:
            start = self.formatters[0]._parse(start)
        if end == None:
            end = np.max(self.X[:,0])
        else:
            end = self.formatters[0]._parse(end)

        idx = np.where(np.logical_and(self.X[:,0] &gt;= start, self.X[:,0] &lt;= end))
        self.mask[idx] = False
    
    def remove_rel_range(self, start, end):
        &#34;&#34;&#34;
        Removes observations between start and end as a percentage of the number of observations. So &#39;0&#39; is the first observation, &#39;0.5&#39; is the middle observation, and &#39;1&#39; is the last observation.

        Args:
            start (float[0,1]): Start percentage of interval.
            end (float[0,1]): End percentage of interval.
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        x_min = np.min(self.X[:,0])
        x_max = np.max(self.X[:,0])
        start = x_min + np.round(max(0.0, min(1.0, start)) * (x_max-x_min))
        end = x_min + np.round(max(0.0, min(1.0, end)) * (x_max-x_min))

        idx = np.where(np.logical_and(self.X[:,0] &gt;= start, self.X[:,0] &lt;= end))
        self.mask[idx] = False

    def remove_random_ranges(self, n, duration):
        &#34;&#34;&#34;
        Removes a number of ranges to simulate sensor failure.

        Args:
            n (int): Number of ranges to remove.
            duration (float,str): Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).

        Examples:
            &gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

            &gt;&gt;&gt; data.remove_random_ranges(3, &#39;1d&#39;) # remove three ranges that are 1 day wide
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        duration = self.formatters[0]._parse_duration(duration)
        if n &lt; 1 or duration &lt; 1:
            return

        # TODO: what if N != 1 and we have dates on the X-axis? Make sure that ranges do not overlap and are picked randomly
        m = (self.X[-1]-self.X[0]) - n*duration
        if m &lt;= 0:
            raise Exception(&#34;no data left after removing ranges&#34;)

        locs = np.round(np.sort(np.random.rand(n)) * m)
        for i in range(len(locs)):
            loc = int(locs[i] + i * duration)
            idx = np.arange(int(loc), int(loc+duration))
            self.mask[idx] = False
    
    ################################################################

    def set_pred_range(self, start=None, end=None, n=None, step=None):
        &#34;&#34;&#34;
        Sets the prediction range to the interval [start,end] with either &#39;n&#39; points or a given &#39;step&#39; between the points. Start and end can be set as strings and step in the duration string format if the proper formatter is set.

        Args:
            start (float,str,optional): Start of interval, defaults to the first observation.
            end (float,str,optional): End of interval, defaults to the last observation.
            n (int,optional): Number of points to generate in the interval.
            step (float,str,optional): Spacing between points in the interval.

            If neither &#39;step&#39; or &#39;n&#39; is passed, default number of points is 100.

        Examples:
            &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.set_pred_range(3, 8, 200)
        
            &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
            &gt;&gt;&gt; data.set_pred_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;, step=&#39;1d&#39;)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only set prediction range on one dimensional input data&#34;)

        cstart = start
        if cstart == None:
            cstart = self.X[0,:]
        elif isinstance(cstart, list):
            for i in range(self.get_input_dims()):
                cstart[i] = self.formatters[i]._parse(cstart[i])
        else:
            cstart = self.formatters[0]._parse(cstart)

        cend = end
        if cend == None:
            cend = self.X[-1,:]
        elif isinstance(cend, list):
            for i in range(self.get_input_dims()):
                cend[i] = self.formatters[i]._parse(cend[i])
        else:
            cend = self.formatters[0]._parse(cend)
        
        cstart = _normalize_input_dims(cstart, self.get_input_dims())
        cend = _normalize_input_dims(cend, self.get_input_dims())

        # TODO: works for multi input dims?
        if cend &lt;= cstart:
            raise ValueError(&#34;start must be lower than end&#34;)

        # TODO: prediction range for multi input dimension; fix other axes to zero so we can plot?
        if step == None and n != None:
            self.X_pred = np.empty((n, self.get_input_dims()))
            for i in range(self.get_input_dims()):
                self.X_pred[:,i] = np.linspace(cstart[i], cend[i], n)
        else:
            if self.get_input_dims() != 1:
                raise ValueError(&#34;cannot use step for multi dimensional input, use n&#34;)
            cstep = step
            if cstep == None:
                cstep = (cend[0]-cstart[0])/100
            else:
                cstep = self.formatters[0]._parse(cstep)
            self.X_pred = np.arange(cstart[0], cend[0]+cstep, cstep).reshape(-1, 1)
    
    def set_pred(self, x):
        &#34;&#34;&#34;
        Set the prediction range directly.

        Args:
            x (list,np.ndarray): Array of shape (n) or (n,input_dims) with input values to predict at.

        Examples:
            &gt;&gt;&gt; data.set_pred([5.0, 5.5, 6.0, 6.5, 7.0])
        &#34;&#34;&#34;
        if x.ndim != 2 or x.shape[1] != self.get_input_dims():
            raise ValueError(&#34;x shape must be (n,input_dims)&#34;)
        if isinstance(x, list):
            x = np.array(x)
        elif not isinstance(x, np.ndarray):
            raise ValueError(&#34;x expected to be a list or Numpy array&#34;)

        self.X_pred = x

    ################################################################

    def get_nyquist_estimation(self):
        &#34;&#34;&#34;
        Estimate nyquist frequency by taking 0.5/(minimum distance of points).

        Returns:
            ndarray: Nyquist frequency array of shape (input_dims).
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        nyquist = np.empty((input_dims))
        for i in range(self.get_input_dims()):
            x = np.sort(self.X[:,i])
            dist = np.abs(x[1:]-x[:-1]) # TODO: assumes X is sorted, use average distance instead of minimal distance?
            dist = np.min(dist[np.nonzero(dist)])
            nyquist[i] = 0.5/dist
        return nyquist

    def get_bnse_estimation(self, Q=1, n=5000):
        &#34;&#34;&#34;
        Peaks estimation using BNSE (Bayesian Non-parametric Spectral Estimation).

        Args:
            Q (int): Number of peaks to find, defaults to 1.
            n (int): Number of points of the grid to evaluate 
                frequencies, defaults to 5000.

        Returns:
            amplitudes: Amplitude array of shape (input_dims,Q).
            positions: Frequency array of shape (input_dims,Q).
            variances: Variance array of shape (input_dims, Q).
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((input_dims, Q))
        B = np.zeros((input_dims, Q))
        C = np.zeros((input_dims, Q))

        nyquist = self.get_nyquist_estimation()
        for i in range(input_dims):
            x = self.X[:,i]
            y = self.Y
            bnse = bse(x, y)
            bnse.set_freqspace(nyquist[i], dimension=n)
            bnse.train()
            bnse.compute_moments()

            amplitudes, positions, variances = bnse.get_freq_peaks()
            if len(positions) == 0:
                continue

            n = len(positions)
            if n &lt; Q and n != 0:
                # if there not enough peaks, we will repeat them
                j = 0
                while len(positions) &lt; Q:
                    amplitudes = np.append(amplitudes, amplitudes[j])
                    positions = np.append(positions, positions[j])
                    variances = np.append(variances, variances[j])
                    j = (j+1) % n

            A[i,:] = amplitudes[:Q]
            B[i,:] = positions[:Q]
            C[i,:] = variances[:Q]
        return A, B, C

    def get_ls_estimation(self, Q=1, n=50000):
        &#34;&#34;&#34;
        Peak estimation using Lomb Scargle.

        Args:
            Q (int): Number of peaks to find, defaults to 1.
            n (int): Number of points to use for Lomb Scargle, defaults to 50000.

        Returns:
            ndarray: Frequency array of shape (input_dims,Q).
            ndarray: Amplitude array of shape (input_dims,Q).
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((input_dims, Q))
        B = np.zeros((input_dims, Q))
        C = np.zeros((input_dims, Q))

        nyquist = self.get_nyquist_estimation() * 2 * np.pi
        for i in range(input_dims):
            x = np.linspace(0, nyquist[i], n+1)[1:]
            dx = x[1]-x[0]

            y = signal.lombscargle(self.X[:,i], self.Y, x)
            ind, _ = signal.find_peaks(y)
            ind = ind[np.argsort(y[ind])[::-1]] # sort by biggest peak first

            widths, width_heights, _, _ = signal.peak_widths(y, ind, rel_height=0.5)
            widths *= dx / np.pi / 2.0

            positions = x[ind] / np.pi / 2.0
            amplitudes = y[ind]
            variances = widths / np.sqrt(8 * np.log(amplitudes / width_heights)) # from full-width half-maximum to Gaussian sigma

            n = len(positions)
            if n &lt; Q and n != 0:
                # if there not enough peaks, we will repeat them
                j = 0
                while len(positions) &lt; Q:
                    amplitudes = np.append(amplitudes, amplitudes[j])
                    positions = np.append(positions, positions[j])
                    variances = np.append(variances, variances[j])
                    j = (j+1) % n

            A[i,:] = amplitudes[:Q]
            B[i,:] = positions[:Q]
            C[i,:] = variances[:Q]
        return A, B, C
    
    #def get_gm_estimation(self):
    #    # TODO: use sklearn.mixture.GaussianMixture to retrieve fitted gaussian mixtures to spectral data
    #    pass

    def plot(self, title=None, filename=None, show=True):
        &#34;&#34;&#34;
        Plot the data including removed observations, latent function, and predictions.

        Args:
            title (str,optional): Set the title for the plot.
            filename (str,optional): If set, export figure to file.
            show (bool,optional): If True, show the plot immediately.
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise Exception(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise Exception(&#34;two dimensional input data not yet implemented&#34;) # TODO

        fig, axes = plt.subplots(1, 1, figsize=(20, 5), constrained_layout=True, squeeze=False)
        if title != None:
            fig.suptitle(title, fontsize=36)

        plotting_pred = False
        plotting_F = False
        plotting_obs = False

        if self.Y_mu_pred.size != 0:
            lower = self.Y_mu_pred - self.Y_var_pred
            upper = self.Y_mu_pred + self.Y_var_pred
            axes[0,0].plot(self.X_pred[:,0], self.Y_mu_pred, &#39;b-&#39;, lw=3)
            axes[0,0].fill_between(self.X_pred[:,0], lower, upper, color=&#39;b&#39;, alpha=0.1)
            axes[0,0].plot(self.X_pred[:,0], lower, &#39;b-&#39;, lw=1, alpha=0.5)
            axes[0,0].plot(self.X_pred[:,0], upper, &#39;b-&#39;, lw=1, alpha=0.5)
            plotting_pred = True

        if self.F != None:
            n = len(self.X[:,0])*10
            x_min = np.min(self.X[:,0])
            x_max = np.max(self.X[:,0])

            x = np.empty((n, 1))
            x[:,0] = np.linspace(x_min, x_max, n)
            y = self.F(x)

            axes[0,0].plot(x[:,0], y, &#39;r--&#39;, lw=1)
            plotting_F = True

        axes[0,0].plot(self.X[:,0], self.Y, &#39;k-&#39;)

        if self.has_removed_obs():
            X, Y = self.get_obs()
            axes[0,0].plot(X[:,0], Y, &#39;k.&#39;, mew=2, ms=8)
            plotting_obs = True

        axes[0,0].set_xlabel(self.input_label[0])
        axes[0,0].set_ylabel(self.output_label)
        axes[0,0].set_title(self.name, fontsize=30)
        formatter = matplotlib.ticker.FuncFormatter(lambda x,pos: self.formatters[0]._format(x))
        axes[0,0].xaxis.set_major_formatter(formatter)

        # build legend
        if plotting_F or plotting_obs:
            legend = []
            legend.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=&#39;k&#39;, label=&#39;Data&#39;))
            if plotting_F:
                legend.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;r&#39;, label=&#39;Latent function&#39;))
            if plotting_obs:
                legend.append(plt.Line2D([0], [0], ls=&#39;&#39;, marker=&#39;.&#39;, color=&#39;k&#39;, mew=2, ms=8, label=&#39;Training&#39;))
            if plotting_pred:
                legend.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=&#39;b&#39;, lw=3, label=&#39;Prediction&#39;))
            plt.legend(handles=legend, loc=&#39;best&#39;)

        if filename != None:
            plt.savefig(filename+&#39;.pdf&#39;, dpi=300)
        if show:
            plt.show()

    def plot_spectrum(self, method=&#39;lombscargle&#39;, angularfreq=False, per=None, maxfreq=None, title=None, filename=None, show=True):
        &#34;&#34;&#34;
        Plot the spectrum of the data.

        TODO: Add BNSE as spectrum estimate option.

        Args:
            method (str,optional): Set the method to get the spectrum such as &#39;lombscargle&#39;.
            angularfreq (bool,optional): Use angular frequencies.
            per (float,str): Set the scale of the X axis depending on the formatter used, eg. per=5 or per=&#39;3d&#39; for three days.
            maxfreq (float,optional): Maximum frequency to plot, otherwise the Nyquist frequency is used.
            title (str,optional): Set the title for the plot.
            filename (str,optional): If set, export figure to file.
            show (bool,optional): If True, show the plot immediately.
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise Exception(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise Exception(&#34;two dimensional input data not yet implemented&#34;) # TODO

        # sns.set(font_scale=2)
        # sns.axes_style(&#34;darkgrid&#34;)
        # sns.set_style(&#34;whitegrid&#34;)

        fig, axes = plt.subplots(1, 1, figsize=(20, 5), constrained_layout=True, squeeze=False)
        if title != None:
            fig.suptitle(title, fontsize=36)

        X_space = self.X[:,0].copy()

        formatter = self.formatters[0]
        factor, name = formatter._scale(per)
        if name != None:
            axes[0,0].set_xlabel(&#39;Frequency (1/&#39;+name+&#39;)&#39;)
        else:
            axes[0,0].set_xlabel(&#39;Frequency&#39;)

        if not angularfreq:
            X_space *= 2 * np.pi
        X_space /= factor

        freq = maxfreq
        if freq == None:
            dist = np.abs(X_space[1:]-X_space[:-1])
            freq = 1/np.average(dist)

        X = np.linspace(0.0, freq, 10001)[1:]
        if method == &#39;lombscargle&#39;:
            Y = signal.lombscargle(X_space, self.Y, X)
        else:
            raise ValueError(&#39;periodogram method &#34;%s&#34; does not exist&#39; % (method))

        axes[0,0].plot(X, Y, &#39;k-&#39;)
        axes[0,0].set_title(self.name + &#39; spectrum&#39;, fontsize=30)
        axes[0,0].set_yticks([])
        axes[0,0].set_ylim(0, None)

        if filename != None:
            plt.savefig(filename+&#39;.pdf&#39;, dpi=300)
        if show:
            plt.show()

        return axes[0, 0]

def _check_function(f, input_dims):
    if not inspect.isfunction(f):
        raise ValueError(&#34;function must take X as a parameter&#34;)

    sig = inspect.signature(f)
    if not len(sig.parameters) == 1:
        raise ValueError(&#34;function must take X as a parameter&#34;)

    x = np.ones((1, input_dims))
    y = f(x)
    if len(y.shape) != 1 or y.shape[0] != 1:
        raise ValueError(&#34;function must return Y with shape (n), note that X has shape (n,input_dims)&#34;)

def _normalize_input_dims(x, input_dims):
    if x == None:
        return x
    if isinstance(x, float):
        x = [x]
    elif isinstance(x, int):
        x = [float(x)]
    elif isinstance(x, str):
        x = [x]
    elif isinstance(x, np.ndarray):
        x = list(x)
    elif not isinstance(x, list):
        raise ValueError(&#34;input should be a floating point, list or ndarray&#34;)
    if input_dims != None and len(x) != input_dims:
        raise ValueError(&#34;input must be a scalar for single-dimension input or a list of values for each input dimension&#34;)
    return x</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mogptk.data.LoadCSV"><code class="name flex">
<span>def <span class="ident">LoadCSV</span></span>(<span>filename, x_cols, y_col, name=None, format={}, filter=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>LoadCSV loads a dataset from a given CSV file. It loads in x_cols as the names of the input dimension columns, and y_col the name of the output column. Setting a formatter for a column will enable parsing for example date fields such as '2019-03-01'. A filter can be set to filter out data from the CSV, such as ensuring that another column has a certain value.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>CSV filename.</dd>
<dt><strong><code>x_cols</code></strong> :&ensp;<code>str</code>, <code>list</code></dt>
<dd>Name or names of X column(s) in CSV.</dd>
<dt><strong><code>y_col</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of Y column in CSV.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>Name of dataset.</dd>
<dt><strong><code>format</code></strong> :&ensp;<code>dict</code>,optional</dt>
<dd>Dictionary with x_cols values as keys containing FormatNumber (default), FormatDate, FormetDateTime, &hellip;</dd>
<dt><strong><code>filter</code></strong> :&ensp;<code>function</code>,optional</dt>
<dd>Function that takes row as argument, and returns True to keep the record.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Additional keyword arguments for csv.DictReader.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="mogptk.data.Data" href="#mogptk.data.Data"><code>Data</code></a></strong></dt>
<dd>The dataset.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; LoadCSV('gold.csv', 'Date', 'Price', name='Gold', format={'Date': FormatDate}, filter=lambda row: row['Region'] == 'Europe')
&lt;mogptk.data.Data at ...&gt;

&gt;&gt;&gt; LoadCSV('gold.csv', 'Date', 'Price', delimiter=' ', quotechar='|')
&lt;mogptk.data.Data at ...&gt;
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def LoadCSV(filename, x_cols, y_col, name=None, format={}, filter=None, **kwargs):
    &#34;&#34;&#34;
    LoadCSV loads a dataset from a given CSV file. It loads in x_cols as the names of the input dimension columns, and y_col the name of the output column. Setting a formatter for a column will enable parsing for example date fields such as &#39;2019-03-01&#39;. A filter can be set to filter out data from the CSV, such as ensuring that another column has a certain value.

    Args:
        filename (str): CSV filename.
        x_cols (str, list): Name or names of X column(s) in CSV.
        y_col (str): Name of Y column in CSV.
        name (str,optional): Name of dataset.
        format (dict,optional): Dictionary with x_cols values as keys containing FormatNumber (default), FormatDate, FormetDateTime, ...
        filter (function,optional): Function that takes row as argument, and returns True to keep the record.
        **kwargs: Additional keyword arguments for csv.DictReader.

    Returns:
        Data: The dataset.

    Examples:
        &gt;&gt;&gt; LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, name=&#39;Gold&#39;, format={&#39;Date&#39;: FormatDate}, filter=lambda row: row[&#39;Region&#39;] == &#39;Europe&#39;)
        &lt;mogptk.data.Data at ...&gt;

        &gt;&gt;&gt; LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, delimiter=&#39; &#39;, quotechar=&#39;|&#39;)
        &lt;mogptk.data.Data at ...&gt;
    &#34;&#34;&#34;

    input_dims = 1
    if isinstance(x_cols, list) and all(isinstance(item, str) for item in x_cols):
        input_dims = len(x_cols)
    elif isinstance(x_cols, str):
        x_cols = [x_cols]
    else:
        raise ValueError(&#34;x_cols must be string or list of strings&#34;)
    if not isinstance(y_col, str):
        raise ValueError(&#34;y_col must be string&#34;)

    with open(filename, mode=&#39;r&#39;) as csv_file:
        rows = list(csv.DictReader(csv_file, **kwargs))

        def _to_number(val, row, col):
            try:
                if col in format:
                    return format[col]._parse(val, loc=&#34;row %d column %s&#34; % (row+1, col)), True
                else:
                    return FormatNumber._parse(val, loc=&#34;row %d column %s&#34; % (row+1, col)), True
            except:
                return np.nan, False
        
        X = np.empty((len(rows), input_dims))
        Y = np.empty((len(rows)))
        remove = []
        for j, row in enumerate(rows):
            if filter != None and not filter(row):
                remove.append(j)
                continue

            for i, x_col in enumerate(x_cols):
                X[j,i], ok = _to_number(row[x_col], j+1, x_col)
                if not ok:
                    remove.append(j)

            Y[j], ok = _to_number(row[y_col], j+1, y_col)
            if not ok:
                remove.append(j)

        X = np.delete(X, remove, 0)
        Y = np.delete(Y, remove, 0)

        fmts = []
        for x_col in x_cols:
            if x_col in format:
                fmts.append(format[x_col])
            else:
                fmts.append(FormatNumber)

        data = Data(X, Y, name=name, format=fmts)
        data.set_labels(x_col, y_col)
        return data</code></pre>
</details>
</dd>
<dt id="mogptk.data.LoadFunction"><code class="name flex">
<span>def <span class="ident">LoadFunction</span></span>(<span>f, start, end, n, var=0.0, name=None, random=False)</span>
</code></dt>
<dd>
<section class="desc"><p>LoadFunction loads a dataset from a given function y = f(x) + N(0,var). It will pick n data points between start and end for x, for which f is being evaluated. By default the n points are spread equally over the interval, with random=True they will be picked randomly.</p>
<p>The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>function</code></dt>
<dd>Function taking x with shape (n,input_dims) and returning shape (n) as y.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of data points to pick between start and end.</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code>,<code>list</code></dt>
<dd>Define start of interval.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code>,<code>list</code></dt>
<dd>Define end of interval.</dd>
<dt><strong><code>var</code></strong> :&ensp;<code>float</code>,optional</dt>
<dd>Variance added to the output.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>Name of dataset.</dd>
<dt><strong><code>random</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Select points randomly between start and end (defaults to False).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="mogptk.data.Data" href="#mogptk.data.Data"><code>Data</code></a></strong></dt>
<dd>The dataset.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&lt;mogptk.data.Data at ...&gt;
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def LoadFunction(f, start, end, n, var=0.0, name=None, random=False):
    &#34;&#34;&#34;
    LoadFunction loads a dataset from a given function y = f(x) + N(0,var). It will pick n data points between start and end for x, for which f is being evaluated. By default the n points are spread equally over the interval, with random=True they will be picked randomly.

    The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.

    Args:
        f (function): Function taking x with shape (n,input_dims) and returning shape (n) as y.
        n (int): Number of data points to pick between start and end.
        start (float,list): Define start of interval.
        end (float,list): Define end of interval.
        var (float,optional): Variance added to the output.
        name (str,optional): Name of dataset.
        random (boolean): Select points randomly between start and end (defaults to False).

    Returns:
        Data: The dataset.

    Examples:
        &gt;&gt;&gt; LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &lt;mogptk.data.Data at ...&gt;
    &#34;&#34;&#34;
    # TODO: make work for multiple input dimensions, take n as a list

    start = _normalize_input_dims(start, None)
    input_dims = len(start)
    if input_dims != 1:
        raise ValueError(&#34;can only load function with one dimensional input data&#34;)
    
    end = _normalize_input_dims(end, input_dims)
    _check_function(f, input_dims)

    x = np.empty((n, input_dims))
    for i in range(input_dims):
        if start[i] &gt;= end[i]:
            if input_dims == 1:
                raise ValueError(&#34;start must be lower than end&#34;)
            else:
                raise ValueError(&#34;start must be lower than end for input dimension %d&#34; % (i))

        if random:
            x[:,i] = np.random.uniform(start[i], end[i], n)
        else:
            x[:,i] = np.linspace(start[i], end[i], n)

    y = f(x)
    if y.ndim == 2 and y.shape[1] == 1:
        y = y[:,0]
    y += np.random.normal(0.0, var, n)

    data = Data(x, y, name=name)
    data.set_function(f)
    return data</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mogptk.data.Data"><code class="flex name class">
<span>class <span class="ident">Data</span></span>
<span>(</span><span>X, Y, name='', format=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Data class holds all the observations, latent functions and prediction data.</p>
<p>This class takes the data raw, but you can load data also conveniently using
LoadFunction, LoadCSV, LoadDataFrame, etc. This class allows to modify the data before being passed into the model.
Examples are transforming data, such as detrending or taking the log, removing data range to simulate sensor failure,
and aggregating data for given spans on X, such as aggregating daily data into
weekly data. Additionally, we also use this class to set the range we want to predict.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list</code>,<code>ndarray</code></dt>
<dd>Independent variable data of shape (n) or (n,input_dims).</dd>
<dt><strong><code>Y</code></strong> :&ensp;<code>list</code>,<code>ndarray</code></dt>
<dd>Dependent variable data of shape (n).</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>Name of dataset.</dd>
<dt><strong><code>format</code></strong> :&ensp;<code>list</code>,optional</dt>
<dd>List of formatters (such as FormatNumber (default), FormatDate,
FormetDateTime, &hellip;) for each input dimension.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; Data([0, 1, 2, 3], [4, 3, 5, 6])
&lt;mogptk.data.Data at ...&gt;
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class Data:
    def __init__(self, X, Y, name=&#39;&#39;, format=None):
        &#34;&#34;&#34;
        Data class holds all the observations, latent functions and prediction data.

        This class takes the data raw, but you can load data also conveniently using
        LoadFunction, LoadCSV, LoadDataFrame, etc. This class allows to modify the data before being passed into the model.
        Examples are transforming data, such as detrending or taking the log, removing data range to simulate sensor failure,
        and aggregating data for given spans on X, such as aggregating daily data into
        weekly data. Additionally, we also use this class to set the range we want to predict.

        Args:
            X (list,ndarray): Independent variable data of shape (n) or (n,input_dims).
            Y (list,ndarray): Dependent variable data of shape (n).
            name (str,optional): Name of dataset.
            format (list,optional): List of formatters (such as FormatNumber (default), FormatDate,
                FormetDateTime, ...) for each input dimension.

        Examples:
            &gt;&gt;&gt; Data([0, 1, 2, 3], [4, 3, 5, 6])
            &lt;mogptk.data.Data at ...&gt;
        &#34;&#34;&#34;

        if isinstance(X, list):
            X = np.array(X)
        if isinstance(Y, list):
            Y = np.array(Y)
        if not isinstance(X, np.ndarray) or not isinstance(Y, np.ndarray):
            raise ValueError(&#34;X and Y must be lists or numpy arrays&#34;)

        if X.ndim == 1:
            X = X.reshape(-1, 1)
        if X.ndim != 2:
            raise ValueError(&#34;X must be either a one or two dimensional array of data&#34;)
        if Y.ndim != 1:
            raise ValueError(&#34;Y must be a one dimensional array of data&#34;)
        if X.shape[0] != Y.shape[0]:
            raise ValueError(&#34;X and Y must be of the same length&#34;)
        
        n = X.shape[0]
        input_dims = X.shape[1]

        if format == None:
            format = [FormatNumber] * input_dims
        if not isinstance(format, list):
            format = [format]
        if len(format) != input_dims:
            raise ValueError(&#34;format must be defined for all input dimensions&#34;)

        # sort on X for single input dimensions
        if input_dims == 1:
            ind = np.argsort(X, axis=0)
            X = np.take_along_axis(X, ind, axis=0)
            Y = np.take_along_axis(Y, ind[:,0], axis=0)
        
        self.name = name
        self.X = X # shape (n, input_dims)
        self.Y = Y # shape (n)
        self.mask = np.array([True] * n)
        self.F = None
        self.X_pred = np.array([])
        self.Y_mu_pred = np.array([])
        self.Y_var_pred = np.array([])

        self.input_label = [&#39;&#39;] * input_dims
        self.output_label = &#39;&#39;
        self.formatters = format
        self.transformations = []

    def __str__(self):
        return &#34;x=%s\ny=%s&#34; % (self.X.tolist(), self.Y.tolist())

    def _encode(self):
        return str(dill.dumps(self))

    def _decode(d):
        return dill.loads(eval(d))

    def set_name(self, name):
        &#34;&#34;&#34;
        Set name for dataset.

        Args:
            name (str): Name of dataset.
        &#34;&#34;&#34;
        self.name = name

    def set_labels(self, input, output):
        &#34;&#34;&#34;
        Set axes labels for plots.

        Args:
            input (list,str): Independent variable name for each input dimension.
            output (str): Dependent variable name for output dimension.

        Examples:
            &gt;&gt;&gt; data.set_labels([&#39;X&#39;, &#39;Y&#39;], &#39;Cd&#39;)
        &#34;&#34;&#34;
        if isinstance(input, str):
            input = [input]
        elif not isinstance(input, list) or not all(isinstance(item, str) for item in input):
            raise ValueError(&#34;input labels must be list of strings&#34;)
        if not isinstance(output, str):
            raise ValueError(&#34;output label must be string&#34;)
        if len(input) != self.get_input_dims():
            raise ValueError(&#34;input labels must have the same input dimensions as the data&#34;)

        self.input_label = input
        self.output_label = output

    def set_function(self, f):
        &#34;&#34;&#34;
        Set a (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.
    
        The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.

        Args:
            f (function): Function taking x with shape (n,input_dims) and returning shape (n) as y.

        Examples:
            &gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
        &#34;&#34;&#34;
        _check_function(f, self.get_input_dims())
        self.F = f

    def copy(self):
        &#34;&#34;&#34;
        Make a deep copy of the dataset.

        Returns:
            Data: Data.
        &#34;&#34;&#34;
        return copy.deepcopy(self)

    def transform(self, transformer):
        &#34;&#34;&#34;
        Transform the data by using one of the provided transformers, such as TransformDetrend, TransformNormalize, TransformLog, ...

        Args:
            transformer (obj): Transformer object with _forward(x, y) and _backward(x, y) methods.

        Examples:
            &gt;&gt;&gt; import mogptk
            &gt;&gt;&gt; from mogptk import TransformDetrend
            &gt;&gt;&gt; data = mogptk.Data(x, y)
            &gt;&gt;&gt; data.transform(TransformDetrend)
        &#34;&#34;&#34;
        t = transformer
        if &#39;__init__&#39; in vars(transformer):
            t = transformer(self)

        self.Y = t._forward(self.X, self.Y)
        if self.F != None:
            f = self.F
            self.F = lambda x: t._forward(x, f(x))
        self.transformations.append(t)
    
    def filter(self, start, end):
        &#34;&#34;&#34;
        Filter the data range to be between start and end. Start and end can be strings if a proper formatter is set for the independent variable.

        Args:
            start (float,str): Start of interval.
            end (float,str): End of interval.

        Examples:
            &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.filter(3, 8)
        
            &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
            &gt;&gt;&gt; data.filter(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise ValueError(&#34;can only filter on one dimensional input data&#34;)
        
        cstart = self.formatters[0]._parse(start)
        cend = self.formatters[0]._parse(end)
        ind = (self.X[:,0] &gt;= cstart) &amp; (self.X[:,0] &lt; cend)

        self.X = np.expand_dims(self.X[ind,0], 1)
        self.Y = self.Y[ind]
        self.mask = self.mask[ind]

    def aggregate(self, duration, f=np.mean):
        &#34;&#34;&#34;
        Aggregate the data by duration and apply a function to obtain a reduced dataset.

        For example, group daily data by week and take the mean.
        The duration can be set as a number which defined the intervals on the X axis,
        or by a string written in the duration format with:
        y=year, M=month, w=week, d=day, h=hour, m=minute, and s=second.
        For example, 3w1d means three weeks and one day, ie. 22 days, or 6M to mean six months.
        If using a number, be aware that when using FormatDate your X data is denoted per day,
        while with FormatDateTime it is per second.

        Args:
            duration (float,str): Duration along the X axis or as a string in the duration format.
            f (function,optional): Function to use to reduce data, by default uses np.mean.

        Examples:
            &gt;&gt;&gt; data.aggregate(5)

            &gt;&gt;&gt; data.aggregate(&#39;2w&#39;, f=np.sum)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise ValueError(&#34;can only aggregate on one dimensional input data&#34;)
        
        start = self.X[0,0]
        end = self.X[-1,0]
        step = self.formatters[0]._parse_duration(duration)

        X = np.arange(start+step/2, end+step/2, step)
        Y = np.empty((len(X)))
        for i in range(len(X)):
            ind = (self.X[:,0] &gt;= X[i]-step/2) &amp; (self.X[:,0] &lt; X[i]+step/2)
            Y[i] = f(self.Y[ind])

        self.X = np.expand_dims(X, 1)
        self.Y = Y
        self.mask = np.array([True] * len(self.X))

    ################################################################

    def has_removed_obs(self):
        &#34;&#34;&#34;
        Returns True if observations have been removed using the remove_* methods.
        &#34;&#34;&#34;
        return False in self.mask

    def get_input_dims(self):
        &#34;&#34;&#34;
        Returns the number of input dimensions.

        Returns:
            int: Input dimensions.
        &#34;&#34;&#34;
        return self.X.shape[1]

    def get_obs(self):
        &#34;&#34;&#34;
        Returns the observations.

        Returns:
            ndarray: X data of shape (n,input_dims).
            ndarray: Y data of shape (n).
        &#34;&#34;&#34;
        return self.X[self.mask,:], self.Y[self.mask]
    
    def get_all_obs(self):
        &#34;&#34;&#34;
        Returns all observations (including removed observations).

        Returns:
            ndarray: X data of shape (n,input_dims).
            ndarray: Y data of shape (n).
        &#34;&#34;&#34;
        return self.X, self.Y

    def get_del_obs(self):
        &#34;&#34;&#34;
        Returns the removed observations.

        Returns:
            ndarray: X data of shape (n,input_dims).
            ndarray: Y data of shape (n).
        &#34;&#34;&#34;
        return self.X[~self.mask,:], self.Y[~self.mask]

    ################################################################
    
    def remove_randomly(self, n=None, pct=None):
        &#34;&#34;&#34;
        Removes observations randomly on the whole range. Either &#39;n&#39; observations are removed, or a percentage of the observations.

        Args:
            n (int,optional): Number of observations to remove randomly.
            pct (float[0,1],optional): Percentage of observations to remove randomly.

        Examples:
            &gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

            &gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
        &#34;&#34;&#34;
        if n == None:
            if pct == None:
                n = 0
            else:
                n = int(pct * self.X.shape[0])

        idx = np.random.choice(self.X.shape[0], n, replace=False)
        self.mask[idx] = False
    
    def remove_range(self, start=None, end=None):
        &#34;&#34;&#34;
        Removes observations in the interval [start,end]. Start and end can be strings if a proper formatter is set for the independent variable.
        
        Args:
            start (float,str,optional): Start of interval. Defaults to first value in observations.
            end (float,str,optional): End of interval. Defaults to last value in observations.

        Examples:
            &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.remove_range(3, 8)
        
            &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
            &gt;&gt;&gt; data.remove_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        if start == None:
            start = np.min(self.X[:,0])
        else:
            start = self.formatters[0]._parse(start)
        if end == None:
            end = np.max(self.X[:,0])
        else:
            end = self.formatters[0]._parse(end)

        idx = np.where(np.logical_and(self.X[:,0] &gt;= start, self.X[:,0] &lt;= end))
        self.mask[idx] = False
    
    def remove_rel_range(self, start, end):
        &#34;&#34;&#34;
        Removes observations between start and end as a percentage of the number of observations. So &#39;0&#39; is the first observation, &#39;0.5&#39; is the middle observation, and &#39;1&#39; is the last observation.

        Args:
            start (float[0,1]): Start percentage of interval.
            end (float[0,1]): End percentage of interval.
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        x_min = np.min(self.X[:,0])
        x_max = np.max(self.X[:,0])
        start = x_min + np.round(max(0.0, min(1.0, start)) * (x_max-x_min))
        end = x_min + np.round(max(0.0, min(1.0, end)) * (x_max-x_min))

        idx = np.where(np.logical_and(self.X[:,0] &gt;= start, self.X[:,0] &lt;= end))
        self.mask[idx] = False

    def remove_random_ranges(self, n, duration):
        &#34;&#34;&#34;
        Removes a number of ranges to simulate sensor failure.

        Args:
            n (int): Number of ranges to remove.
            duration (float,str): Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).

        Examples:
            &gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

            &gt;&gt;&gt; data.remove_random_ranges(3, &#39;1d&#39;) # remove three ranges that are 1 day wide
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        duration = self.formatters[0]._parse_duration(duration)
        if n &lt; 1 or duration &lt; 1:
            return

        # TODO: what if N != 1 and we have dates on the X-axis? Make sure that ranges do not overlap and are picked randomly
        m = (self.X[-1]-self.X[0]) - n*duration
        if m &lt;= 0:
            raise Exception(&#34;no data left after removing ranges&#34;)

        locs = np.round(np.sort(np.random.rand(n)) * m)
        for i in range(len(locs)):
            loc = int(locs[i] + i * duration)
            idx = np.arange(int(loc), int(loc+duration))
            self.mask[idx] = False
    
    ################################################################

    def set_pred_range(self, start=None, end=None, n=None, step=None):
        &#34;&#34;&#34;
        Sets the prediction range to the interval [start,end] with either &#39;n&#39; points or a given &#39;step&#39; between the points. Start and end can be set as strings and step in the duration string format if the proper formatter is set.

        Args:
            start (float,str,optional): Start of interval, defaults to the first observation.
            end (float,str,optional): End of interval, defaults to the last observation.
            n (int,optional): Number of points to generate in the interval.
            step (float,str,optional): Spacing between points in the interval.

            If neither &#39;step&#39; or &#39;n&#39; is passed, default number of points is 100.

        Examples:
            &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
            &gt;&gt;&gt; data.set_pred_range(3, 8, 200)
        
            &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
            &gt;&gt;&gt; data.set_pred_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;, step=&#39;1d&#39;)
        &#34;&#34;&#34;
        if self.get_input_dims() != 1:
            raise Exception(&#34;can only set prediction range on one dimensional input data&#34;)

        cstart = start
        if cstart == None:
            cstart = self.X[0,:]
        elif isinstance(cstart, list):
            for i in range(self.get_input_dims()):
                cstart[i] = self.formatters[i]._parse(cstart[i])
        else:
            cstart = self.formatters[0]._parse(cstart)

        cend = end
        if cend == None:
            cend = self.X[-1,:]
        elif isinstance(cend, list):
            for i in range(self.get_input_dims()):
                cend[i] = self.formatters[i]._parse(cend[i])
        else:
            cend = self.formatters[0]._parse(cend)
        
        cstart = _normalize_input_dims(cstart, self.get_input_dims())
        cend = _normalize_input_dims(cend, self.get_input_dims())

        # TODO: works for multi input dims?
        if cend &lt;= cstart:
            raise ValueError(&#34;start must be lower than end&#34;)

        # TODO: prediction range for multi input dimension; fix other axes to zero so we can plot?
        if step == None and n != None:
            self.X_pred = np.empty((n, self.get_input_dims()))
            for i in range(self.get_input_dims()):
                self.X_pred[:,i] = np.linspace(cstart[i], cend[i], n)
        else:
            if self.get_input_dims() != 1:
                raise ValueError(&#34;cannot use step for multi dimensional input, use n&#34;)
            cstep = step
            if cstep == None:
                cstep = (cend[0]-cstart[0])/100
            else:
                cstep = self.formatters[0]._parse(cstep)
            self.X_pred = np.arange(cstart[0], cend[0]+cstep, cstep).reshape(-1, 1)
    
    def set_pred(self, x):
        &#34;&#34;&#34;
        Set the prediction range directly.

        Args:
            x (list,np.ndarray): Array of shape (n) or (n,input_dims) with input values to predict at.

        Examples:
            &gt;&gt;&gt; data.set_pred([5.0, 5.5, 6.0, 6.5, 7.0])
        &#34;&#34;&#34;
        if x.ndim != 2 or x.shape[1] != self.get_input_dims():
            raise ValueError(&#34;x shape must be (n,input_dims)&#34;)
        if isinstance(x, list):
            x = np.array(x)
        elif not isinstance(x, np.ndarray):
            raise ValueError(&#34;x expected to be a list or Numpy array&#34;)

        self.X_pred = x

    ################################################################

    def get_nyquist_estimation(self):
        &#34;&#34;&#34;
        Estimate nyquist frequency by taking 0.5/(minimum distance of points).

        Returns:
            ndarray: Nyquist frequency array of shape (input_dims).
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        nyquist = np.empty((input_dims))
        for i in range(self.get_input_dims()):
            x = np.sort(self.X[:,i])
            dist = np.abs(x[1:]-x[:-1]) # TODO: assumes X is sorted, use average distance instead of minimal distance?
            dist = np.min(dist[np.nonzero(dist)])
            nyquist[i] = 0.5/dist
        return nyquist

    def get_bnse_estimation(self, Q=1, n=5000):
        &#34;&#34;&#34;
        Peaks estimation using BNSE (Bayesian Non-parametric Spectral Estimation).

        Args:
            Q (int): Number of peaks to find, defaults to 1.
            n (int): Number of points of the grid to evaluate 
                frequencies, defaults to 5000.

        Returns:
            amplitudes: Amplitude array of shape (input_dims,Q).
            positions: Frequency array of shape (input_dims,Q).
            variances: Variance array of shape (input_dims, Q).
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((input_dims, Q))
        B = np.zeros((input_dims, Q))
        C = np.zeros((input_dims, Q))

        nyquist = self.get_nyquist_estimation()
        for i in range(input_dims):
            x = self.X[:,i]
            y = self.Y
            bnse = bse(x, y)
            bnse.set_freqspace(nyquist[i], dimension=n)
            bnse.train()
            bnse.compute_moments()

            amplitudes, positions, variances = bnse.get_freq_peaks()
            if len(positions) == 0:
                continue

            n = len(positions)
            if n &lt; Q and n != 0:
                # if there not enough peaks, we will repeat them
                j = 0
                while len(positions) &lt; Q:
                    amplitudes = np.append(amplitudes, amplitudes[j])
                    positions = np.append(positions, positions[j])
                    variances = np.append(variances, variances[j])
                    j = (j+1) % n

            A[i,:] = amplitudes[:Q]
            B[i,:] = positions[:Q]
            C[i,:] = variances[:Q]
        return A, B, C

    def get_ls_estimation(self, Q=1, n=50000):
        &#34;&#34;&#34;
        Peak estimation using Lomb Scargle.

        Args:
            Q (int): Number of peaks to find, defaults to 1.
            n (int): Number of points to use for Lomb Scargle, defaults to 50000.

        Returns:
            ndarray: Frequency array of shape (input_dims,Q).
            ndarray: Amplitude array of shape (input_dims,Q).
        &#34;&#34;&#34;
        input_dims = self.get_input_dims()

        # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
        # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
        A = np.zeros((input_dims, Q))
        B = np.zeros((input_dims, Q))
        C = np.zeros((input_dims, Q))

        nyquist = self.get_nyquist_estimation() * 2 * np.pi
        for i in range(input_dims):
            x = np.linspace(0, nyquist[i], n+1)[1:]
            dx = x[1]-x[0]

            y = signal.lombscargle(self.X[:,i], self.Y, x)
            ind, _ = signal.find_peaks(y)
            ind = ind[np.argsort(y[ind])[::-1]] # sort by biggest peak first

            widths, width_heights, _, _ = signal.peak_widths(y, ind, rel_height=0.5)
            widths *= dx / np.pi / 2.0

            positions = x[ind] / np.pi / 2.0
            amplitudes = y[ind]
            variances = widths / np.sqrt(8 * np.log(amplitudes / width_heights)) # from full-width half-maximum to Gaussian sigma

            n = len(positions)
            if n &lt; Q and n != 0:
                # if there not enough peaks, we will repeat them
                j = 0
                while len(positions) &lt; Q:
                    amplitudes = np.append(amplitudes, amplitudes[j])
                    positions = np.append(positions, positions[j])
                    variances = np.append(variances, variances[j])
                    j = (j+1) % n

            A[i,:] = amplitudes[:Q]
            B[i,:] = positions[:Q]
            C[i,:] = variances[:Q]
        return A, B, C
    
    #def get_gm_estimation(self):
    #    # TODO: use sklearn.mixture.GaussianMixture to retrieve fitted gaussian mixtures to spectral data
    #    pass

    def plot(self, title=None, filename=None, show=True):
        &#34;&#34;&#34;
        Plot the data including removed observations, latent function, and predictions.

        Args:
            title (str,optional): Set the title for the plot.
            filename (str,optional): If set, export figure to file.
            show (bool,optional): If True, show the plot immediately.
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise Exception(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise Exception(&#34;two dimensional input data not yet implemented&#34;) # TODO

        fig, axes = plt.subplots(1, 1, figsize=(20, 5), constrained_layout=True, squeeze=False)
        if title != None:
            fig.suptitle(title, fontsize=36)

        plotting_pred = False
        plotting_F = False
        plotting_obs = False

        if self.Y_mu_pred.size != 0:
            lower = self.Y_mu_pred - self.Y_var_pred
            upper = self.Y_mu_pred + self.Y_var_pred
            axes[0,0].plot(self.X_pred[:,0], self.Y_mu_pred, &#39;b-&#39;, lw=3)
            axes[0,0].fill_between(self.X_pred[:,0], lower, upper, color=&#39;b&#39;, alpha=0.1)
            axes[0,0].plot(self.X_pred[:,0], lower, &#39;b-&#39;, lw=1, alpha=0.5)
            axes[0,0].plot(self.X_pred[:,0], upper, &#39;b-&#39;, lw=1, alpha=0.5)
            plotting_pred = True

        if self.F != None:
            n = len(self.X[:,0])*10
            x_min = np.min(self.X[:,0])
            x_max = np.max(self.X[:,0])

            x = np.empty((n, 1))
            x[:,0] = np.linspace(x_min, x_max, n)
            y = self.F(x)

            axes[0,0].plot(x[:,0], y, &#39;r--&#39;, lw=1)
            plotting_F = True

        axes[0,0].plot(self.X[:,0], self.Y, &#39;k-&#39;)

        if self.has_removed_obs():
            X, Y = self.get_obs()
            axes[0,0].plot(X[:,0], Y, &#39;k.&#39;, mew=2, ms=8)
            plotting_obs = True

        axes[0,0].set_xlabel(self.input_label[0])
        axes[0,0].set_ylabel(self.output_label)
        axes[0,0].set_title(self.name, fontsize=30)
        formatter = matplotlib.ticker.FuncFormatter(lambda x,pos: self.formatters[0]._format(x))
        axes[0,0].xaxis.set_major_formatter(formatter)

        # build legend
        if plotting_F or plotting_obs:
            legend = []
            legend.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=&#39;k&#39;, label=&#39;Data&#39;))
            if plotting_F:
                legend.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;r&#39;, label=&#39;Latent function&#39;))
            if plotting_obs:
                legend.append(plt.Line2D([0], [0], ls=&#39;&#39;, marker=&#39;.&#39;, color=&#39;k&#39;, mew=2, ms=8, label=&#39;Training&#39;))
            if plotting_pred:
                legend.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=&#39;b&#39;, lw=3, label=&#39;Prediction&#39;))
            plt.legend(handles=legend, loc=&#39;best&#39;)

        if filename != None:
            plt.savefig(filename+&#39;.pdf&#39;, dpi=300)
        if show:
            plt.show()

    def plot_spectrum(self, method=&#39;lombscargle&#39;, angularfreq=False, per=None, maxfreq=None, title=None, filename=None, show=True):
        &#34;&#34;&#34;
        Plot the spectrum of the data.

        TODO: Add BNSE as spectrum estimate option.

        Args:
            method (str,optional): Set the method to get the spectrum such as &#39;lombscargle&#39;.
            angularfreq (bool,optional): Use angular frequencies.
            per (float,str): Set the scale of the X axis depending on the formatter used, eg. per=5 or per=&#39;3d&#39; for three days.
            maxfreq (float,optional): Maximum frequency to plot, otherwise the Nyquist frequency is used.
            title (str,optional): Set the title for the plot.
            filename (str,optional): If set, export figure to file.
            show (bool,optional): If True, show the plot immediately.
        &#34;&#34;&#34;
        # TODO: ability to plot conditional or marginal distribution to reduce input dims
        if self.get_input_dims() &gt; 2:
            raise Exception(&#34;cannot plot more than two input dimensions&#34;)
        if self.get_input_dims() == 2:
            raise Exception(&#34;two dimensional input data not yet implemented&#34;) # TODO

        # sns.set(font_scale=2)
        # sns.axes_style(&#34;darkgrid&#34;)
        # sns.set_style(&#34;whitegrid&#34;)

        fig, axes = plt.subplots(1, 1, figsize=(20, 5), constrained_layout=True, squeeze=False)
        if title != None:
            fig.suptitle(title, fontsize=36)

        X_space = self.X[:,0].copy()

        formatter = self.formatters[0]
        factor, name = formatter._scale(per)
        if name != None:
            axes[0,0].set_xlabel(&#39;Frequency (1/&#39;+name+&#39;)&#39;)
        else:
            axes[0,0].set_xlabel(&#39;Frequency&#39;)

        if not angularfreq:
            X_space *= 2 * np.pi
        X_space /= factor

        freq = maxfreq
        if freq == None:
            dist = np.abs(X_space[1:]-X_space[:-1])
            freq = 1/np.average(dist)

        X = np.linspace(0.0, freq, 10001)[1:]
        if method == &#39;lombscargle&#39;:
            Y = signal.lombscargle(X_space, self.Y, X)
        else:
            raise ValueError(&#39;periodogram method &#34;%s&#34; does not exist&#39; % (method))

        axes[0,0].plot(X, Y, &#39;k-&#39;)
        axes[0,0].set_title(self.name + &#39; spectrum&#39;, fontsize=30)
        axes[0,0].set_yticks([])
        axes[0,0].set_ylim(0, None)

        if filename != None:
            plt.savefig(filename+&#39;.pdf&#39;, dpi=300)
        if show:
            plt.show()

        return axes[0, 0]</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="mogptk.data.Data.aggregate"><code class="name flex">
<span>def <span class="ident">aggregate</span></span>(<span>self, duration, f=<function mean at 0x7f05971ac0d0>)</span>
</code></dt>
<dd>
<section class="desc"><p>Aggregate the data by duration and apply a function to obtain a reduced dataset.</p>
<p>For example, group daily data by week and take the mean.
The duration can be set as a number which defined the intervals on the X axis,
or by a string written in the duration format with:
y=year, M=month, w=week, d=day, h=hour, m=minute, and s=second.
For example, 3w1d means three weeks and one day, ie. 22 days, or 6M to mean six months.
If using a number, be aware that when using FormatDate your X data is denoted per day,
while with FormatDateTime it is per second.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>duration</code></strong> :&ensp;<code>float</code>,<code>str</code></dt>
<dd>Duration along the X axis or as a string in the duration format.</dd>
<dt><strong><code>f</code></strong> :&ensp;<code>function</code>,optional</dt>
<dd>Function to use to reduce data, by default uses np.mean.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data.aggregate(5)

&gt;&gt;&gt; data.aggregate('2w', f=np.sum)
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def aggregate(self, duration, f=np.mean):
    &#34;&#34;&#34;
    Aggregate the data by duration and apply a function to obtain a reduced dataset.

    For example, group daily data by week and take the mean.
    The duration can be set as a number which defined the intervals on the X axis,
    or by a string written in the duration format with:
    y=year, M=month, w=week, d=day, h=hour, m=minute, and s=second.
    For example, 3w1d means three weeks and one day, ie. 22 days, or 6M to mean six months.
    If using a number, be aware that when using FormatDate your X data is denoted per day,
    while with FormatDateTime it is per second.

    Args:
        duration (float,str): Duration along the X axis or as a string in the duration format.
        f (function,optional): Function to use to reduce data, by default uses np.mean.

    Examples:
        &gt;&gt;&gt; data.aggregate(5)

        &gt;&gt;&gt; data.aggregate(&#39;2w&#39;, f=np.sum)
    &#34;&#34;&#34;
    if self.get_input_dims() != 1:
        raise ValueError(&#34;can only aggregate on one dimensional input data&#34;)
    
    start = self.X[0,0]
    end = self.X[-1,0]
    step = self.formatters[0]._parse_duration(duration)

    X = np.arange(start+step/2, end+step/2, step)
    Y = np.empty((len(X)))
    for i in range(len(X)):
        ind = (self.X[:,0] &gt;= X[i]-step/2) &amp; (self.X[:,0] &lt; X[i]+step/2)
        Y[i] = f(self.Y[ind])

    self.X = np.expand_dims(X, 1)
    self.Y = Y
    self.mask = np.array([True] * len(self.X))</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Make a deep copy of the dataset.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="mogptk.data.Data" href="#mogptk.data.Data"><code>Data</code></a></strong></dt>
<dd>Data.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def copy(self):
    &#34;&#34;&#34;
    Make a deep copy of the dataset.

    Returns:
        Data: Data.
    &#34;&#34;&#34;
    return copy.deepcopy(self)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, start, end)</span>
</code></dt>
<dd>
<section class="desc"><p>Filter the data range to be between start and end. Start and end can be strings if a proper formatter is set for the independent variable.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code>,<code>str</code></dt>
<dd>Start of interval.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code>,<code>str</code></dt>
<dd>End of interval.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&gt;&gt;&gt; data.filter(3, 8)

&gt;&gt;&gt; data = LoadCSV('gold.csv', 'Date', 'Price', format={'Date': FormatDate})
&gt;&gt;&gt; data.filter('2016-01-15', '2016-06-15')
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def filter(self, start, end):
    &#34;&#34;&#34;
    Filter the data range to be between start and end. Start and end can be strings if a proper formatter is set for the independent variable.

    Args:
        start (float,str): Start of interval.
        end (float,str): End of interval.

    Examples:
        &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &gt;&gt;&gt; data.filter(3, 8)
    
        &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
        &gt;&gt;&gt; data.filter(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
    &#34;&#34;&#34;
    if self.get_input_dims() != 1:
        raise ValueError(&#34;can only filter on one dimensional input data&#34;)
    
    cstart = self.formatters[0]._parse(start)
    cend = self.formatters[0]._parse(end)
    ind = (self.X[:,0] &gt;= cstart) &amp; (self.X[:,0] &lt; cend)

    self.X = np.expand_dims(self.X[ind,0], 1)
    self.Y = self.Y[ind]
    self.mask = self.mask[ind]</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_all_obs"><code class="name flex">
<span>def <span class="ident">get_all_obs</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns all observations (including removed observations).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ndarray</code></strong></dt>
<dd>X data of shape (n,input_dims).</dd>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Y data of shape (n).</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_all_obs(self):
    &#34;&#34;&#34;
    Returns all observations (including removed observations).

    Returns:
        ndarray: X data of shape (n,input_dims).
        ndarray: Y data of shape (n).
    &#34;&#34;&#34;
    return self.X, self.Y</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_bnse_estimation"><code class="name flex">
<span>def <span class="ident">get_bnse_estimation</span></span>(<span>self, Q=1, n=5000)</span>
</code></dt>
<dd>
<section class="desc"><p>Peaks estimation using BNSE (Bayesian Non-parametric Spectral Estimation).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Q</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of peaks to find, defaults to 1.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points of the grid to evaluate
frequencies, defaults to 5000.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>amplitudes</code></strong></dt>
<dd>Amplitude array of shape (input_dims,Q).</dd>
<dt><strong><code>positions</code></strong></dt>
<dd>Frequency array of shape (input_dims,Q).</dd>
<dt><strong><code>variances</code></strong></dt>
<dd>Variance array of shape (input_dims, Q).</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_bnse_estimation(self, Q=1, n=5000):
    &#34;&#34;&#34;
    Peaks estimation using BNSE (Bayesian Non-parametric Spectral Estimation).

    Args:
        Q (int): Number of peaks to find, defaults to 1.
        n (int): Number of points of the grid to evaluate 
            frequencies, defaults to 5000.

    Returns:
        amplitudes: Amplitude array of shape (input_dims,Q).
        positions: Frequency array of shape (input_dims,Q).
        variances: Variance array of shape (input_dims, Q).
    &#34;&#34;&#34;
    input_dims = self.get_input_dims()

    # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
    # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
    A = np.zeros((input_dims, Q))
    B = np.zeros((input_dims, Q))
    C = np.zeros((input_dims, Q))

    nyquist = self.get_nyquist_estimation()
    for i in range(input_dims):
        x = self.X[:,i]
        y = self.Y
        bnse = bse(x, y)
        bnse.set_freqspace(nyquist[i], dimension=n)
        bnse.train()
        bnse.compute_moments()

        amplitudes, positions, variances = bnse.get_freq_peaks()
        if len(positions) == 0:
            continue

        n = len(positions)
        if n &lt; Q and n != 0:
            # if there not enough peaks, we will repeat them
            j = 0
            while len(positions) &lt; Q:
                amplitudes = np.append(amplitudes, amplitudes[j])
                positions = np.append(positions, positions[j])
                variances = np.append(variances, variances[j])
                j = (j+1) % n

        A[i,:] = amplitudes[:Q]
        B[i,:] = positions[:Q]
        C[i,:] = variances[:Q]
    return A, B, C</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_del_obs"><code class="name flex">
<span>def <span class="ident">get_del_obs</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the removed observations.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ndarray</code></strong></dt>
<dd>X data of shape (n,input_dims).</dd>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Y data of shape (n).</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_del_obs(self):
    &#34;&#34;&#34;
    Returns the removed observations.

    Returns:
        ndarray: X data of shape (n,input_dims).
        ndarray: Y data of shape (n).
    &#34;&#34;&#34;
    return self.X[~self.mask,:], self.Y[~self.mask]</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_input_dims"><code class="name flex">
<span>def <span class="ident">get_input_dims</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the number of input dimensions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Input dimensions.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_input_dims(self):
    &#34;&#34;&#34;
    Returns the number of input dimensions.

    Returns:
        int: Input dimensions.
    &#34;&#34;&#34;
    return self.X.shape[1]</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_ls_estimation"><code class="name flex">
<span>def <span class="ident">get_ls_estimation</span></span>(<span>self, Q=1, n=50000)</span>
</code></dt>
<dd>
<section class="desc"><p>Peak estimation using Lomb Scargle.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Q</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of peaks to find, defaults to 1.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points to use for Lomb Scargle, defaults to 50000.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Frequency array of shape (input_dims,Q).</dd>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Amplitude array of shape (input_dims,Q).</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_ls_estimation(self, Q=1, n=50000):
    &#34;&#34;&#34;
    Peak estimation using Lomb Scargle.

    Args:
        Q (int): Number of peaks to find, defaults to 1.
        n (int): Number of points to use for Lomb Scargle, defaults to 50000.

    Returns:
        ndarray: Frequency array of shape (input_dims,Q).
        ndarray: Amplitude array of shape (input_dims,Q).
    &#34;&#34;&#34;
    input_dims = self.get_input_dims()

    # Gaussian: f(x) = A * exp((x-B)^2 / (2C^2))
    # Ie. A is the amplitude or peak height, B the mean or peak position, and C the variance or peak width
    A = np.zeros((input_dims, Q))
    B = np.zeros((input_dims, Q))
    C = np.zeros((input_dims, Q))

    nyquist = self.get_nyquist_estimation() * 2 * np.pi
    for i in range(input_dims):
        x = np.linspace(0, nyquist[i], n+1)[1:]
        dx = x[1]-x[0]

        y = signal.lombscargle(self.X[:,i], self.Y, x)
        ind, _ = signal.find_peaks(y)
        ind = ind[np.argsort(y[ind])[::-1]] # sort by biggest peak first

        widths, width_heights, _, _ = signal.peak_widths(y, ind, rel_height=0.5)
        widths *= dx / np.pi / 2.0

        positions = x[ind] / np.pi / 2.0
        amplitudes = y[ind]
        variances = widths / np.sqrt(8 * np.log(amplitudes / width_heights)) # from full-width half-maximum to Gaussian sigma

        n = len(positions)
        if n &lt; Q and n != 0:
            # if there not enough peaks, we will repeat them
            j = 0
            while len(positions) &lt; Q:
                amplitudes = np.append(amplitudes, amplitudes[j])
                positions = np.append(positions, positions[j])
                variances = np.append(variances, variances[j])
                j = (j+1) % n

        A[i,:] = amplitudes[:Q]
        B[i,:] = positions[:Q]
        C[i,:] = variances[:Q]
    return A, B, C</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_nyquist_estimation"><code class="name flex">
<span>def <span class="ident">get_nyquist_estimation</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Estimate nyquist frequency by taking 0.5/(minimum distance of points).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Nyquist frequency array of shape (input_dims).</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_nyquist_estimation(self):
    &#34;&#34;&#34;
    Estimate nyquist frequency by taking 0.5/(minimum distance of points).

    Returns:
        ndarray: Nyquist frequency array of shape (input_dims).
    &#34;&#34;&#34;
    input_dims = self.get_input_dims()

    nyquist = np.empty((input_dims))
    for i in range(self.get_input_dims()):
        x = np.sort(self.X[:,i])
        dist = np.abs(x[1:]-x[:-1]) # TODO: assumes X is sorted, use average distance instead of minimal distance?
        dist = np.min(dist[np.nonzero(dist)])
        nyquist[i] = 0.5/dist
    return nyquist</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.get_obs"><code class="name flex">
<span>def <span class="ident">get_obs</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the observations.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ndarray</code></strong></dt>
<dd>X data of shape (n,input_dims).</dd>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Y data of shape (n).</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_obs(self):
    &#34;&#34;&#34;
    Returns the observations.

    Returns:
        ndarray: X data of shape (n,input_dims).
        ndarray: Y data of shape (n).
    &#34;&#34;&#34;
    return self.X[self.mask,:], self.Y[self.mask]</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.has_removed_obs"><code class="name flex">
<span>def <span class="ident">has_removed_obs</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns True if observations have been removed using the remove_* methods.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def has_removed_obs(self):
    &#34;&#34;&#34;
    Returns True if observations have been removed using the remove_* methods.
    &#34;&#34;&#34;
    return False in self.mask</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, title=None, filename=None, show=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Plot the data including removed observations, latent function, and predictions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>Set the title for the plot.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>If set, export figure to file.</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>,optional</dt>
<dd>If True, show the plot immediately.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plot(self, title=None, filename=None, show=True):
    &#34;&#34;&#34;
    Plot the data including removed observations, latent function, and predictions.

    Args:
        title (str,optional): Set the title for the plot.
        filename (str,optional): If set, export figure to file.
        show (bool,optional): If True, show the plot immediately.
    &#34;&#34;&#34;
    # TODO: ability to plot conditional or marginal distribution to reduce input dims
    if self.get_input_dims() &gt; 2:
        raise Exception(&#34;cannot plot more than two input dimensions&#34;)
    if self.get_input_dims() == 2:
        raise Exception(&#34;two dimensional input data not yet implemented&#34;) # TODO

    fig, axes = plt.subplots(1, 1, figsize=(20, 5), constrained_layout=True, squeeze=False)
    if title != None:
        fig.suptitle(title, fontsize=36)

    plotting_pred = False
    plotting_F = False
    plotting_obs = False

    if self.Y_mu_pred.size != 0:
        lower = self.Y_mu_pred - self.Y_var_pred
        upper = self.Y_mu_pred + self.Y_var_pred
        axes[0,0].plot(self.X_pred[:,0], self.Y_mu_pred, &#39;b-&#39;, lw=3)
        axes[0,0].fill_between(self.X_pred[:,0], lower, upper, color=&#39;b&#39;, alpha=0.1)
        axes[0,0].plot(self.X_pred[:,0], lower, &#39;b-&#39;, lw=1, alpha=0.5)
        axes[0,0].plot(self.X_pred[:,0], upper, &#39;b-&#39;, lw=1, alpha=0.5)
        plotting_pred = True

    if self.F != None:
        n = len(self.X[:,0])*10
        x_min = np.min(self.X[:,0])
        x_max = np.max(self.X[:,0])

        x = np.empty((n, 1))
        x[:,0] = np.linspace(x_min, x_max, n)
        y = self.F(x)

        axes[0,0].plot(x[:,0], y, &#39;r--&#39;, lw=1)
        plotting_F = True

    axes[0,0].plot(self.X[:,0], self.Y, &#39;k-&#39;)

    if self.has_removed_obs():
        X, Y = self.get_obs()
        axes[0,0].plot(X[:,0], Y, &#39;k.&#39;, mew=2, ms=8)
        plotting_obs = True

    axes[0,0].set_xlabel(self.input_label[0])
    axes[0,0].set_ylabel(self.output_label)
    axes[0,0].set_title(self.name, fontsize=30)
    formatter = matplotlib.ticker.FuncFormatter(lambda x,pos: self.formatters[0]._format(x))
    axes[0,0].xaxis.set_major_formatter(formatter)

    # build legend
    if plotting_F or plotting_obs:
        legend = []
        legend.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=&#39;k&#39;, label=&#39;Data&#39;))
        if plotting_F:
            legend.append(plt.Line2D([0], [0], ls=&#39;--&#39;, color=&#39;r&#39;, label=&#39;Latent function&#39;))
        if plotting_obs:
            legend.append(plt.Line2D([0], [0], ls=&#39;&#39;, marker=&#39;.&#39;, color=&#39;k&#39;, mew=2, ms=8, label=&#39;Training&#39;))
        if plotting_pred:
            legend.append(plt.Line2D([0], [0], ls=&#39;-&#39;, color=&#39;b&#39;, lw=3, label=&#39;Prediction&#39;))
        plt.legend(handles=legend, loc=&#39;best&#39;)

    if filename != None:
        plt.savefig(filename+&#39;.pdf&#39;, dpi=300)
    if show:
        plt.show()</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.plot_spectrum"><code class="name flex">
<span>def <span class="ident">plot_spectrum</span></span>(<span>self, method='lombscargle', angularfreq=False, per=None, maxfreq=None, title=None, filename=None, show=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Plot the spectrum of the data.</p>
<p>TODO: Add BNSE as spectrum estimate option.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>Set the method to get the spectrum such as 'lombscargle'.</dd>
<dt><strong><code>angularfreq</code></strong> :&ensp;<code>bool</code>,optional</dt>
<dd>Use angular frequencies.</dd>
<dt><strong><code>per</code></strong> :&ensp;<code>float</code>,<code>str</code></dt>
<dd>Set the scale of the X axis depending on the formatter used, eg. per=5 or per='3d' for three days.</dd>
<dt><strong><code>maxfreq</code></strong> :&ensp;<code>float</code>,optional</dt>
<dd>Maximum frequency to plot, otherwise the Nyquist frequency is used.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>Set the title for the plot.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code>,optional</dt>
<dd>If set, export figure to file.</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>,optional</dt>
<dd>If True, show the plot immediately.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plot_spectrum(self, method=&#39;lombscargle&#39;, angularfreq=False, per=None, maxfreq=None, title=None, filename=None, show=True):
    &#34;&#34;&#34;
    Plot the spectrum of the data.

    TODO: Add BNSE as spectrum estimate option.

    Args:
        method (str,optional): Set the method to get the spectrum such as &#39;lombscargle&#39;.
        angularfreq (bool,optional): Use angular frequencies.
        per (float,str): Set the scale of the X axis depending on the formatter used, eg. per=5 or per=&#39;3d&#39; for three days.
        maxfreq (float,optional): Maximum frequency to plot, otherwise the Nyquist frequency is used.
        title (str,optional): Set the title for the plot.
        filename (str,optional): If set, export figure to file.
        show (bool,optional): If True, show the plot immediately.
    &#34;&#34;&#34;
    # TODO: ability to plot conditional or marginal distribution to reduce input dims
    if self.get_input_dims() &gt; 2:
        raise Exception(&#34;cannot plot more than two input dimensions&#34;)
    if self.get_input_dims() == 2:
        raise Exception(&#34;two dimensional input data not yet implemented&#34;) # TODO

    # sns.set(font_scale=2)
    # sns.axes_style(&#34;darkgrid&#34;)
    # sns.set_style(&#34;whitegrid&#34;)

    fig, axes = plt.subplots(1, 1, figsize=(20, 5), constrained_layout=True, squeeze=False)
    if title != None:
        fig.suptitle(title, fontsize=36)

    X_space = self.X[:,0].copy()

    formatter = self.formatters[0]
    factor, name = formatter._scale(per)
    if name != None:
        axes[0,0].set_xlabel(&#39;Frequency (1/&#39;+name+&#39;)&#39;)
    else:
        axes[0,0].set_xlabel(&#39;Frequency&#39;)

    if not angularfreq:
        X_space *= 2 * np.pi
    X_space /= factor

    freq = maxfreq
    if freq == None:
        dist = np.abs(X_space[1:]-X_space[:-1])
        freq = 1/np.average(dist)

    X = np.linspace(0.0, freq, 10001)[1:]
    if method == &#39;lombscargle&#39;:
        Y = signal.lombscargle(X_space, self.Y, X)
    else:
        raise ValueError(&#39;periodogram method &#34;%s&#34; does not exist&#39; % (method))

    axes[0,0].plot(X, Y, &#39;k-&#39;)
    axes[0,0].set_title(self.name + &#39; spectrum&#39;, fontsize=30)
    axes[0,0].set_yticks([])
    axes[0,0].set_ylim(0, None)

    if filename != None:
        plt.savefig(filename+&#39;.pdf&#39;, dpi=300)
    if show:
        plt.show()

    return axes[0, 0]</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_random_ranges"><code class="name flex">
<span>def <span class="ident">remove_random_ranges</span></span>(<span>self, n, duration)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes a number of ranges to simulate sensor failure.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of ranges to remove.</dd>
<dt><strong><code>duration</code></strong> :&ensp;<code>float</code>,<code>str</code></dt>
<dd>Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

&gt;&gt;&gt; data.remove_random_ranges(3, '1d') # remove three ranges that are 1 day wide
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def remove_random_ranges(self, n, duration):
    &#34;&#34;&#34;
    Removes a number of ranges to simulate sensor failure.

    Args:
        n (int): Number of ranges to remove.
        duration (float,str): Width of ranges to remove, can use a number or the duration format syntax (see aggregate()).

    Examples:
        &gt;&gt;&gt; data.remove_random_ranges(2, 5) # remove two ranges that are 5 wide in input space

        &gt;&gt;&gt; data.remove_random_ranges(3, &#39;1d&#39;) # remove three ranges that are 1 day wide
    &#34;&#34;&#34;
    if self.get_input_dims() != 1:
        raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

    duration = self.formatters[0]._parse_duration(duration)
    if n &lt; 1 or duration &lt; 1:
        return

    # TODO: what if N != 1 and we have dates on the X-axis? Make sure that ranges do not overlap and are picked randomly
    m = (self.X[-1]-self.X[0]) - n*duration
    if m &lt;= 0:
        raise Exception(&#34;no data left after removing ranges&#34;)

    locs = np.round(np.sort(np.random.rand(n)) * m)
    for i in range(len(locs)):
        loc = int(locs[i] + i * duration)
        idx = np.arange(int(loc), int(loc+duration))
        self.mask[idx] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_randomly"><code class="name flex">
<span>def <span class="ident">remove_randomly</span></span>(<span>self, n=None, pct=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes observations randomly on the whole range. Either 'n' observations are removed, or a percentage of the observations.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code>,optional</dt>
<dd>Number of observations to remove randomly.</dd>
<dt><strong><code>pct</code></strong> :&ensp;<code>float</code>[<code>0</code>,<code>1</code>],optional</dt>
<dd>Percentage of observations to remove randomly.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

&gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def remove_randomly(self, n=None, pct=None):
    &#34;&#34;&#34;
    Removes observations randomly on the whole range. Either &#39;n&#39; observations are removed, or a percentage of the observations.

    Args:
        n (int,optional): Number of observations to remove randomly.
        pct (float[0,1],optional): Percentage of observations to remove randomly.

    Examples:
        &gt;&gt;&gt; data.remove_randomly(50) # remove 50 observations

        &gt;&gt;&gt; data.remove_randomly(pct=0.9) # remove 90% of the observations
    &#34;&#34;&#34;
    if n == None:
        if pct == None:
            n = 0
        else:
            n = int(pct * self.X.shape[0])

    idx = np.random.choice(self.X.shape[0], n, replace=False)
    self.mask[idx] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_range"><code class="name flex">
<span>def <span class="ident">remove_range</span></span>(<span>self, start=None, end=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes observations in the interval [start,end]. Start and end can be strings if a proper formatter is set for the independent variable.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code>,<code>str</code>,optional</dt>
<dd>Start of interval. Defaults to first value in observations.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code>,<code>str</code>,optional</dt>
<dd>End of interval. Defaults to last value in observations.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&gt;&gt;&gt; data.remove_range(3, 8)

&gt;&gt;&gt; data = LoadCSV('gold.csv', 'Date', 'Price', format={'Date': FormatDate})
&gt;&gt;&gt; data.remove_range('2016-01-15', '2016-06-15')
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def remove_range(self, start=None, end=None):
    &#34;&#34;&#34;
    Removes observations in the interval [start,end]. Start and end can be strings if a proper formatter is set for the independent variable.
    
    Args:
        start (float,str,optional): Start of interval. Defaults to first value in observations.
        end (float,str,optional): End of interval. Defaults to last value in observations.

    Examples:
        &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &gt;&gt;&gt; data.remove_range(3, 8)
    
        &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
        &gt;&gt;&gt; data.remove_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;)
    &#34;&#34;&#34;
    if self.get_input_dims() != 1:
        raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

    if start == None:
        start = np.min(self.X[:,0])
    else:
        start = self.formatters[0]._parse(start)
    if end == None:
        end = np.max(self.X[:,0])
    else:
        end = self.formatters[0]._parse(end)

    idx = np.where(np.logical_and(self.X[:,0] &gt;= start, self.X[:,0] &lt;= end))
    self.mask[idx] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.remove_rel_range"><code class="name flex">
<span>def <span class="ident">remove_rel_range</span></span>(<span>self, start, end)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes observations between start and end as a percentage of the number of observations. So '0' is the first observation, '0.5' is the middle observation, and '1' is the last observation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code>[<code>0</code>,<code>1</code>]</dt>
<dd>Start percentage of interval.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code>[<code>0</code>,<code>1</code>]</dt>
<dd>End percentage of interval.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def remove_rel_range(self, start, end):
    &#34;&#34;&#34;
    Removes observations between start and end as a percentage of the number of observations. So &#39;0&#39; is the first observation, &#39;0.5&#39; is the middle observation, and &#39;1&#39; is the last observation.

    Args:
        start (float[0,1]): Start percentage of interval.
        end (float[0,1]): End percentage of interval.
    &#34;&#34;&#34;
    if self.get_input_dims() != 1:
        raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

    x_min = np.min(self.X[:,0])
    x_max = np.max(self.X[:,0])
    start = x_min + np.round(max(0.0, min(1.0, start)) * (x_max-x_min))
    end = x_min + np.round(max(0.0, min(1.0, end)) * (x_max-x_min))

    idx = np.where(np.logical_and(self.X[:,0] &gt;= start, self.X[:,0] &lt;= end))
    self.mask[idx] = False</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_function"><code class="name flex">
<span>def <span class="ident">set_function</span></span>(<span>self, f)</span>
</code></dt>
<dd>
<section class="desc"><p>Set a (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.</p>
<p>The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>function</code></dt>
<dd>Function taking x with shape (n,input_dims) and returning shape (n) as y.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def set_function(self, f):
    &#34;&#34;&#34;
    Set a (latent) function for the data, ie. the theoretical or true signal. This is used for plotting purposes and is optional.

    The function should take one argument x with shape (n,input_dims) and return y with shape (n). If your data has only one input dimension, you can use x[:,0] to select only the first (and only) input dimension.

    Args:
        f (function): Function taking x with shape (n,input_dims) and returning shape (n) as y.

    Examples:
        &gt;&gt;&gt; data.set_function(lambda x: np.sin(3*x[:,0])
    &#34;&#34;&#34;
    _check_function(f, self.get_input_dims())
    self.F = f</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_labels"><code class="name flex">
<span>def <span class="ident">set_labels</span></span>(<span>self, input, output)</span>
</code></dt>
<dd>
<section class="desc"><p>Set axes labels for plots.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>list</code>,<code>str</code></dt>
<dd>Independent variable name for each input dimension.</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code></dt>
<dd>Dependent variable name for output dimension.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data.set_labels(['X', 'Y'], 'Cd')
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def set_labels(self, input, output):
    &#34;&#34;&#34;
    Set axes labels for plots.

    Args:
        input (list,str): Independent variable name for each input dimension.
        output (str): Dependent variable name for output dimension.

    Examples:
        &gt;&gt;&gt; data.set_labels([&#39;X&#39;, &#39;Y&#39;], &#39;Cd&#39;)
    &#34;&#34;&#34;
    if isinstance(input, str):
        input = [input]
    elif not isinstance(input, list) or not all(isinstance(item, str) for item in input):
        raise ValueError(&#34;input labels must be list of strings&#34;)
    if not isinstance(output, str):
        raise ValueError(&#34;output label must be string&#34;)
    if len(input) != self.get_input_dims():
        raise ValueError(&#34;input labels must have the same input dimensions as the data&#34;)

    self.input_label = input
    self.output_label = output</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_name"><code class="name flex">
<span>def <span class="ident">set_name</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Set name for dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of dataset.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def set_name(self, name):
    &#34;&#34;&#34;
    Set name for dataset.

    Args:
        name (str): Name of dataset.
    &#34;&#34;&#34;
    self.name = name</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_pred"><code class="name flex">
<span>def <span class="ident">set_pred</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the prediction range directly.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code>,<code>np.ndarray</code></dt>
<dd>Array of shape (n) or (n,input_dims) with input values to predict at.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data.set_pred([5.0, 5.5, 6.0, 6.5, 7.0])
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def set_pred(self, x):
    &#34;&#34;&#34;
    Set the prediction range directly.

    Args:
        x (list,np.ndarray): Array of shape (n) or (n,input_dims) with input values to predict at.

    Examples:
        &gt;&gt;&gt; data.set_pred([5.0, 5.5, 6.0, 6.5, 7.0])
    &#34;&#34;&#34;
    if x.ndim != 2 or x.shape[1] != self.get_input_dims():
        raise ValueError(&#34;x shape must be (n,input_dims)&#34;)
    if isinstance(x, list):
        x = np.array(x)
    elif not isinstance(x, np.ndarray):
        raise ValueError(&#34;x expected to be a list or Numpy array&#34;)

    self.X_pred = x</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.set_pred_range"><code class="name flex">
<span>def <span class="ident">set_pred_range</span></span>(<span>self, start=None, end=None, n=None, step=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Sets the prediction range to the interval [start,end] with either 'n' points or a given 'step' between the points. Start and end can be set as strings and step in the duration string format if the proper formatter is set.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>float</code>,<code>str</code>,optional</dt>
<dd>Start of interval, defaults to the first observation.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>float</code>,<code>str</code>,optional</dt>
<dd>End of interval, defaults to the last observation.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code>,optional</dt>
<dd>Number of points to generate in the interval.</dd>
<dt><strong><code>step</code></strong> :&ensp;<code>float</code>,<code>str</code>,optional</dt>
<dd>Spacing between points in the interval.</dd>
</dl>
<p>If neither 'step' or 'n' is passed, default number of points is 100.</p>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name='Sine wave')
&gt;&gt;&gt; data.set_pred_range(3, 8, 200)

&gt;&gt;&gt; data = LoadCSV('gold.csv', 'Date', 'Price', format={'Date': FormatDate})
&gt;&gt;&gt; data.set_pred_range('2016-01-15', '2016-06-15', step='1d')
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def set_pred_range(self, start=None, end=None, n=None, step=None):
    &#34;&#34;&#34;
    Sets the prediction range to the interval [start,end] with either &#39;n&#39; points or a given &#39;step&#39; between the points. Start and end can be set as strings and step in the duration string format if the proper formatter is set.

    Args:
        start (float,str,optional): Start of interval, defaults to the first observation.
        end (float,str,optional): End of interval, defaults to the last observation.
        n (int,optional): Number of points to generate in the interval.
        step (float,str,optional): Spacing between points in the interval.

        If neither &#39;step&#39; or &#39;n&#39; is passed, default number of points is 100.

    Examples:
        &gt;&gt;&gt; data = LoadFunction(lambda x: np.sin(3*x[:,0]), 0, 10, n=200, var=0.1, name=&#39;Sine wave&#39;)
        &gt;&gt;&gt; data.set_pred_range(3, 8, 200)
    
        &gt;&gt;&gt; data = LoadCSV(&#39;gold.csv&#39;, &#39;Date&#39;, &#39;Price&#39;, format={&#39;Date&#39;: FormatDate})
        &gt;&gt;&gt; data.set_pred_range(&#39;2016-01-15&#39;, &#39;2016-06-15&#39;, step=&#39;1d&#39;)
    &#34;&#34;&#34;
    if self.get_input_dims() != 1:
        raise Exception(&#34;can only set prediction range on one dimensional input data&#34;)

    cstart = start
    if cstart == None:
        cstart = self.X[0,:]
    elif isinstance(cstart, list):
        for i in range(self.get_input_dims()):
            cstart[i] = self.formatters[i]._parse(cstart[i])
    else:
        cstart = self.formatters[0]._parse(cstart)

    cend = end
    if cend == None:
        cend = self.X[-1,:]
    elif isinstance(cend, list):
        for i in range(self.get_input_dims()):
            cend[i] = self.formatters[i]._parse(cend[i])
    else:
        cend = self.formatters[0]._parse(cend)
    
    cstart = _normalize_input_dims(cstart, self.get_input_dims())
    cend = _normalize_input_dims(cend, self.get_input_dims())

    # TODO: works for multi input dims?
    if cend &lt;= cstart:
        raise ValueError(&#34;start must be lower than end&#34;)

    # TODO: prediction range for multi input dimension; fix other axes to zero so we can plot?
    if step == None and n != None:
        self.X_pred = np.empty((n, self.get_input_dims()))
        for i in range(self.get_input_dims()):
            self.X_pred[:,i] = np.linspace(cstart[i], cend[i], n)
    else:
        if self.get_input_dims() != 1:
            raise ValueError(&#34;cannot use step for multi dimensional input, use n&#34;)
        cstep = step
        if cstep == None:
            cstep = (cend[0]-cstart[0])/100
        else:
            cstep = self.formatters[0]._parse(cstep)
        self.X_pred = np.arange(cstart[0], cend[0]+cstep, cstep).reshape(-1, 1)</code></pre>
</details>
</dd>
<dt id="mogptk.data.Data.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, transformer)</span>
</code></dt>
<dd>
<section class="desc"><p>Transform the data by using one of the provided transformers, such as TransformDetrend, TransformNormalize, TransformLog, &hellip;</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transformer</code></strong> :&ensp;<code>obj</code></dt>
<dd>Transformer object with _forward(x, y) and _backward(x, y) methods.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; import mogptk
&gt;&gt;&gt; from mogptk import TransformDetrend
&gt;&gt;&gt; data = mogptk.Data(x, y)
&gt;&gt;&gt; data.transform(TransformDetrend)
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def transform(self, transformer):
    &#34;&#34;&#34;
    Transform the data by using one of the provided transformers, such as TransformDetrend, TransformNormalize, TransformLog, ...

    Args:
        transformer (obj): Transformer object with _forward(x, y) and _backward(x, y) methods.

    Examples:
        &gt;&gt;&gt; import mogptk
        &gt;&gt;&gt; from mogptk import TransformDetrend
        &gt;&gt;&gt; data = mogptk.Data(x, y)
        &gt;&gt;&gt; data.transform(TransformDetrend)
    &#34;&#34;&#34;
    t = transformer
    if &#39;__init__&#39; in vars(transformer):
        t = transformer(self)

    self.Y = t._forward(self.X, self.Y)
    if self.F != None:
        f = self.F
        self.F = lambda x: t._forward(x, f(x))
    self.transformations.append(t)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mogptk.data.FormatDate"><code class="flex name class">
<span>class <span class="ident">FormatDate</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>FormatDate is a formatter that takes date values as input, such as '2019-03-01', and stores values internally as days since 1970-01-01.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class FormatDate:
    &#34;&#34;&#34;
    FormatDate is a formatter that takes date values as input, such as &#39;2019-03-01&#39;, and stores values internally as days since 1970-01-01.
    &#34;&#34;&#34;
    def _format(val):
        return datetime.datetime.utcfromtimestamp(val*3600*24).strftime(&#39;%Y-%m-%d&#39;)

    def _parse(val, loc=None):
        try:
            return (dateutil.parser.parse(val) - datetime.datetime(1970,1,1)).total_seconds()/3600/24
        except ValueError:
            if loc == None:
                raise ValueError(&#34;could not convert input to date&#34;)
            else:
                raise ValueError(&#34;could not convert input to date at %s&#34; % (loc))

    def _parse_duration(val):
        if isinstance(val, int):
            return val
        if isinstance(val, str):
            return _parse_duration_to_sec(val)/24/3600
        raise ValueError(&#34;could not convert input to duration&#34;)

    def _scale(maxfreq=None):
        if maxfreq == &#39;year&#39;:
            return 356.2425, &#39;year&#39;
        if maxfreq == &#39;month&#39;:
            return 30.4369, &#39;month&#39;
        if maxfreq == None or maxfreq == &#39;day&#39;:
            return 1, &#39;day&#39;
        if maxfreq == &#39;hour&#39;:
            return 1/24, &#39;hour&#39;
        if maxfreq == &#39;minute&#39;:
            return 1/24/60, &#39;minute&#39;
        if maxfreq == &#39;second&#39;:
            return 1/24/3600, &#39;second&#39;</code></pre>
</details>
</dd>
<dt id="mogptk.data.FormatDateTime"><code class="flex name class">
<span>class <span class="ident">FormatDateTime</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>FormatDateTime is a formatter that takes date and time values as input, such as '2019-03-01 12:30', and stores values internally as seconds since 1970-01-01.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class FormatDateTime:
    &#34;&#34;&#34;
    FormatDateTime is a formatter that takes date and time values as input, such as &#39;2019-03-01 12:30&#39;, and stores values internally as seconds since 1970-01-01.
    &#34;&#34;&#34;
    def _format(val):
        return datetime.datetime.utcfromtimestamp(val).strftime(&#39;%Y-%m-%d %H:%M&#39;)

    def _parse(val, loc=None):
        try:
            return (dateutil.parser.parse(val) - datetime.datetime(1970,1,1)).total_seconds()
        except ValueError:
            if loc == None:
                raise ValueError(&#34;could not convert input to datetime&#34;)
            else:
                raise ValueError(&#34;could not convert input to datetime at %s&#34; % (loc))

    def _parse_duration(val):
        if isinstance(val, int):
            return val
        if isinstance(val, str):
            return _parse_duration_to_sec(val)
        raise ValueError(&#34;could not convert input to duration&#34;)

    def _scale(maxfreq=None):
        if maxfreq == &#39;year&#39;:
            return 3600*24*356.2425, &#39;year&#39;
        if maxfreq == &#39;month&#39;:
            return 3600*24*30.4369, &#39;month&#39;
        if maxfreq == &#39;day&#39;:
            return 3600*24, &#39;day&#39;
        if maxfreq == &#39;hour&#39;:
            return 3600, &#39;hour&#39;
        if maxfreq == &#39;minute&#39;:
            return 60, &#39;minute&#39;
        if maxfreq == None or maxfreq == &#39;second&#39;:
            return 1, &#39;second&#39;</code></pre>
</details>
</dd>
<dt id="mogptk.data.FormatNumber"><code class="flex name class">
<span>class <span class="ident">FormatNumber</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>FormatNumber is the default formatter and takes regular floating point values as input.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class FormatNumber:
    &#34;&#34;&#34;
    FormatNumber is the default formatter and takes regular floating point values as input.
    &#34;&#34;&#34;
    def _format(val):
        return val

    def _parse(val, loc=None):
        try:
            return float(val)
        except ValueError:
            if loc == None:
                raise ValueError(&#34;could not convert input to number&#34;)
            else:
                raise ValueError(&#34;could not convert input to number at %s&#34; % (loc))

    def _parse_duration(val, loc=None):
        return FormatNumber._parse(val, loc)

    def _scale(maxfreq=None):
        return 1, None</code></pre>
</details>
</dd>
<dt id="mogptk.data.TransformDetrend"><code class="flex name class">
<span>class <span class="ident">TransformDetrend</span></span>
<span>(</span><span>data)</span>
</code></dt>
<dd>
<section class="desc"><p>TransformDetrend is a transformer that detrends the data.</p>
<p>TODO : add regression or other order polinomial.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class TransformDetrend:
    &#34;&#34;&#34;
    TransformDetrend is a transformer that detrends the data.

    TODO : add regression or other order polinomial.
    &#34;&#34;&#34;
    def __init__(self, data):
        if data.get_input_dims() != 1:
            raise Exception(&#34;can only remove ranges on one dimensional input data&#34;)

        self.coef = np.polyfit(data.X[:,0], data.Y, 2)
        # reg = Ridge(alpha=0.1, fit_intercept=True)
        # reg.fit(data.X, data.Y)
        # self.trend = reg

    def _forward(self, x, y):
        return y - np.polyval(self.coef, x[:, 0])
        # return y - self.trend.predict(x)
    
    def _backward(self, x, y):
        return y + np.polyval(self.coef, x[:, 0])</code></pre>
</details>
</dd>
<dt id="mogptk.data.TransformLog"><code class="flex name class">
<span>class <span class="ident">TransformLog</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>TransformLog is a transformer that takes the log of the data. Make sure there is no negative data.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class TransformLog:
    &#34;&#34;&#34;
    TransformLog is a transformer that takes the log of the data. Make sure there is no negative data.
    &#34;&#34;&#34;
    def _forward(x, y):
        return np.log(y)
    
    def _backward(x, y):
        return np.exp(y)</code></pre>
</details>
</dd>
<dt id="mogptk.data.TransformNormalize"><code class="flex name class">
<span>class <span class="ident">TransformNormalize</span></span>
<span>(</span><span>data)</span>
</code></dt>
<dd>
<section class="desc"><p>TransformNormalize is a transformer that normalizes the data, so that all Y data is between 0 and 1.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class TransformNormalize:
    &#34;&#34;&#34;
    TransformNormalize is a transformer that normalizes the data, so that all Y data is between 0 and 1.
    &#34;&#34;&#34;
    def __init__(self, data):
        self.ymin = np.amin([self.ymin, np.amin(self.Y)])
        self.ymax = np.amax([self.ymax, np.amax(self.Y)])

    def _forward(self, x, y):
        return (y-self.ymin)/(self.ymax-self.ymin)
    
    def _backward(self, x, y):
        return y*(self.ymax-self.ymin)+self.ymin</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mogptk" href="index.html">mogptk</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mogptk.data.LoadCSV" href="#mogptk.data.LoadCSV">LoadCSV</a></code></li>
<li><code><a title="mogptk.data.LoadFunction" href="#mogptk.data.LoadFunction">LoadFunction</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mogptk.data.Data" href="#mogptk.data.Data">Data</a></code></h4>
<ul class="">
<li><code><a title="mogptk.data.Data.aggregate" href="#mogptk.data.Data.aggregate">aggregate</a></code></li>
<li><code><a title="mogptk.data.Data.copy" href="#mogptk.data.Data.copy">copy</a></code></li>
<li><code><a title="mogptk.data.Data.filter" href="#mogptk.data.Data.filter">filter</a></code></li>
<li><code><a title="mogptk.data.Data.get_all_obs" href="#mogptk.data.Data.get_all_obs">get_all_obs</a></code></li>
<li><code><a title="mogptk.data.Data.get_bnse_estimation" href="#mogptk.data.Data.get_bnse_estimation">get_bnse_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_del_obs" href="#mogptk.data.Data.get_del_obs">get_del_obs</a></code></li>
<li><code><a title="mogptk.data.Data.get_input_dims" href="#mogptk.data.Data.get_input_dims">get_input_dims</a></code></li>
<li><code><a title="mogptk.data.Data.get_ls_estimation" href="#mogptk.data.Data.get_ls_estimation">get_ls_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_nyquist_estimation" href="#mogptk.data.Data.get_nyquist_estimation">get_nyquist_estimation</a></code></li>
<li><code><a title="mogptk.data.Data.get_obs" href="#mogptk.data.Data.get_obs">get_obs</a></code></li>
<li><code><a title="mogptk.data.Data.has_removed_obs" href="#mogptk.data.Data.has_removed_obs">has_removed_obs</a></code></li>
<li><code><a title="mogptk.data.Data.plot" href="#mogptk.data.Data.plot">plot</a></code></li>
<li><code><a title="mogptk.data.Data.plot_spectrum" href="#mogptk.data.Data.plot_spectrum">plot_spectrum</a></code></li>
<li><code><a title="mogptk.data.Data.remove_random_ranges" href="#mogptk.data.Data.remove_random_ranges">remove_random_ranges</a></code></li>
<li><code><a title="mogptk.data.Data.remove_randomly" href="#mogptk.data.Data.remove_randomly">remove_randomly</a></code></li>
<li><code><a title="mogptk.data.Data.remove_range" href="#mogptk.data.Data.remove_range">remove_range</a></code></li>
<li><code><a title="mogptk.data.Data.remove_rel_range" href="#mogptk.data.Data.remove_rel_range">remove_rel_range</a></code></li>
<li><code><a title="mogptk.data.Data.set_function" href="#mogptk.data.Data.set_function">set_function</a></code></li>
<li><code><a title="mogptk.data.Data.set_labels" href="#mogptk.data.Data.set_labels">set_labels</a></code></li>
<li><code><a title="mogptk.data.Data.set_name" href="#mogptk.data.Data.set_name">set_name</a></code></li>
<li><code><a title="mogptk.data.Data.set_pred" href="#mogptk.data.Data.set_pred">set_pred</a></code></li>
<li><code><a title="mogptk.data.Data.set_pred_range" href="#mogptk.data.Data.set_pred_range">set_pred_range</a></code></li>
<li><code><a title="mogptk.data.Data.transform" href="#mogptk.data.Data.transform">transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mogptk.data.FormatDate" href="#mogptk.data.FormatDate">FormatDate</a></code></h4>
</li>
<li>
<h4><code><a title="mogptk.data.FormatDateTime" href="#mogptk.data.FormatDateTime">FormatDateTime</a></code></h4>
</li>
<li>
<h4><code><a title="mogptk.data.FormatNumber" href="#mogptk.data.FormatNumber">FormatNumber</a></code></h4>
</li>
<li>
<h4><code><a title="mogptk.data.TransformDetrend" href="#mogptk.data.TransformDetrend">TransformDetrend</a></code></h4>
</li>
<li>
<h4><code><a title="mogptk.data.TransformLog" href="#mogptk.data.TransformLog">TransformLog</a></code></h4>
</li>
<li>
<h4><code><a title="mogptk.data.TransformNormalize" href="#mogptk.data.TransformNormalize">TransformNormalize</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>