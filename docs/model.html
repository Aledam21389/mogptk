<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>mogptk.model API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mogptk.model</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L0-L372" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import os
import time
import pickle
import numpy as np
import torch
from .serie import Serie
from .dataset import DataSet
from .kernels import GPR
import matplotlib
import matplotlib.pyplot as plt
import matplotlib as mpl
from mpl_toolkits.axes_grid1 import make_axes_locatable

import logging
logger = logging.getLogger(&#39;mogptk&#39;)

eps = 1e-20

def LoadModel(filename):
    &#34;&#34;&#34;
    Load model from a given file that was previously saved with `model.save()`.

    Args:
        filename (str): Filename to load from.

    Examples:
        &gt;&gt;&gt; Load(&#39;filename&#39;)
    &#34;&#34;&#34;
    filename += &#34;.npy&#34; 
    with open(filename, &#39;rb&#39;) as r:
        return pickle.load(r)

class Exact:
    def build(self, kernel, x, y, name=None):
        return GPR(kernel, x, y, name=name)

class Model:
    def __init__(self, dataset, kernel, model=Exact(), name=None):
        &#34;&#34;&#34;
        Base class for Multi-Output Gaussian process models. See subclasses for instantiation.

        Args:
            dataset (mogptk.dataset.DataSet, mogptk.data.Data): DataSet with Data objects for all the channels. When a (list or dict of) Data object is passed, it will automatically be converted to a DataSet.
            name (str): Name of the model.
        &#34;&#34;&#34;
        
        if not isinstance(dataset, DataSet):
            dataset = DataSet(dataset)
        if dataset.get_output_dims() == 0:
            raise Exception(&#34;dataset must have at least one channel&#34;)
        names = [name for name in dataset.get_names() if name is not None]
        if len(set(names)) != len(names):
            raise Exception(&#34;all data channels must have unique names&#34;)

        for channel in dataset:
            for dim in range(channel.get_input_dims()):
                xran = np.max(channel.X[dim].transformed) - np.min(channel.X[dim].transformed)
                if xran &lt; 1e-3:
                    logger.warning(&#34;Very small X range may give problems, it is suggested to scale up your X-axis&#34;)
                elif 1e4 &lt; xran:
                    logger.warning(&#34;Very large X range may give problems, it is suggested to scale down your X-axis&#34;)

        self.name = name
        self.dataset = dataset
        self.kernel = kernel

        X = [np.array([x[channel.mask] for x in channel.X]).T for channel in self.dataset.channels]
        Y = [np.array(channel.Y[channel.mask]) for channel in self.dataset.channels]
        x, y = self._to_kernel_format(X, Y)

        self.model = model.build(kernel, x, y, name)

    ################################################################

    def print_parameters(self):
        &#34;&#34;&#34;
        Print the parameters of the model in a table.

        Examples:
            &gt;&gt;&gt; model.print_parameters()
        &#34;&#34;&#34;
        self.model.print_parameters()

    def get_parameters(self):
        &#34;&#34;&#34;
        Returns all parameters set for the kernel per component.

        Examples:
            &gt;&gt;&gt; params = model.get_parameters()
        &#34;&#34;&#34;
        self.model.parameters()

    def save(self, filename):
        &#34;&#34;&#34;
        Save model to a given file that can then be loaded with `Load()`.

        Args:
            filename (str): Filename to save to, automatically appends &#39;.model&#39;.

        Examples:
            &gt;&gt;&gt; model.save(&#39;filename&#39;)
        &#34;&#34;&#34;
        filename += &#34;.npy&#34; 
        try:
            os.remove(filename)
        except OSError:
            pass
        with open(filename, &#39;wb&#39;) as w:
            pickle.dump(self, w)

    def log_marginal_likelihood(self):
        return self.model.log_marginal_likelihood().detach().item()

    def train(
        self,
        method=&#39;Adam&#39;,
        iters=500,
        verbose=False,
        **kwargs):
        &#34;&#34;&#34;
        Trains the model using the kernel and its parameters.

        For different optimizers, see scipy.optimize.minimize.
        It can be bounded by a maximum number of iterations, disp will output final
        optimization information. When using the &#39;Adam&#39; optimizer, a
        learning_rate can be set.

        Args:
            method (str): Optimizer to use such as LBFGS, Adam, Adagrad, or SGD. Defaults to Adam.
            iters (int): Number of iterations, or maximum in case of LBFGS optimizer. Defaults to 500.
            verbose (bool): Print verbose output about the state of the optimizer.
            **kwargs (dict): Additional dictionary of parameters passed to the PyTorch optimizer. 

        Examples:
            &gt;&gt;&gt; model.train()
            
            &gt;&gt;&gt; model.train(method=&#39;lbfgs&#39;, tolerance_grad=1e-10, tolerance_change=1e-12)
            
            &gt;&gt;&gt; model.train(method=&#39;adam&#39;, lr=1e-4)
        &#34;&#34;&#34;
        if verbose:
            training_points = sum([len(channel.get_train_data()[0]) for channel in self.dataset])
            parameters = sum([int(np.prod(param.shape)) for param in self.model.parameters()])
            print(&#39;\nStarting optimization using&#39;, method)
            print(&#39;‣ Model: {}&#39;.format(self.name))
            print(&#39;‣ Channels: {}&#39;.format(len(self.dataset)))
            if hasattr(self, &#39;Q&#39;):
                print(&#39;‣ Mixtures: {}&#39;.format(self.Q))
            print(&#39;‣ Training points: {}&#39;.format(training_points))
            print(&#39;‣ Parameters: {}&#39;.format(parameters))
            print(&#39;‣ Initial NLL: {:.3f}&#39;.format(-self.model.log_marginal_likelihood().tolist()))
            inital_time = time.time()

        try:
            if method.lower() in (&#39;l-bfgs&#39;, &#39;lbfgs&#39;, &#39;l-bfgs-b&#39;, &#39;lbfgsb&#39;):
                if not &#39;max_iter&#39; in kwargs:
                    kwargs[&#39;max_iter&#39;] = iters
                    iters = 0
                optimizer = torch.optim.LBFGS(self.model.parameters(), **kwargs)
                optimizer.step(lambda: self.model.loss())
                iters = optimizer.state_dict()[&#39;state&#39;][0][&#39;func_evals&#39;]
            elif method.lower() == &#39;adam&#39;:
                if not &#39;lr&#39; in kwargs:
                    kwargs[&#39;lr&#39;] = 0.1
                optimizer = torch.optim.Adam(self.model.parameters(), **kwargs)
                for i in range(iters):
                    loss = self.model.loss()
                    optimizer.step()
            elif method.lower() == &#39;sgd&#39;:
                optimizer = torch.optim.SGD(self.model.parameters(), **kwargs)
                for i in range(iters):
                    loss = self.model.loss()
                    optimizer.step()
            elif method.lower() == &#39;adagrad&#39;:
                optimizer = torch.optim.Adagrad(self.model.parameters(), **kwargs)
                for i in range(iters):
                    loss = self.model.loss()
                    optimizer.step()
            else:
                print(&#34;Unknown optimizer:&#34;, method)
        except Exception as e:
            return

        if verbose:
            elapsed_time = time.time() - inital_time
            print(&#39;\nOptimization finished in {:.2f} minutes&#39;.format(elapsed_time / 60.0))
            print(&#39;‣ Function evaluations: {}&#39;.format(iters))
            print(&#39;‣ Final NLL: {:.3f}&#39;.format(-self.model.log_marginal_likelihood().tolist()))

    ################################################################################
    # Predictions ##################################################################
    ################################################################################

    # TODO: add get_prediction

    def _to_kernel_format(self, X, Y=None):
        &#34;&#34;&#34;
        Return the data vectors in the format as used by the kernels.

        Returns:
            numpy.ndarray: X data of shape (n,2) where X[:,0] contains the channel indices and X[:,1] the X values.
            numpy.ndarray: Y data.
        &#34;&#34;&#34;
        if isinstance(X, dict):
            x_dict = X
            X = self.dataset.get_prediction()
            for name, channel_x in x_dict.items():
                X[self.dataset.get_index(name)] = channel_x
        elif isinstance(X, np.ndarray):
            X = list(X)
        elif not isinstance(X, list):
            raise ValueError(&#34;X must be a list, dict or numpy.ndarray&#34;)
        if len(X) != len(self.dataset.channels):
            raise ValueError(&#34;X must be a list of shape (n,input_dims) for each channel&#34;)
        X_orig = [channel_x.copy() for channel_x in X]
        for j, channel_x in enumerate(X):
            input_dims = self.dataset.get_input_dims()[j]
            if isinstance(channel_x, list):
                channel_x = np.array(channel_x)
            elif not isinstance(channel_x, np.ndarray):
                raise ValueError(&#34;X must be a list of lists or numpy.ndarrays&#34;)
            if channel_x.ndim == 1:
                channel_x = channel_x.reshape(-1, 1)
            if channel_x.ndim != 2 or channel_x.shape[1] != input_dims:
                raise ValueError(&#34;X must be a list of shape (n,input_dims) for each channel&#34;)
            X[j] = np.array([self.dataset[j].X[i].transform(channel_x[:,i]) for i in range(input_dims)]).T

        chan = [i * np.ones(len(X[i])) for i in range(len(X))]
        chan = np.concatenate(chan).reshape(-1, 1)
        if len(X) == 0:
            x = np.array([])
        else:
            x = np.concatenate(X, axis=0)
            x = np.concatenate([chan, x], axis=1)
        if Y is None:
            return x

        if isinstance(Y, np.ndarray):
            Y = list(Y)
        elif not isinstance(Y, list):
            raise ValueError(&#34;Y must be a list or numpy.ndarray&#34;)
        if len(Y) != len(self.dataset.channels):
            raise ValueError(&#34;Y must be a list of shape (n,) for each channel&#34;)
        for j, channel_y in enumerate(Y):
            if channel_y.ndim != 1:
                raise ValueError(&#34;Y must be a list of shape (n,) for each channel&#34;)
            if channel_y.shape[0] != X[j].shape[0]:
                raise ValueError(&#34;Y must have the same number of data points per channel as X&#34;)
            Y[j] = self.dataset[j].Y.transform(channel_y, x=X_orig[j])
        if len(Y) == 0:
            y = np.array([])
        else:
            y = np.concatenate(Y, axis=0).reshape(-1, 1)
        return x, y

    def predict(self, X=None, sigma=2.0, transformed=False):
        &#34;&#34;&#34;
        Predict with model.

        Will make a prediction using x as input. If no input value is passed, the prediction will 
        be made with atribute self.X_pred that can be setted with other functions.

        Args:
            X (list, dict, optional): Dictionary where keys are channel index and elements numpy arrays with channel inputs. If passed, results will be returned and not saved in the data set for later retrieval.
            sigma (float, optional): The uncertainty interval&#39;s number of standard deviations.
            transformed (boolean, optional): Return transformed data as used for training.

        Returns:
            numpy.ndarray: Y mean prediction of shape (n,).
            numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
            numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).

        Examples:
            &gt;&gt;&gt; model.predict(plot=True)
        &#34;&#34;&#34;
        save = X is None
        if save:
            X = self.dataset.get_prediction_x()
        x = self._to_kernel_format(X)

        mu, var = self.model.predict(x)

        i = 0
        Mu = []
        Var = []
        for j in range(self.dataset.get_output_dims()):
            N = X[j].shape[0]
            Mu.append(np.squeeze(mu[i:i+N]))
            Var.append(np.squeeze(var[i:i+N]))
            i += N

        if save:
            for j in range(self.dataset.get_output_dims()):
                #self.dataset[j].X_pred = [Serie(X[j][:,i], self.dataset[j].X[i].transformers) for i in range(self.dataset[j].get_input_dims())]
                self.dataset[j].Y_mu_pred[self.name] = Mu[j]
                self.dataset[j].Y_var_pred[self.name] = Var[j]
        else:
            Lower = []
            Upper = []
            for j in range(self.dataset.get_output_dims()):
                Lower.append(Mu[j] - sigma*np.sqrt(Var[j]))
                Upper.append(Mu[j] + sigma*np.sqrt(Var[j]))

            X_pred = [np.array([self.dataset[j].X[i].transform(X[j][:,i]) for i in range(self.dataset[j].get_input_dims())]) for channel in range(self.dataset.get_output_dims())]
            if transformed:
                return X_pred, Mu, Lower, Upper
            else:
                for j in range(self.dataset.get_output_dims()):
                    Mu[j] = self.dataset[j].Y.detransform(Mu[j], X[j])
                    Lower[j] = self.dataset[j].Y.detransform(Lower[j], X[j])
                    Upper[j] = self.dataset[j].Y.detransform(Upper[j], X[j])
                return X, Mu, Lower, Upper

    def plot(self, xmin=None, xmax=None, n_points=31, title=None, figsize=(12,12)):
        &#34;&#34;&#34;
        Plot the gram matrix of associated kernel.

        The gram matrix is evaluated depending a equally spaced grid 
        between [xmin_i, xmax_i] for i = 0, ..., n_channels.

        Args:
            xmin (float, list, array): Interval minimum.
            xmax (float, list, array): Interval maximum.
            n_points (int): Number of points per channel.
            title (str): Figure title.
            figsize (tuple): Figure size.
        
        Returns:
            fig: Matplotlib figure.
            ax: Matplotlib axis.
        &#34;&#34;&#34;
        if xmin is None:
            xmin = [np.array(data.X[0].transformed).min() for data in self.dataset]
        if xmax is None:
            xmax = [np.array(data.X[0].transformed).max() for data in self.dataset]

        M = len(self.dataset)
        if not isinstance(xmin, (list, np.ndarray)):
            xmin = [xmin] * M
        if not isinstance(xmax, (list, np.ndarray)):
            xmax = [xmax] * M

        X = np.zeros((M*n_points, 2))
        X[:,0] = np.repeat(np.arange(M), n_points)
        for m in range(M):
            X[m*n_points:(m+1)*n_points,1] = np.linspace(xmin[m], xmax[m], n_points)
            
        fig, ax = plt.subplots(1, 1, figsize=figsize, constrained_layout=True)
        if title is not None:
            fig.suptitle(title, fontsize=18)

        K_gram = self.model.K(X)
        color_range = np.abs(K_gram).max()
        norm = mpl.colors.Normalize(vmin=-color_range, vmax=color_range)
        im = ax.matshow(K_gram, cmap=&#39;coolwarm&#39;, norm=norm)

        divider = make_axes_locatable(ax)
        cax = divider.append_axes(&#34;right&#34;, size=&#34;5%&#34;, pad=0.3)
        fig.colorbar(im, cax=cax)

        # Major ticks every 20, minor ticks every 5
        major_ticks = np.arange(-0.5, M * n_points, n_points)
        minor_ticks = np.arange(-0.5, M * n_points, 2)

        ax.set_xticks(major_ticks)
        ax.set_yticks(major_ticks)
        ax.grid(which=&#39;major&#39;, lw=1.5, c=&#39;k&#39;)
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, length=0)

        return fig, ax</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mogptk.model.LoadModel"><code class="name flex">
<span>def <span class="ident">LoadModel</span></span>(<span>filename)</span>
</code></dt>
<dd>
<section class="desc"><p>Load model from a given file that was previously saved with <code>model.save()</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Filename to load from.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; Load('filename')
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L19-L31" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def LoadModel(filename):
    &#34;&#34;&#34;
    Load model from a given file that was previously saved with `model.save()`.

    Args:
        filename (str): Filename to load from.

    Examples:
        &gt;&gt;&gt; Load(&#39;filename&#39;)
    &#34;&#34;&#34;
    filename += &#34;.npy&#34; 
    with open(filename, &#39;rb&#39;) as r:
        return pickle.load(r)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mogptk.model.Exact"><code class="flex name class">
<span>class <span class="ident">Exact</span></span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L33-L35" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Exact:
    def build(self, kernel, x, y, name=None):
        return GPR(kernel, x, y, name=name)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="mogptk.model.Exact.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, kernel, x, y, name=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L34-L35" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def build(self, kernel, x, y, name=None):
    return GPR(kernel, x, y, name=name)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mogptk.model.Model"><code class="flex name class">
<span>class <span class="ident">Model</span></span>
<span>(</span><span>dataset, kernel, model=&lt;mogptk.model.Exact object&gt;, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Base class for Multi-Output Gaussian process models. See subclasses for instantiation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<a title="mogptk.dataset.DataSet" href="dataset.html#mogptk.dataset.DataSet"><code>DataSet</code></a>, <a title="mogptk.data.Data" href="data.html#mogptk.data.Data"><code>Data</code></a></dt>
<dd>DataSet with Data objects for all the channels. When a (list or dict of) Data object is passed, it will automatically be converted to a DataSet.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the model.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L37-L372" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Model:
    def __init__(self, dataset, kernel, model=Exact(), name=None):
        &#34;&#34;&#34;
        Base class for Multi-Output Gaussian process models. See subclasses for instantiation.

        Args:
            dataset (mogptk.dataset.DataSet, mogptk.data.Data): DataSet with Data objects for all the channels. When a (list or dict of) Data object is passed, it will automatically be converted to a DataSet.
            name (str): Name of the model.
        &#34;&#34;&#34;
        
        if not isinstance(dataset, DataSet):
            dataset = DataSet(dataset)
        if dataset.get_output_dims() == 0:
            raise Exception(&#34;dataset must have at least one channel&#34;)
        names = [name for name in dataset.get_names() if name is not None]
        if len(set(names)) != len(names):
            raise Exception(&#34;all data channels must have unique names&#34;)

        for channel in dataset:
            for dim in range(channel.get_input_dims()):
                xran = np.max(channel.X[dim].transformed) - np.min(channel.X[dim].transformed)
                if xran &lt; 1e-3:
                    logger.warning(&#34;Very small X range may give problems, it is suggested to scale up your X-axis&#34;)
                elif 1e4 &lt; xran:
                    logger.warning(&#34;Very large X range may give problems, it is suggested to scale down your X-axis&#34;)

        self.name = name
        self.dataset = dataset
        self.kernel = kernel

        X = [np.array([x[channel.mask] for x in channel.X]).T for channel in self.dataset.channels]
        Y = [np.array(channel.Y[channel.mask]) for channel in self.dataset.channels]
        x, y = self._to_kernel_format(X, Y)

        self.model = model.build(kernel, x, y, name)

    ################################################################

    def print_parameters(self):
        &#34;&#34;&#34;
        Print the parameters of the model in a table.

        Examples:
            &gt;&gt;&gt; model.print_parameters()
        &#34;&#34;&#34;
        self.model.print_parameters()

    def get_parameters(self):
        &#34;&#34;&#34;
        Returns all parameters set for the kernel per component.

        Examples:
            &gt;&gt;&gt; params = model.get_parameters()
        &#34;&#34;&#34;
        self.model.parameters()

    def save(self, filename):
        &#34;&#34;&#34;
        Save model to a given file that can then be loaded with `Load()`.

        Args:
            filename (str): Filename to save to, automatically appends &#39;.model&#39;.

        Examples:
            &gt;&gt;&gt; model.save(&#39;filename&#39;)
        &#34;&#34;&#34;
        filename += &#34;.npy&#34; 
        try:
            os.remove(filename)
        except OSError:
            pass
        with open(filename, &#39;wb&#39;) as w:
            pickle.dump(self, w)

    def log_marginal_likelihood(self):
        return self.model.log_marginal_likelihood().detach().item()

    def train(
        self,
        method=&#39;Adam&#39;,
        iters=500,
        verbose=False,
        **kwargs):
        &#34;&#34;&#34;
        Trains the model using the kernel and its parameters.

        For different optimizers, see scipy.optimize.minimize.
        It can be bounded by a maximum number of iterations, disp will output final
        optimization information. When using the &#39;Adam&#39; optimizer, a
        learning_rate can be set.

        Args:
            method (str): Optimizer to use such as LBFGS, Adam, Adagrad, or SGD. Defaults to Adam.
            iters (int): Number of iterations, or maximum in case of LBFGS optimizer. Defaults to 500.
            verbose (bool): Print verbose output about the state of the optimizer.
            **kwargs (dict): Additional dictionary of parameters passed to the PyTorch optimizer. 

        Examples:
            &gt;&gt;&gt; model.train()
            
            &gt;&gt;&gt; model.train(method=&#39;lbfgs&#39;, tolerance_grad=1e-10, tolerance_change=1e-12)
            
            &gt;&gt;&gt; model.train(method=&#39;adam&#39;, lr=1e-4)
        &#34;&#34;&#34;
        if verbose:
            training_points = sum([len(channel.get_train_data()[0]) for channel in self.dataset])
            parameters = sum([int(np.prod(param.shape)) for param in self.model.parameters()])
            print(&#39;\nStarting optimization using&#39;, method)
            print(&#39;‣ Model: {}&#39;.format(self.name))
            print(&#39;‣ Channels: {}&#39;.format(len(self.dataset)))
            if hasattr(self, &#39;Q&#39;):
                print(&#39;‣ Mixtures: {}&#39;.format(self.Q))
            print(&#39;‣ Training points: {}&#39;.format(training_points))
            print(&#39;‣ Parameters: {}&#39;.format(parameters))
            print(&#39;‣ Initial NLL: {:.3f}&#39;.format(-self.model.log_marginal_likelihood().tolist()))
            inital_time = time.time()

        try:
            if method.lower() in (&#39;l-bfgs&#39;, &#39;lbfgs&#39;, &#39;l-bfgs-b&#39;, &#39;lbfgsb&#39;):
                if not &#39;max_iter&#39; in kwargs:
                    kwargs[&#39;max_iter&#39;] = iters
                    iters = 0
                optimizer = torch.optim.LBFGS(self.model.parameters(), **kwargs)
                optimizer.step(lambda: self.model.loss())
                iters = optimizer.state_dict()[&#39;state&#39;][0][&#39;func_evals&#39;]
            elif method.lower() == &#39;adam&#39;:
                if not &#39;lr&#39; in kwargs:
                    kwargs[&#39;lr&#39;] = 0.1
                optimizer = torch.optim.Adam(self.model.parameters(), **kwargs)
                for i in range(iters):
                    loss = self.model.loss()
                    optimizer.step()
            elif method.lower() == &#39;sgd&#39;:
                optimizer = torch.optim.SGD(self.model.parameters(), **kwargs)
                for i in range(iters):
                    loss = self.model.loss()
                    optimizer.step()
            elif method.lower() == &#39;adagrad&#39;:
                optimizer = torch.optim.Adagrad(self.model.parameters(), **kwargs)
                for i in range(iters):
                    loss = self.model.loss()
                    optimizer.step()
            else:
                print(&#34;Unknown optimizer:&#34;, method)
        except Exception as e:
            return

        if verbose:
            elapsed_time = time.time() - inital_time
            print(&#39;\nOptimization finished in {:.2f} minutes&#39;.format(elapsed_time / 60.0))
            print(&#39;‣ Function evaluations: {}&#39;.format(iters))
            print(&#39;‣ Final NLL: {:.3f}&#39;.format(-self.model.log_marginal_likelihood().tolist()))

    ################################################################################
    # Predictions ##################################################################
    ################################################################################

    # TODO: add get_prediction

    def _to_kernel_format(self, X, Y=None):
        &#34;&#34;&#34;
        Return the data vectors in the format as used by the kernels.

        Returns:
            numpy.ndarray: X data of shape (n,2) where X[:,0] contains the channel indices and X[:,1] the X values.
            numpy.ndarray: Y data.
        &#34;&#34;&#34;
        if isinstance(X, dict):
            x_dict = X
            X = self.dataset.get_prediction()
            for name, channel_x in x_dict.items():
                X[self.dataset.get_index(name)] = channel_x
        elif isinstance(X, np.ndarray):
            X = list(X)
        elif not isinstance(X, list):
            raise ValueError(&#34;X must be a list, dict or numpy.ndarray&#34;)
        if len(X) != len(self.dataset.channels):
            raise ValueError(&#34;X must be a list of shape (n,input_dims) for each channel&#34;)
        X_orig = [channel_x.copy() for channel_x in X]
        for j, channel_x in enumerate(X):
            input_dims = self.dataset.get_input_dims()[j]
            if isinstance(channel_x, list):
                channel_x = np.array(channel_x)
            elif not isinstance(channel_x, np.ndarray):
                raise ValueError(&#34;X must be a list of lists or numpy.ndarrays&#34;)
            if channel_x.ndim == 1:
                channel_x = channel_x.reshape(-1, 1)
            if channel_x.ndim != 2 or channel_x.shape[1] != input_dims:
                raise ValueError(&#34;X must be a list of shape (n,input_dims) for each channel&#34;)
            X[j] = np.array([self.dataset[j].X[i].transform(channel_x[:,i]) for i in range(input_dims)]).T

        chan = [i * np.ones(len(X[i])) for i in range(len(X))]
        chan = np.concatenate(chan).reshape(-1, 1)
        if len(X) == 0:
            x = np.array([])
        else:
            x = np.concatenate(X, axis=0)
            x = np.concatenate([chan, x], axis=1)
        if Y is None:
            return x

        if isinstance(Y, np.ndarray):
            Y = list(Y)
        elif not isinstance(Y, list):
            raise ValueError(&#34;Y must be a list or numpy.ndarray&#34;)
        if len(Y) != len(self.dataset.channels):
            raise ValueError(&#34;Y must be a list of shape (n,) for each channel&#34;)
        for j, channel_y in enumerate(Y):
            if channel_y.ndim != 1:
                raise ValueError(&#34;Y must be a list of shape (n,) for each channel&#34;)
            if channel_y.shape[0] != X[j].shape[0]:
                raise ValueError(&#34;Y must have the same number of data points per channel as X&#34;)
            Y[j] = self.dataset[j].Y.transform(channel_y, x=X_orig[j])
        if len(Y) == 0:
            y = np.array([])
        else:
            y = np.concatenate(Y, axis=0).reshape(-1, 1)
        return x, y

    def predict(self, X=None, sigma=2.0, transformed=False):
        &#34;&#34;&#34;
        Predict with model.

        Will make a prediction using x as input. If no input value is passed, the prediction will 
        be made with atribute self.X_pred that can be setted with other functions.

        Args:
            X (list, dict, optional): Dictionary where keys are channel index and elements numpy arrays with channel inputs. If passed, results will be returned and not saved in the data set for later retrieval.
            sigma (float, optional): The uncertainty interval&#39;s number of standard deviations.
            transformed (boolean, optional): Return transformed data as used for training.

        Returns:
            numpy.ndarray: Y mean prediction of shape (n,).
            numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
            numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).

        Examples:
            &gt;&gt;&gt; model.predict(plot=True)
        &#34;&#34;&#34;
        save = X is None
        if save:
            X = self.dataset.get_prediction_x()
        x = self._to_kernel_format(X)

        mu, var = self.model.predict(x)

        i = 0
        Mu = []
        Var = []
        for j in range(self.dataset.get_output_dims()):
            N = X[j].shape[0]
            Mu.append(np.squeeze(mu[i:i+N]))
            Var.append(np.squeeze(var[i:i+N]))
            i += N

        if save:
            for j in range(self.dataset.get_output_dims()):
                #self.dataset[j].X_pred = [Serie(X[j][:,i], self.dataset[j].X[i].transformers) for i in range(self.dataset[j].get_input_dims())]
                self.dataset[j].Y_mu_pred[self.name] = Mu[j]
                self.dataset[j].Y_var_pred[self.name] = Var[j]
        else:
            Lower = []
            Upper = []
            for j in range(self.dataset.get_output_dims()):
                Lower.append(Mu[j] - sigma*np.sqrt(Var[j]))
                Upper.append(Mu[j] + sigma*np.sqrt(Var[j]))

            X_pred = [np.array([self.dataset[j].X[i].transform(X[j][:,i]) for i in range(self.dataset[j].get_input_dims())]) for channel in range(self.dataset.get_output_dims())]
            if transformed:
                return X_pred, Mu, Lower, Upper
            else:
                for j in range(self.dataset.get_output_dims()):
                    Mu[j] = self.dataset[j].Y.detransform(Mu[j], X[j])
                    Lower[j] = self.dataset[j].Y.detransform(Lower[j], X[j])
                    Upper[j] = self.dataset[j].Y.detransform(Upper[j], X[j])
                return X, Mu, Lower, Upper

    def plot(self, xmin=None, xmax=None, n_points=31, title=None, figsize=(12,12)):
        &#34;&#34;&#34;
        Plot the gram matrix of associated kernel.

        The gram matrix is evaluated depending a equally spaced grid 
        between [xmin_i, xmax_i] for i = 0, ..., n_channels.

        Args:
            xmin (float, list, array): Interval minimum.
            xmax (float, list, array): Interval maximum.
            n_points (int): Number of points per channel.
            title (str): Figure title.
            figsize (tuple): Figure size.
        
        Returns:
            fig: Matplotlib figure.
            ax: Matplotlib axis.
        &#34;&#34;&#34;
        if xmin is None:
            xmin = [np.array(data.X[0].transformed).min() for data in self.dataset]
        if xmax is None:
            xmax = [np.array(data.X[0].transformed).max() for data in self.dataset]

        M = len(self.dataset)
        if not isinstance(xmin, (list, np.ndarray)):
            xmin = [xmin] * M
        if not isinstance(xmax, (list, np.ndarray)):
            xmax = [xmax] * M

        X = np.zeros((M*n_points, 2))
        X[:,0] = np.repeat(np.arange(M), n_points)
        for m in range(M):
            X[m*n_points:(m+1)*n_points,1] = np.linspace(xmin[m], xmax[m], n_points)
            
        fig, ax = plt.subplots(1, 1, figsize=figsize, constrained_layout=True)
        if title is not None:
            fig.suptitle(title, fontsize=18)

        K_gram = self.model.K(X)
        color_range = np.abs(K_gram).max()
        norm = mpl.colors.Normalize(vmin=-color_range, vmax=color_range)
        im = ax.matshow(K_gram, cmap=&#39;coolwarm&#39;, norm=norm)

        divider = make_axes_locatable(ax)
        cax = divider.append_axes(&#34;right&#34;, size=&#34;5%&#34;, pad=0.3)
        fig.colorbar(im, cax=cax)

        # Major ticks every 20, minor ticks every 5
        major_ticks = np.arange(-0.5, M * n_points, n_points)
        minor_ticks = np.arange(-0.5, M * n_points, 2)

        ax.set_xticks(major_ticks)
        ax.set_yticks(major_ticks)
        ax.grid(which=&#39;major&#39;, lw=1.5, c=&#39;k&#39;)
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, length=0)

        return fig, ax</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mogptk.conv.CONV" href="conv.html#mogptk.conv.CONV">CONV</a></li>
<li><a title="mogptk.csm.CSM" href="csm.html#mogptk.csm.CSM">CSM</a></li>
<li><a title="mogptk.mosm.MOSM" href="mosm.html#mogptk.mosm.MOSM">MOSM</a></li>
<li><a title="mogptk.sm.SM" href="sm.html#mogptk.sm.SM">SM</a></li>
<li><a title="mogptk.sm_lmc.SM_LMC" href="sm_lmc.html#mogptk.sm_lmc.SM_LMC">SM_LMC</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mogptk.model.Model.get_parameters"><code class="name flex">
<span>def <span class="ident">get_parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns all parameters set for the kernel per component.</p>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; params = model.get_parameters()
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L84-L91" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_parameters(self):
    &#34;&#34;&#34;
    Returns all parameters set for the kernel per component.

    Examples:
        &gt;&gt;&gt; params = model.get_parameters()
    &#34;&#34;&#34;
    self.model.parameters()</code></pre>
</details>
</dd>
<dt id="mogptk.model.Model.log_marginal_likelihood"><code class="name flex">
<span>def <span class="ident">log_marginal_likelihood</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L111-L112" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def log_marginal_likelihood(self):
    return self.model.log_marginal_likelihood().detach().item()</code></pre>
</details>
</dd>
<dt id="mogptk.model.Model.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, xmin=None, xmax=None, n_points=31, title=None, figsize=(12, 12))</span>
</code></dt>
<dd>
<section class="desc"><p>Plot the gram matrix of associated kernel.</p>
<p>The gram matrix is evaluated depending a equally spaced grid
between [xmin_i, xmax_i] for i = 0, &hellip;, n_channels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>xmin</code></strong> :&ensp;<code>float</code>, <code>list</code>, <code>array</code></dt>
<dd>Interval minimum.</dd>
<dt><strong><code>xmax</code></strong> :&ensp;<code>float</code>, <code>list</code>, <code>array</code></dt>
<dd>Interval maximum.</dd>
<dt><strong><code>n_points</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points per channel.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code></dt>
<dd>Figure title.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Figure size.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong></dt>
<dd>Matplotlib figure.</dd>
<dt><strong><code>ax</code></strong></dt>
<dd>Matplotlib axis.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L314-L372" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self, xmin=None, xmax=None, n_points=31, title=None, figsize=(12,12)):
    &#34;&#34;&#34;
    Plot the gram matrix of associated kernel.

    The gram matrix is evaluated depending a equally spaced grid 
    between [xmin_i, xmax_i] for i = 0, ..., n_channels.

    Args:
        xmin (float, list, array): Interval minimum.
        xmax (float, list, array): Interval maximum.
        n_points (int): Number of points per channel.
        title (str): Figure title.
        figsize (tuple): Figure size.
    
    Returns:
        fig: Matplotlib figure.
        ax: Matplotlib axis.
    &#34;&#34;&#34;
    if xmin is None:
        xmin = [np.array(data.X[0].transformed).min() for data in self.dataset]
    if xmax is None:
        xmax = [np.array(data.X[0].transformed).max() for data in self.dataset]

    M = len(self.dataset)
    if not isinstance(xmin, (list, np.ndarray)):
        xmin = [xmin] * M
    if not isinstance(xmax, (list, np.ndarray)):
        xmax = [xmax] * M

    X = np.zeros((M*n_points, 2))
    X[:,0] = np.repeat(np.arange(M), n_points)
    for m in range(M):
        X[m*n_points:(m+1)*n_points,1] = np.linspace(xmin[m], xmax[m], n_points)
        
    fig, ax = plt.subplots(1, 1, figsize=figsize, constrained_layout=True)
    if title is not None:
        fig.suptitle(title, fontsize=18)

    K_gram = self.model.K(X)
    color_range = np.abs(K_gram).max()
    norm = mpl.colors.Normalize(vmin=-color_range, vmax=color_range)
    im = ax.matshow(K_gram, cmap=&#39;coolwarm&#39;, norm=norm)

    divider = make_axes_locatable(ax)
    cax = divider.append_axes(&#34;right&#34;, size=&#34;5%&#34;, pad=0.3)
    fig.colorbar(im, cax=cax)

    # Major ticks every 20, minor ticks every 5
    major_ticks = np.arange(-0.5, M * n_points, n_points)
    minor_ticks = np.arange(-0.5, M * n_points, 2)

    ax.set_xticks(major_ticks)
    ax.set_yticks(major_ticks)
    ax.grid(which=&#39;major&#39;, lw=1.5, c=&#39;k&#39;)
    ax.set_xticklabels([])
    ax.set_yticklabels([])
    ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, length=0)

    return fig, ax</code></pre>
</details>
</dd>
<dt id="mogptk.model.Model.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X=None, sigma=2.0, transformed=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Predict with model.</p>
<p>Will make a prediction using x as input. If no input value is passed, the prediction will
be made with atribute self.X_pred that can be setted with other functions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>list</code>, <code>dict</code>, optional</dt>
<dd>Dictionary where keys are channel index and elements numpy arrays with channel inputs. If passed, results will be returned and not saved in the data set for later retrieval.</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The uncertainty interval's number of standard deviations.</dd>
<dt><strong><code>transformed</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Return transformed data as used for training.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>numpy.ndarray: Y mean prediction of shape (n,).
numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).</p>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; model.predict(plot=True)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L256-L312" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def predict(self, X=None, sigma=2.0, transformed=False):
    &#34;&#34;&#34;
    Predict with model.

    Will make a prediction using x as input. If no input value is passed, the prediction will 
    be made with atribute self.X_pred that can be setted with other functions.

    Args:
        X (list, dict, optional): Dictionary where keys are channel index and elements numpy arrays with channel inputs. If passed, results will be returned and not saved in the data set for later retrieval.
        sigma (float, optional): The uncertainty interval&#39;s number of standard deviations.
        transformed (boolean, optional): Return transformed data as used for training.

    Returns:
        numpy.ndarray: Y mean prediction of shape (n,).
        numpy.ndarray: Y lower prediction of uncertainty interval of shape (n,).
        numpy.ndarray: Y upper prediction of uncertainty interval of shape (n,).

    Examples:
        &gt;&gt;&gt; model.predict(plot=True)
    &#34;&#34;&#34;
    save = X is None
    if save:
        X = self.dataset.get_prediction_x()
    x = self._to_kernel_format(X)

    mu, var = self.model.predict(x)

    i = 0
    Mu = []
    Var = []
    for j in range(self.dataset.get_output_dims()):
        N = X[j].shape[0]
        Mu.append(np.squeeze(mu[i:i+N]))
        Var.append(np.squeeze(var[i:i+N]))
        i += N

    if save:
        for j in range(self.dataset.get_output_dims()):
            #self.dataset[j].X_pred = [Serie(X[j][:,i], self.dataset[j].X[i].transformers) for i in range(self.dataset[j].get_input_dims())]
            self.dataset[j].Y_mu_pred[self.name] = Mu[j]
            self.dataset[j].Y_var_pred[self.name] = Var[j]
    else:
        Lower = []
        Upper = []
        for j in range(self.dataset.get_output_dims()):
            Lower.append(Mu[j] - sigma*np.sqrt(Var[j]))
            Upper.append(Mu[j] + sigma*np.sqrt(Var[j]))

        X_pred = [np.array([self.dataset[j].X[i].transform(X[j][:,i]) for i in range(self.dataset[j].get_input_dims())]) for channel in range(self.dataset.get_output_dims())]
        if transformed:
            return X_pred, Mu, Lower, Upper
        else:
            for j in range(self.dataset.get_output_dims()):
                Mu[j] = self.dataset[j].Y.detransform(Mu[j], X[j])
                Lower[j] = self.dataset[j].Y.detransform(Lower[j], X[j])
                Upper[j] = self.dataset[j].Y.detransform(Upper[j], X[j])
            return X, Mu, Lower, Upper</code></pre>
</details>
</dd>
<dt id="mogptk.model.Model.print_parameters"><code class="name flex">
<span>def <span class="ident">print_parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Print the parameters of the model in a table.</p>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; model.print_parameters()
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L75-L82" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def print_parameters(self):
    &#34;&#34;&#34;
    Print the parameters of the model in a table.

    Examples:
        &gt;&gt;&gt; model.print_parameters()
    &#34;&#34;&#34;
    self.model.print_parameters()</code></pre>
</details>
</dd>
<dt id="mogptk.model.Model.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<section class="desc"><p>Save model to a given file that can then be loaded with <code>Load()</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Filename to save to, automatically appends '.model'.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; model.save('filename')
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L93-L109" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def save(self, filename):
    &#34;&#34;&#34;
    Save model to a given file that can then be loaded with `Load()`.

    Args:
        filename (str): Filename to save to, automatically appends &#39;.model&#39;.

    Examples:
        &gt;&gt;&gt; model.save(&#39;filename&#39;)
    &#34;&#34;&#34;
    filename += &#34;.npy&#34; 
    try:
        os.remove(filename)
    except OSError:
        pass
    with open(filename, &#39;wb&#39;) as w:
        pickle.dump(self, w)</code></pre>
</details>
</dd>
<dt id="mogptk.model.Model.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, method='Adam', iters=500, verbose=False, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Trains the model using the kernel and its parameters.</p>
<p>For different optimizers, see scipy.optimize.minimize.
It can be bounded by a maximum number of iterations, disp will output final
optimization information. When using the 'Adam' optimizer, a
learning_rate can be set.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Optimizer to use such as LBFGS, Adam, Adagrad, or SGD. Defaults to Adam.</dd>
<dt><strong><code>iters</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of iterations, or maximum in case of LBFGS optimizer. Defaults to 500.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code></dt>
<dd>Print verbose output about the state of the optimizer.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Additional dictionary of parameters passed to the PyTorch optimizer. </dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; model.train()

&gt;&gt;&gt; model.train(method='lbfgs', tolerance_grad=1e-10, tolerance_change=1e-12)

&gt;&gt;&gt; model.train(method='adam', lr=1e-4)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/78bafe783f7fa50837056832b8d4498935d9a97a/mogptk/model.py#L114-L188" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def train(
    self,
    method=&#39;Adam&#39;,
    iters=500,
    verbose=False,
    **kwargs):
    &#34;&#34;&#34;
    Trains the model using the kernel and its parameters.

    For different optimizers, see scipy.optimize.minimize.
    It can be bounded by a maximum number of iterations, disp will output final
    optimization information. When using the &#39;Adam&#39; optimizer, a
    learning_rate can be set.

    Args:
        method (str): Optimizer to use such as LBFGS, Adam, Adagrad, or SGD. Defaults to Adam.
        iters (int): Number of iterations, or maximum in case of LBFGS optimizer. Defaults to 500.
        verbose (bool): Print verbose output about the state of the optimizer.
        **kwargs (dict): Additional dictionary of parameters passed to the PyTorch optimizer. 

    Examples:
        &gt;&gt;&gt; model.train()
        
        &gt;&gt;&gt; model.train(method=&#39;lbfgs&#39;, tolerance_grad=1e-10, tolerance_change=1e-12)
        
        &gt;&gt;&gt; model.train(method=&#39;adam&#39;, lr=1e-4)
    &#34;&#34;&#34;
    if verbose:
        training_points = sum([len(channel.get_train_data()[0]) for channel in self.dataset])
        parameters = sum([int(np.prod(param.shape)) for param in self.model.parameters()])
        print(&#39;\nStarting optimization using&#39;, method)
        print(&#39;‣ Model: {}&#39;.format(self.name))
        print(&#39;‣ Channels: {}&#39;.format(len(self.dataset)))
        if hasattr(self, &#39;Q&#39;):
            print(&#39;‣ Mixtures: {}&#39;.format(self.Q))
        print(&#39;‣ Training points: {}&#39;.format(training_points))
        print(&#39;‣ Parameters: {}&#39;.format(parameters))
        print(&#39;‣ Initial NLL: {:.3f}&#39;.format(-self.model.log_marginal_likelihood().tolist()))
        inital_time = time.time()

    try:
        if method.lower() in (&#39;l-bfgs&#39;, &#39;lbfgs&#39;, &#39;l-bfgs-b&#39;, &#39;lbfgsb&#39;):
            if not &#39;max_iter&#39; in kwargs:
                kwargs[&#39;max_iter&#39;] = iters
                iters = 0
            optimizer = torch.optim.LBFGS(self.model.parameters(), **kwargs)
            optimizer.step(lambda: self.model.loss())
            iters = optimizer.state_dict()[&#39;state&#39;][0][&#39;func_evals&#39;]
        elif method.lower() == &#39;adam&#39;:
            if not &#39;lr&#39; in kwargs:
                kwargs[&#39;lr&#39;] = 0.1
            optimizer = torch.optim.Adam(self.model.parameters(), **kwargs)
            for i in range(iters):
                loss = self.model.loss()
                optimizer.step()
        elif method.lower() == &#39;sgd&#39;:
            optimizer = torch.optim.SGD(self.model.parameters(), **kwargs)
            for i in range(iters):
                loss = self.model.loss()
                optimizer.step()
        elif method.lower() == &#39;adagrad&#39;:
            optimizer = torch.optim.Adagrad(self.model.parameters(), **kwargs)
            for i in range(iters):
                loss = self.model.loss()
                optimizer.step()
        else:
            print(&#34;Unknown optimizer:&#34;, method)
    except Exception as e:
        return

    if verbose:
        elapsed_time = time.time() - inital_time
        print(&#39;\nOptimization finished in {:.2f} minutes&#39;.format(elapsed_time / 60.0))
        print(&#39;‣ Function evaluations: {}&#39;.format(iters))
        print(&#39;‣ Final NLL: {:.3f}&#39;.format(-self.model.log_marginal_likelihood().tolist()))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mogptk" href="index.html">mogptk</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mogptk.model.LoadModel" href="#mogptk.model.LoadModel">LoadModel</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mogptk.model.Exact" href="#mogptk.model.Exact">Exact</a></code></h4>
<ul class="">
<li><code><a title="mogptk.model.Exact.build" href="#mogptk.model.Exact.build">build</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mogptk.model.Model" href="#mogptk.model.Model">Model</a></code></h4>
<ul class="">
<li><code><a title="mogptk.model.Model.get_parameters" href="#mogptk.model.Model.get_parameters">get_parameters</a></code></li>
<li><code><a title="mogptk.model.Model.log_marginal_likelihood" href="#mogptk.model.Model.log_marginal_likelihood">log_marginal_likelihood</a></code></li>
<li><code><a title="mogptk.model.Model.plot" href="#mogptk.model.Model.plot">plot</a></code></li>
<li><code><a title="mogptk.model.Model.predict" href="#mogptk.model.Model.predict">predict</a></code></li>
<li><code><a title="mogptk.model.Model.print_parameters" href="#mogptk.model.Model.print_parameters">print_parameters</a></code></li>
<li><code><a title="mogptk.model.Model.save" href="#mogptk.model.Model.save">save</a></code></li>
<li><code><a title="mogptk.model.Model.train" href="#mogptk.model.Model.train">train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>