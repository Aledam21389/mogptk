<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>mogptk.kernels.multikernel API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mogptk.kernels.multikernel</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L0-L126" class="git-link">Browse git</a>
</summary>
<pre><code class="python"># This is a simplification and adaptation to gpflow 1.0 of the work done
# by Rasmus Bonnevie on issue #328, credits to him.
import tensorflow as tf
from gpflow.kernels import Kernel

class MultiKernel(Kernel):
    &#34;&#34;&#34;Abstract class for MultiOutput Kernels.

    This abstract kernel assumes input X where the first column is a
    series of integer indices and the remaining dimensions are
    unconstrained. Multikernels are designed to handle outputs from
    different Gaussian processes, specifically in the case where they
    are not independent and where they can be observed independently.
    This abstract class implements the functionality necessary to split
    the observations into different cases and reorder the final kernel
    matrix appropriately.
    &#34;&#34;&#34;
    def __init__(self, input_dim, output_dim, active_dims=None, name=None):
        Kernel.__init__(self, active_dims, name)
        self.input_dim = input_dim
        self.output_dim = output_dim

    def subK(self, indexes, X, X2):
        return NotImplementedError

    def subKdiag(self, indexes, X):
        K = self.subK((indexes, indexes), X, X)
        return tf.linalg.diag_part(K)

    def K(self, X, X2=None, presliced=False):
        # TODO: clean up, what follows is a start
        #if presliced == False:
        #    X, X2 = self.slice(X, X2)

        #idx = tf.cast(X[:, 0], tf.int32)
        #parts = tf.dynamic_partition(X[:, 1:], idx, self.output_dim)

        #if X2 is None:
        #    for i in range(self.output_dim):
        #        for j in range(self.output_dim):
        #            self.K_sub((i,j), parts[i], parts[j])
        #else:
        #    idx2 = idx


        # X, X2 = self._slice(X, X2)
        Xindex = tf.cast(X[:, 0], tf.int32)  # find group indices

        Xparts, Xsplitn, Xreturn = self._splitback(X[:, 1:], Xindex)

        if X2 is None:
            X2, X2parts, X2return, X2splitn = (X, Xparts, Xreturn, Xsplitn)
        else:
            X2index = tf.cast(X2[:, 0], tf.int32)
            X2parts, X2splitn, X2return = self._splitback(X2[:, 1:], X2index)

        #original
        #Find out what happens when there&#39;s an empty index for output_dim
        # construct kernel matrix for index-sorted data (stacked Xparts)
        blocks = []
        for i in range(self.output_dim):
            row_i = []
            for j in range(self.output_dim):
                row_i.append(self.subK((i, j), Xparts[i], X2parts[j]))
            blocks.append(tf.concat(row_i, 1))
        Ksort = tf.concat(blocks, 0)

        #new

        # Ksort = self.subK((tf.unstack(Xsplitn),tf.unstack(X2splitn)), X[:,1:], X2[:,1:])

        #ORIGINAL
        # split matrix into chunks, then stitch them together in correct order
        Ktmp = self._reconstruct(Ksort, Xsplitn, Xreturn)
        KT = self._reconstruct(tf.transpose(Ktmp), X2splitn, X2return)
        Kout = tf.transpose(KT, name=&#39;K&#39;)
        return Kout
        #ORIGINAL

        # return Ksort

    def K_diag(self, X, presliced=False):
        # X, _ = self._slice(X, None)
        Xindex = tf.cast(X[:, 0], tf.int32)  # find recursion level indices
        Xparts, Xsplitn, Freturn = self._splitback(X[:, 1:], Xindex)

        subdiags = []
        for index, data in enumerate(Xparts):
            subdiags.append(self.subKdiag(index, Xparts[index]))
        Kd = tf.concat(subdiags, 0)
        return self._reconstruct(Kd, Xsplitn, Freturn)

    def _splitback(self, data, indices):
        &#34;&#34;&#34;Apply dynamic_partitioning and calculate necessary statistics
        for inverse mapping.&#34;&#34;&#34;
        # split data based on indices
        parts = tf.dynamic_partition(data, indices, self.output_dim)

        # to be able to invert the splitting, we need:
        # the size of each data split
        splitnum = tf.stack([tf.shape(x)[0] for x in parts])
        # indices to invert dynamic_part
        goback = tf.dynamic_partition(tf.range(tf.shape(data)[0]), indices, self.output_dim)
        return (parts, splitnum, goback)

    def _reconstruct(self, K, splitnum, goback):
        &#34;&#34;&#34;Use quantities from splitback to invert a dynamic_partition.&#34;&#34;&#34;
        tmp = tf.split(K, splitnum, axis=0)
        return tf.dynamic_stitch(goback, tmp)  # stitch

    def sqdist(self, X, X2, lscales):
        &#34;&#34;&#34;Return the square distance between two tensors.&#34;&#34;&#34;
        Xs = tf.reduce_sum(tf.square(X) * lscales, 1)
        if X2 is None:
            return -2 * tf.matmul(X * lscales, tf.transpose(X)) \
                    + tf.reshape(Xs, (-1, 1)) + tf.reshape(Xs, (1, -1))
        else:
            X2s = tf.reduce_sum(tf.square(X2) * lscales, 1)
            return -2 * tf.matmul(X * lscales, tf.transpose(X2)) \
                    + tf.reshape(Xs, (-1, 1)) + tf.reshape(X2s, (1, -1))

    def dist(self, X, X2):
        if X2 is None:
            X2 = X
        X = tf.expand_dims(tf.transpose(X), axis=2)
        X2 = tf.expand_dims(tf.transpose(X2), axis=1)
        return tf.matmul(X, tf.ones_like(X2)) + tf.matmul(tf.ones_like(X), -X2)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mogptk.kernels.multikernel.MultiKernel"><code class="flex name class">
<span>class <span class="ident">MultiKernel</span></span>
<span>(</span><span>input_dim, output_dim, active_dims=None, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Abstract class for MultiOutput Kernels.</p>
<p>This abstract kernel assumes input X where the first column is a
series of integer indices and the remaining dimensions are
unconstrained. Multikernels are designed to handle outputs from
different Gaussian processes, specifically in the case where they
are not independent and where they can be observed independently.
This abstract class implements the functionality necessary to split
the observations into different cases and reorder the final kernel
matrix appropriately.</p>
<p>:param active_dims: active dimensions, either a slice or list of
indices into the columns of X.
:param name: optional kernel name.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L6-L127" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class MultiKernel(Kernel):
    &#34;&#34;&#34;Abstract class for MultiOutput Kernels.

    This abstract kernel assumes input X where the first column is a
    series of integer indices and the remaining dimensions are
    unconstrained. Multikernels are designed to handle outputs from
    different Gaussian processes, specifically in the case where they
    are not independent and where they can be observed independently.
    This abstract class implements the functionality necessary to split
    the observations into different cases and reorder the final kernel
    matrix appropriately.
    &#34;&#34;&#34;
    def __init__(self, input_dim, output_dim, active_dims=None, name=None):
        Kernel.__init__(self, active_dims, name)
        self.input_dim = input_dim
        self.output_dim = output_dim

    def subK(self, indexes, X, X2):
        return NotImplementedError

    def subKdiag(self, indexes, X):
        K = self.subK((indexes, indexes), X, X)
        return tf.linalg.diag_part(K)

    def K(self, X, X2=None, presliced=False):
        # TODO: clean up, what follows is a start
        #if presliced == False:
        #    X, X2 = self.slice(X, X2)

        #idx = tf.cast(X[:, 0], tf.int32)
        #parts = tf.dynamic_partition(X[:, 1:], idx, self.output_dim)

        #if X2 is None:
        #    for i in range(self.output_dim):
        #        for j in range(self.output_dim):
        #            self.K_sub((i,j), parts[i], parts[j])
        #else:
        #    idx2 = idx


        # X, X2 = self._slice(X, X2)
        Xindex = tf.cast(X[:, 0], tf.int32)  # find group indices

        Xparts, Xsplitn, Xreturn = self._splitback(X[:, 1:], Xindex)

        if X2 is None:
            X2, X2parts, X2return, X2splitn = (X, Xparts, Xreturn, Xsplitn)
        else:
            X2index = tf.cast(X2[:, 0], tf.int32)
            X2parts, X2splitn, X2return = self._splitback(X2[:, 1:], X2index)

        #original
        #Find out what happens when there&#39;s an empty index for output_dim
        # construct kernel matrix for index-sorted data (stacked Xparts)
        blocks = []
        for i in range(self.output_dim):
            row_i = []
            for j in range(self.output_dim):
                row_i.append(self.subK((i, j), Xparts[i], X2parts[j]))
            blocks.append(tf.concat(row_i, 1))
        Ksort = tf.concat(blocks, 0)

        #new

        # Ksort = self.subK((tf.unstack(Xsplitn),tf.unstack(X2splitn)), X[:,1:], X2[:,1:])

        #ORIGINAL
        # split matrix into chunks, then stitch them together in correct order
        Ktmp = self._reconstruct(Ksort, Xsplitn, Xreturn)
        KT = self._reconstruct(tf.transpose(Ktmp), X2splitn, X2return)
        Kout = tf.transpose(KT, name=&#39;K&#39;)
        return Kout
        #ORIGINAL

        # return Ksort

    def K_diag(self, X, presliced=False):
        # X, _ = self._slice(X, None)
        Xindex = tf.cast(X[:, 0], tf.int32)  # find recursion level indices
        Xparts, Xsplitn, Freturn = self._splitback(X[:, 1:], Xindex)

        subdiags = []
        for index, data in enumerate(Xparts):
            subdiags.append(self.subKdiag(index, Xparts[index]))
        Kd = tf.concat(subdiags, 0)
        return self._reconstruct(Kd, Xsplitn, Freturn)

    def _splitback(self, data, indices):
        &#34;&#34;&#34;Apply dynamic_partitioning and calculate necessary statistics
        for inverse mapping.&#34;&#34;&#34;
        # split data based on indices
        parts = tf.dynamic_partition(data, indices, self.output_dim)

        # to be able to invert the splitting, we need:
        # the size of each data split
        splitnum = tf.stack([tf.shape(x)[0] for x in parts])
        # indices to invert dynamic_part
        goback = tf.dynamic_partition(tf.range(tf.shape(data)[0]), indices, self.output_dim)
        return (parts, splitnum, goback)

    def _reconstruct(self, K, splitnum, goback):
        &#34;&#34;&#34;Use quantities from splitback to invert a dynamic_partition.&#34;&#34;&#34;
        tmp = tf.split(K, splitnum, axis=0)
        return tf.dynamic_stitch(goback, tmp)  # stitch

    def sqdist(self, X, X2, lscales):
        &#34;&#34;&#34;Return the square distance between two tensors.&#34;&#34;&#34;
        Xs = tf.reduce_sum(tf.square(X) * lscales, 1)
        if X2 is None:
            return -2 * tf.matmul(X * lscales, tf.transpose(X)) \
                    + tf.reshape(Xs, (-1, 1)) + tf.reshape(Xs, (1, -1))
        else:
            X2s = tf.reduce_sum(tf.square(X2) * lscales, 1)
            return -2 * tf.matmul(X * lscales, tf.transpose(X2)) \
                    + tf.reshape(Xs, (-1, 1)) + tf.reshape(X2s, (1, -1))

    def dist(self, X, X2):
        if X2 is None:
            X2 = X
        X = tf.expand_dims(tf.transpose(X), axis=2)
        X2 = tf.expand_dims(tf.transpose(X2), axis=1)
        return tf.matmul(X, tf.ones_like(X2)) + tf.matmul(tf.ones_like(X), -X2)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>gpflow.kernels.base.Kernel</li>
<li>gpflow.base.Module</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mogptk.kernels.conv.ConvolutionalGaussian" href="conv.html#mogptk.kernels.conv.ConvolutionalGaussian">ConvolutionalGaussian</a></li>
<li><a title="mogptk.kernels.csm.CrossSpectralMixture" href="csm.html#mogptk.kernels.csm.CrossSpectralMixture">CrossSpectralMixture</a></li>
<li><a title="mogptk.kernels.mosm.MultiOutputSpectralMixture" href="mosm.html#mogptk.kernels.mosm.MultiOutputSpectralMixture">MultiOutputSpectralMixture</a></li>
<li><a title="mogptk.kernels.sm_lmc.SpectralMixtureLMC" href="sm_lmc.html#mogptk.kernels.sm_lmc.SpectralMixtureLMC">SpectralMixtureLMC</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mogptk.kernels.multikernel.MultiKernel.K"><code class="name flex">
<span>def <span class="ident">K</span></span>(<span>self, X, X2=None, presliced=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L30-L77" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def K(self, X, X2=None, presliced=False):
    # TODO: clean up, what follows is a start
    #if presliced == False:
    #    X, X2 = self.slice(X, X2)

    #idx = tf.cast(X[:, 0], tf.int32)
    #parts = tf.dynamic_partition(X[:, 1:], idx, self.output_dim)

    #if X2 is None:
    #    for i in range(self.output_dim):
    #        for j in range(self.output_dim):
    #            self.K_sub((i,j), parts[i], parts[j])
    #else:
    #    idx2 = idx


    # X, X2 = self._slice(X, X2)
    Xindex = tf.cast(X[:, 0], tf.int32)  # find group indices

    Xparts, Xsplitn, Xreturn = self._splitback(X[:, 1:], Xindex)

    if X2 is None:
        X2, X2parts, X2return, X2splitn = (X, Xparts, Xreturn, Xsplitn)
    else:
        X2index = tf.cast(X2[:, 0], tf.int32)
        X2parts, X2splitn, X2return = self._splitback(X2[:, 1:], X2index)

    #original
    #Find out what happens when there&#39;s an empty index for output_dim
    # construct kernel matrix for index-sorted data (stacked Xparts)
    blocks = []
    for i in range(self.output_dim):
        row_i = []
        for j in range(self.output_dim):
            row_i.append(self.subK((i, j), Xparts[i], X2parts[j]))
        blocks.append(tf.concat(row_i, 1))
    Ksort = tf.concat(blocks, 0)

    #new

    # Ksort = self.subK((tf.unstack(Xsplitn),tf.unstack(X2splitn)), X[:,1:], X2[:,1:])

    #ORIGINAL
    # split matrix into chunks, then stitch them together in correct order
    Ktmp = self._reconstruct(Ksort, Xsplitn, Xreturn)
    KT = self._reconstruct(tf.transpose(Ktmp), X2splitn, X2return)
    Kout = tf.transpose(KT, name=&#39;K&#39;)
    return Kout</code></pre>
</details>
</dd>
<dt id="mogptk.kernels.multikernel.MultiKernel.K_diag"><code class="name flex">
<span>def <span class="ident">K_diag</span></span>(<span>self, X, presliced=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L82-L91" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def K_diag(self, X, presliced=False):
    # X, _ = self._slice(X, None)
    Xindex = tf.cast(X[:, 0], tf.int32)  # find recursion level indices
    Xparts, Xsplitn, Freturn = self._splitback(X[:, 1:], Xindex)

    subdiags = []
    for index, data in enumerate(Xparts):
        subdiags.append(self.subKdiag(index, Xparts[index]))
    Kd = tf.concat(subdiags, 0)
    return self._reconstruct(Kd, Xsplitn, Freturn)</code></pre>
</details>
</dd>
<dt id="mogptk.kernels.multikernel.MultiKernel.dist"><code class="name flex">
<span>def <span class="ident">dist</span></span>(<span>self, X, X2)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L122-L127" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def dist(self, X, X2):
    if X2 is None:
        X2 = X
    X = tf.expand_dims(tf.transpose(X), axis=2)
    X2 = tf.expand_dims(tf.transpose(X2), axis=1)
    return tf.matmul(X, tf.ones_like(X2)) + tf.matmul(tf.ones_like(X), -X2)</code></pre>
</details>
</dd>
<dt id="mogptk.kernels.multikernel.MultiKernel.sqdist"><code class="name flex">
<span>def <span class="ident">sqdist</span></span>(<span>self, X, X2, lscales)</span>
</code></dt>
<dd>
<section class="desc"><p>Return the square distance between two tensors.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L111-L120" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def sqdist(self, X, X2, lscales):
    &#34;&#34;&#34;Return the square distance between two tensors.&#34;&#34;&#34;
    Xs = tf.reduce_sum(tf.square(X) * lscales, 1)
    if X2 is None:
        return -2 * tf.matmul(X * lscales, tf.transpose(X)) \
                + tf.reshape(Xs, (-1, 1)) + tf.reshape(Xs, (1, -1))
    else:
        X2s = tf.reduce_sum(tf.square(X2) * lscales, 1)
        return -2 * tf.matmul(X * lscales, tf.transpose(X2)) \
                + tf.reshape(Xs, (-1, 1)) + tf.reshape(X2s, (1, -1))</code></pre>
</details>
</dd>
<dt id="mogptk.kernels.multikernel.MultiKernel.subK"><code class="name flex">
<span>def <span class="ident">subK</span></span>(<span>self, indexes, X, X2)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L23-L24" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def subK(self, indexes, X, X2):
    return NotImplementedError</code></pre>
</details>
</dd>
<dt id="mogptk.kernels.multikernel.MultiKernel.subKdiag"><code class="name flex">
<span>def <span class="ident">subKdiag</span></span>(<span>self, indexes, X)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/GAMES-UChile/mogptk/blob/b72264f56d683911587496ed946cb8cc84d0bd2d/mogptk/kernels/multikernel.py#L26-L28" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def subKdiag(self, indexes, X):
    K = self.subK((indexes, indexes), X, X)
    return tf.linalg.diag_part(K)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mogptk.kernels" href="index.html">mogptk.kernels</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mogptk.kernels.multikernel.MultiKernel" href="#mogptk.kernels.multikernel.MultiKernel">MultiKernel</a></code></h4>
<ul class="two-column">
<li><code><a title="mogptk.kernels.multikernel.MultiKernel.K" href="#mogptk.kernels.multikernel.MultiKernel.K">K</a></code></li>
<li><code><a title="mogptk.kernels.multikernel.MultiKernel.K_diag" href="#mogptk.kernels.multikernel.MultiKernel.K_diag">K_diag</a></code></li>
<li><code><a title="mogptk.kernels.multikernel.MultiKernel.dist" href="#mogptk.kernels.multikernel.MultiKernel.dist">dist</a></code></li>
<li><code><a title="mogptk.kernels.multikernel.MultiKernel.sqdist" href="#mogptk.kernels.multikernel.MultiKernel.sqdist">sqdist</a></code></li>
<li><code><a title="mogptk.kernels.multikernel.MultiKernel.subK" href="#mogptk.kernels.multikernel.MultiKernel.subK">subK</a></code></li>
<li><code><a title="mogptk.kernels.multikernel.MultiKernel.subKdiag" href="#mogptk.kernels.multikernel.MultiKernel.subKdiag">subKdiag</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>